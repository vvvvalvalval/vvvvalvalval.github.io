<?xml version='1.0' encoding='UTF-8'?>
<rss version='2.0' xmlns:atom='http://www.w3.org/2005/Atom'>
<channel>
<atom:link href='http://vvvvalvalval.github.io/' rel='self' type='application/rss+xml'/>
<title>
Val on Programming
</title>
<link>
http://vvvvalvalval.github.io/
</link>
<description>

</description>
<lastBuildDate>
Tue, 04 Feb 2020 17:54:22 +0100
</lastBuildDate>
<generator>
clj-rss
</generator>
<item>
<guid>
http://vvvvalvalval.github.io/posts/2020-01-31_how-covariances-behave-some-intuitive-views-on-normal-distributions-and-gaussian-processes.html
</guid>
<link>
http://vvvvalvalval.github.io/posts/2020-01-31_how-covariances-behave-some-intuitive-views-on-normal-distributions-and-gaussian-processes.html
</link>
<title>
How covariances behave: some intuitive views on normal distributions and Gaussian Processes
</title>
<description>

</description>
<pubDate>
Fri, 31 Jan 2020 00:00:00 +0100
</pubDate>
</item>
<item>
<guid>
http://vvvvalvalval.github.io/posts/2019-12-18_2-proofs-in-Information-Theory-channel-convexity-of-mutual-information.html
</guid>
<link>
http://vvvvalvalval.github.io/posts/2019-12-18_2-proofs-in-Information-Theory-channel-convexity-of-mutual-information.html
</link>
<title>
2 proofs in Information Theory: channel-convexity of Mutual Information
</title>
<description>

</description>
<pubDate>
Wed, 18 Dec 2019 00:00:00 +0100
</pubDate>
</item>
<item>
<guid>
http://vvvvalvalval.github.io/posts/2019-12-03-inferring-earth-tilt-from-day-lengths.html
</guid>
<link>
http://vvvvalvalval.github.io/posts/2019-12-03-inferring-earth-tilt-from-day-lengths.html
</link>
<title>
Inferring the Earth's tilt from day lengths
</title>
<description>

</description>
<pubDate>
Tue, 03 Dec 2019 00:00:00 +0100
</pubDate>
</item>
<item>
<guid>
http://vvvvalvalval.github.io/posts/2019-09-13-diversified-sampling-mining-large-datasets-for-special-cases.html
</guid>
<link>
http://vvvvalvalval.github.io/posts/2019-09-13-diversified-sampling-mining-large-datasets-for-special-cases.html
</link>
<title>
'Diversified Sampling': mining large datasets for special cases
</title>
<description>
 &lt;p&gt;In this article, I want to share a little &lt;i&gt;data engineering&lt;/i&gt; trick that I've used for building programs that consume poorly-understood data, which I'm calling 'Diversified Sampling'. This terminology is totally made up by me, and there's a high chance that this technique already exists with another name, or that the scholars have deemed it too trivial to name it at all. Hopefully some people more knowledgeable than me will comment on this.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;TL;DR:&lt;/strong&gt; the objective is to build a small sample of the data in which special cases are likely to be represented. The strategy is to have each data item emit a list of 'features', and to boost the probability of selecting rare features. A shallow understanding of the data is often enough to design an effective features extraction. &lt;br /&gt;  &lt;/p&gt;&lt;h2 id=&quot;the&amp;#95;problem&quot;&gt;The problem&lt;/h2&gt;&lt;p&gt;Suppose that you're given a large datasets of documents, and you have to build a system that extracts information from these documents. You only have a poor technical understanding of these documents: basically, some told you informally what the documents are about, and if you're lucky you have a vague spec or schema which will be mostly respected by the documents. What's more, the dataset is big enough that it would take hours for a machine to process it fully, and many lifetimes for you to read all the documents with your own eyes. Yet you have to write a program that processes these documents reliably. What do you do?&lt;/p&gt;&lt;p&gt;As an case study for this article, we're going to use the Articles data dump &lt;a href='https://doaj.org/public-data-dump'&gt;of the Directory of Open Access Journals&lt;/a&gt; (DOAJ), which contains metadata about around 4 million academic articles in the form of JSON documents. To make things concrete, here's one document from this dataset:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;json&quot;&gt;{
  &amp;quot;last&amp;#95;updated&amp;quot; : &amp;quot;2019-02-21T17:05:46Z&amp;quot;,
  &amp;quot;id&amp;quot; : &amp;quot;cfc9b25374b6400da55a35d2815cc915&amp;quot;,
  &amp;quot;bibjson&amp;quot; : {
    &amp;quot;abstract&amp;quot; : &amp;quot;The author estimates both medical insurance agencies’ performance in the field of providing and protecting the rights of insured persons within compulsory medical insurance and the role of insurance medical agencies in the system of social protection of citizens&amp;quot;,
    &amp;quot;month&amp;quot; : &amp;quot;4&amp;quot;,
    &amp;quot;journal&amp;quot; : {
      &amp;quot;publisher&amp;quot; : &amp;quot;Omsk Law Academy&amp;quot;,
      &amp;quot;license&amp;quot; : &amp;#91; {
        &amp;quot;url&amp;quot; : &amp;quot;http://en.vestnik.omua.ru/content/open-access-policy&amp;quot;,
        &amp;quot;open&amp;#95;access&amp;quot; : true,
        &amp;quot;type&amp;quot; : &amp;quot;CC BY&amp;quot;,
        &amp;quot;title&amp;quot; : &amp;quot;CC BY&amp;quot;
      } &amp;#93;,
      &amp;quot;language&amp;quot; : &amp;#91; &amp;quot;RU&amp;quot; &amp;#93;,
      &amp;quot;title&amp;quot; : &amp;quot;Vestnik Omskoj Ûridičeskoj Akademii&amp;quot;,
      &amp;quot;country&amp;quot; : &amp;quot;RU&amp;quot;,
      &amp;quot;number&amp;quot; : &amp;quot;27&amp;quot;,
      &amp;quot;issns&amp;quot; : &amp;#91; &amp;quot;2306-1340&amp;quot;, &amp;quot;2410-8812&amp;quot; &amp;#93;
    },
    &amp;quot;keywords&amp;quot; : &amp;#91; &amp;quot;Compulsory medical insurance&amp;quot;, &amp;quot;insurance medical agencies&amp;quot;, &amp;quot;free medical aid&amp;quot;, &amp;quot;social protection of citizens&amp;quot; &amp;#93;,
    &amp;quot;title&amp;quot; : &amp;quot;The Role of Medical Insurance Agencies in the System of Social Protection of Citizens&amp;quot;,
    &amp;quot;author&amp;quot; : &amp;#91; {
      &amp;quot;affiliation&amp;quot; : &amp;quot;Omsk Law Academy&amp;quot;,
      &amp;quot;name&amp;quot; : &amp;quot;Beketova A. V. &amp;quot;
    } &amp;#93;,
    &amp;quot;year&amp;quot; : &amp;quot;2015&amp;quot;,
    &amp;quot;link&amp;quot; : &amp;#91; {
      &amp;quot;url&amp;quot; : &amp;quot;http://vestnik.omua.ru/?q=content/rol-strahovyh-medicinskih-organizaciy-v-sisteme-socialnoy-zashchity-naseleniya&amp;quot;,
      &amp;quot;type&amp;quot; : &amp;quot;fulltext&amp;quot;
    } &amp;#93;,
    &amp;quot;start&amp;#95;page&amp;quot; : &amp;quot;52&amp;quot;,
    &amp;quot;identifier&amp;quot; : &amp;#91; {
      &amp;quot;type&amp;quot; : &amp;quot;pissn&amp;quot;,
      &amp;quot;id&amp;quot; : &amp;quot;2306-1340&amp;quot;
    }, {
      &amp;quot;type&amp;quot; : &amp;quot;eissn&amp;quot;,
      &amp;quot;id&amp;quot; : &amp;quot;2410-8812&amp;quot;
    } &amp;#93;,
    &amp;quot;end&amp;#95;page&amp;quot; : &amp;quot;55&amp;quot;,
    &amp;quot;subject&amp;quot; : &amp;#91; {
      &amp;quot;scheme&amp;quot; : &amp;quot;LCC&amp;quot;,
      &amp;quot;term&amp;quot; : &amp;quot;Law&amp;quot;,
      &amp;quot;code&amp;quot; : &amp;quot;K&amp;quot;
    } &amp;#93;
  },
  &amp;quot;created&amp;#95;date&amp;quot; : &amp;quot;2018-02-19T06:45:24Z&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;why&amp;#95;we&amp;#95;need&amp;#95;small&amp;#95;samples&quot;&gt;Why we need small samples&lt;/h2&gt;&lt;p&gt;Because the dataset is so big, the need quickly arises to work on small samples of the documents, for several uses:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;For &lt;strong&gt;'having a look'&lt;/strong&gt; at the data, e.g getting familiar with the schema of the documents to understand what attributes are available and what they mean.&lt;/li&gt;&lt;li&gt;For &lt;strong&gt;example-based testing&lt;/strong&gt;: you'll likely want to test whatever code you write for extracting information from the data, so a sample can give you a set of realistic examples on which you can test your processing code quickly.&lt;/li&gt;&lt;li&gt;Even if you prefer &lt;strong&gt;generative testing&lt;/strong&gt;, you're going to have to develop a model of the data, and to iterate on that model you'll want to validate it rapidly against real-world examples.&lt;/li&gt;&lt;li&gt;On a related topic, for &lt;strong&gt;data validation&lt;/strong&gt;: your program will make assumptions about the properties of the data, and you'll want to check that new documents fall within these assumptions. A small sample can help you iterate on these assumptions rapidly, after which you can gain even more confidence by testing these assumptions against the entire dataset.&lt;/li&gt;&lt;/ol&gt;&lt;h2 id=&quot;naive&amp;#95;approach:&amp;#95;uniform&amp;#95;sampling&quot;&gt;Naive approach: uniform sampling&lt;/h2&gt;&lt;p&gt;The most intuitive approach to sampling is simply to select each document randomly with uniform probability; for example, to build a sample of about 1000 documents out of the 4.2 million documents of the DOAJ dataset, I could run them through an algorithm that keeps each document with probability 1000 / 4200000. &lt;/p&gt;&lt;p&gt;Unfortunately, this is likely to be insufficient, because it will fail to capture some rare pathological cases that need to be handled nonetheless. Here are a few examples of 'pathological cases':&lt;/p&gt;&lt;ol&gt;&lt;li&gt;a few documents may be lacking an &lt;code&gt;id&lt;/code&gt; attribute.&lt;/li&gt;&lt;li&gt;a few documents may have their &lt;code&gt;start&amp;#95;page&lt;/code&gt; attribute written in roman numerals (true story!)&lt;/li&gt;&lt;li&gt;a few documents may have more than a thousand &lt;code&gt;keywords&lt;/code&gt;, and your processing code will choke on that.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;When you build on uniform samples, it's common to write code that seems to work perfectly fine, and then fails a few hours into processing because of one pathological input. As your information-extracting code evolves, it's important to be able to detect these edge cases rapidly.&lt;/p&gt;&lt;p&gt;For testing purposes, it's better to have samples in which the special cases are over-represented. We don't want to select all documents with equal probability: we want the &lt;i&gt;freaks&lt;/i&gt;! But how do you select for pathological cases, since your problem is precisely that you have an incomplete understanding of how the data might behave?&lt;/p&gt;&lt;h2 id=&quot;the&amp;#95;algorithm:&amp;#95;selecting&amp;#95;rare&amp;#95;features&quot;&gt;The algorithm: selecting rare features&lt;/h2&gt;&lt;p&gt;The idea behind the approach I'm proposing here is that you can usually detect special cases even without a good understanding of the data semantics, based on some 'mechanical' aspects of the data, such as the set of attributes present in a document, or the presence of rare characters.  &lt;/p&gt;&lt;p&gt;More precisely, the idea is that you would implement a function that extracts from any given document a set of 'features' (a list of Strings); the guiding principle for designing the features function is that pathological cases should exhibit rare features. For example, the features extracted from the above example might be:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;bibjson
bibjson.abstract
bibjson.author
bibjson.author.&amp;#91;&amp;#93;.affiliation
bibjson.author.&amp;#91;&amp;#93;.name
bibjson.end&amp;#95;page
bibjson.identifier
bibjson.identifier.&amp;#91;&amp;#93;.id
bibjson.identifier.&amp;#91;&amp;#93;.type
bibjson.journal
bibjson.journal.country
bibjson.journal.issns
bibjson.journal.issns.0
bibjson.journal.issns.1
bibjson.journal.language
bibjson.journal.license
bibjson.journal.license.&amp;#91;&amp;#93;.open&amp;#95;access
bibjson.journal.license.&amp;#91;&amp;#93;.title
bibjson.journal.license.&amp;#91;&amp;#93;.type
bibjson.journal.license.&amp;#91;&amp;#93;.url
bibjson.journal.number
bibjson.journal.publisher
bibjson.journal.title
bibjson.keywords
bibjson.link
bibjson.link.&amp;#91;&amp;#93;.type
bibjson.link.&amp;#91;&amp;#93;.url
bibjson.month
bibjson.start&amp;#95;page
bibjson.subject
bibjson.subject.&amp;#91;&amp;#93;.code
bibjson.subject.&amp;#91;&amp;#93;.scheme
bibjson.subject.&amp;#91;&amp;#93;.term
bibjson.title
bibjson.year
created&amp;#95;date
doaj.article.link-type/fulltext
doaj.article.n-keywords/highest1bit=4
doaj.article.n-languages/highest1bit=1
doaj.article.n-licenses/highest1bit=1
doaj.article.n-subjects/highest1bit=1
doaj.article.subject-scheme/LCC
doaj.identifier-type/eissn
doaj.identifier-type/pissn
id
last&amp;#95;updated
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Notice how most of these 'features' can be derived very mechanically from the data:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;present attributes / paths:&lt;/strong&gt; for example, &lt;code&gt;bibjson.author.&amp;#91;&amp;#93;.name&lt;/code&gt; tells you that the document is a map with a &lt;code&gt;bibjson&lt;/code&gt; key, containing a map with an &lt;code&gt;author&lt;/code&gt; key, containing an array of maps with a &lt;code&gt;name&lt;/code&gt; key. Such a feature can be extracted from any JSON document without any more knowledge of what it contains.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;cardinality:&lt;/strong&gt; for example, &lt;code&gt;doaj.article.n-keywords/highest1bit=4&lt;/code&gt; tells you that the article has between 4 and 7 &lt;code&gt;keywords&lt;/code&gt;.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;enumerations:&lt;/strong&gt; for example, &lt;code&gt;doaj.article.subject-scheme/LCC&lt;/code&gt; tells you that the article has a subject of scheme &lt;code&gt;LCC&lt;/code&gt;, whatever that means. You don't need to know what a subject or a scheme is to make this extraction: you only need to 'smell' that we're dealing with an enumerated attribute.&lt;/li&gt;&lt;li&gt;other good candidates include character ranges (for detecting diacritics / XML markup / encoding errors), rounded String lengths, URL or date patterns, JSON value types, etc.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Once you can extract appropriate features, the algorithm is simple to describe: &lt;strong&gt;each document is selected with a probability proportional to the rarity (inverse frequency) of its rarest feature.&lt;/strong&gt; More precisely:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;You parameterize your algorithm with a small number &lt;code&gt;K&lt;/code&gt; (e.g 10), meaning that every feature should on average be represented at least &lt;code&gt;K&lt;/code&gt; times.&lt;/li&gt;&lt;li&gt;For each article, you draw a random number &lt;code&gt;r&lt;/code&gt; between 0 and 1. If the document has a feature such that &lt;code&gt;r &amp;lt; K/M&lt;/code&gt;, where &lt;code&gt;M&lt;/code&gt; is the number of times that the feature appears in the entire dataset, then it is selected. In particular, if a feature is rare to the point of being represented fewer than &lt;code&gt;K&lt;/code&gt; times, then the documents having it are guaranteed to be selected.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;Some notes:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;A generally useful refinement from the above is to consider the &lt;i&gt;absence&lt;/i&gt;  of a feature as a feature itself (for instance, this is how you would select the rare occurrence of an &lt;code&gt;id&lt;/code&gt; field missing). With the above notation, this implies comparing &lt;code&gt;r&lt;/code&gt; to either &lt;code&gt;K/M&lt;/code&gt; or &lt;code&gt;K/&amp;#40;N-M&amp;#41;&lt;/code&gt; depending on whether the feature is present or not in the document, where &lt;code&gt;N&lt;/code&gt; denotes the total number of articles.&lt;/li&gt;&lt;li&gt;The algorithm does 2 linear passes on the entire data, and is well suited to be run in a parallel and distributed architecture like MapReduce / Spark / etc. while accumulating very small result. Provided that your features function is not too expensive, this can run very fast.&lt;/li&gt;&lt;li&gt;You choose &lt;code&gt;K&lt;/code&gt; based on the desired sample size. In practice, it can be hard to predict what the resulting sample size will be, because it depends on the number of features but also on how they correlate.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;In light of this, let's have a look at the distribution of features in our dataset:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;|                                 Feature | #articles |
|-----------------------------------------+-----------|
|                                   admin |   1262315 |
|                              admin.seal |   1262315 |
|                                 bibjson |   3925522 |
|                        bibjson.abstract |   3528943 |
|                          bibjson.author |   3892589 |
|           bibjson.author.&amp;#91;&amp;#93;.affiliation |   2075706 |
|                  bibjson.author.&amp;#91;&amp;#93;.name |   3885804 |
|                        bibjson.end&amp;#95;page |   2551540 |
|                      bibjson.identifier |   3925522 |
|                bibjson.identifier.&amp;#91;&amp;#93;.id |   3925522 |
|              bibjson.identifier.&amp;#91;&amp;#93;.type |   3925522 |
|                         bibjson.journal |   3925522 |
|                 bibjson.journal.country |   3925522 |
|                   bibjson.journal.issns |   3925522 |
|                 bibjson.journal.issns.0 |   3925522 |
|                 bibjson.journal.issns.1 |   2105552 |
|                bibjson.journal.language |   3925522 |
|                 bibjson.journal.license |   3925522 |
|  bibjson.journal.license.&amp;#91;&amp;#93;.open&amp;#95;access |   3909861 |
|        bibjson.journal.license.&amp;#91;&amp;#93;.title |   3922195 |
|         bibjson.journal.license.&amp;#91;&amp;#93;.type |   3922195 |
|          bibjson.journal.license.&amp;#91;&amp;#93;.url |   3918950 |
|                  bibjson.journal.number |   3389896 |
|               bibjson.journal.publisher |   3925522 |
|                   bibjson.journal.title |   3925522 |
|                  bibjson.journal.volume |   3800165 |
|                        bibjson.keywords |   2340697 |
|                            bibjson.link |   3925522 |
|            bibjson.link.&amp;#91;&amp;#93;.content&amp;#95;type |   2068285 |
|                    bibjson.link.&amp;#91;&amp;#93;.type |   3912438 |
|                     bibjson.link.&amp;#91;&amp;#93;.url |   3912438 |
|                           bibjson.month |   3237064 |
|                      bibjson.start&amp;#95;page |   3167003 |
|                         bibjson.subject |   3925522 |
|                 bibjson.subject.&amp;#91;&amp;#93;.code |   3918612 |
|               bibjson.subject.&amp;#91;&amp;#93;.scheme |   3918612 |
|                 bibjson.subject.&amp;#91;&amp;#93;.term |   3918612 |
|                           bibjson.title |   3922426 |
|                            bibjson.year |   3855525 |
|                            created&amp;#95;date |   3925522 |
|         doaj.article.link-type/fulltext |   3912438 |
|   doaj.article.n-keywords/highest1bit=0 |   1584825 |
|   doaj.article.n-keywords/highest1bit=1 |    200419 |
| doaj.article.n-keywords/highest1bit=128 |        47 |
|  doaj.article.n-keywords/highest1bit=16 |      8776 |
|   doaj.article.n-keywords/highest1bit=2 |    446826 |
| doaj.article.n-keywords/highest1bit=256 |         2 |
|  doaj.article.n-keywords/highest1bit=32 |       606 |
|   doaj.article.n-keywords/highest1bit=4 |   1466157 |
|  doaj.article.n-keywords/highest1bit=64 |       218 |
|   doaj.article.n-keywords/highest1bit=8 |    217646 |
|  doaj.article.n-languages/highest1bit=0 |         1 |
|  doaj.article.n-languages/highest1bit=1 |   2726455 |
|  doaj.article.n-languages/highest1bit=2 |   1058128 |
|  doaj.article.n-languages/highest1bit=4 |    137890 |
|  doaj.article.n-languages/highest1bit=8 |      3048 |
|   doaj.article.n-licenses/highest1bit=0 |      3327 |
|   doaj.article.n-licenses/highest1bit=1 |   3922195 |
|   doaj.article.n-subjects/highest1bit=0 |      6910 |
|   doaj.article.n-subjects/highest1bit=1 |   2405221 |
|   doaj.article.n-subjects/highest1bit=2 |   1459074 |
|   doaj.article.n-subjects/highest1bit=4 |     53447 |
|   doaj.article.n-subjects/highest1bit=8 |       870 |
|        doaj.article.subject-scheme/DOAJ |      4633 |
|         doaj.article.subject-scheme/LCC |   3918612 |
|                doaj.identifier-type/DOI |     47595 |
|                doaj.identifier-type/doi |   2724699 |
|              doaj.identifier-type/eissn |   2974967 |
|               doaj.identifier-type/issn |      1626 |
|              doaj.identifier-type/pissn |   2831153 |
|          doaj.identifier-type/publisher |      1150 |
|                                      id |   3925522 |
|                            last&amp;#95;updated |   3925522 |
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Looking at this, we see that there are some irregularities which we could have easily missed with naive sampling:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;One article has zero languages - this could easily have caused an error in our processing.&lt;/li&gt;&lt;li&gt;4633 (out of 4 million!) articles have a DOAJ-specific subject scheme, instead of the almost ubiquitous LCC.&lt;/li&gt;&lt;li&gt;1626 articles have an ISSN number which is classified neither as electronic (&lt;code&gt;eissn&lt;/code&gt;) nor print (&lt;code&gt;pissn&lt;/code&gt;)&lt;/li&gt;&lt;li&gt;We see an inconsistency in how DOI identifiers are declared - most of the time as &lt;code&gt;&amp;quot;doi&amp;quot;&lt;/code&gt;, and more rarely (47595) as &lt;code&gt;&amp;quot;DOI&amp;quot;&lt;/code&gt;.&lt;/li&gt;&lt;li&gt;49 articles have more than 128 keywords. This could cause performance issues, should we do some processing that emits tuples of these keywords.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;This isn't to bash on DOAJ - in my experience, compared to other academic publishers, their data exports are really a pleasure to work with. But it is a good reminder that real-world data tends to be full of surprises.&lt;/p&gt;&lt;p&gt;How much does Diversified Sampling increase our odds of selecting these special cases? Let's examine the example of the 4633 articles having a DOAJ-specific subject scheme:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Naive sampling:&lt;/strong&gt; if you use the naive sampling method, aiming for a sample size of 1000 articles, you have a &lt;strong&gt;30.5%&lt;/strong&gt; chance of missing out on all 4633 articles.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Diversified sampling:&lt;/strong&gt; using diversified sampling with &lt;code&gt;K=20&lt;/code&gt; (which in this case yields a sample of about 500 articles), the odds of missing out on all 4633 are &lt;i&gt;at most&lt;/i&gt; &lt;strong&gt;0.0000002%&lt;/strong&gt;. There's a mathematical approximation that sheds some light on this: even when &lt;code&gt;K &amp;lt;&amp;lt; M&lt;/code&gt;, then &lt;code&gt;&amp;#40;1- K/M&amp;#41;&amp;#94;M ≈ exp&amp;#40;-K&amp;#41; ≈ &amp;#40;0.37&amp;#41;&amp;#94;K&lt;/code&gt;.&lt;/li&gt;&lt;/ul&gt;&lt;h2 id=&quot;pitfalls&quot;&gt;Pitfalls&lt;/h2&gt;&lt;h3 id=&quot;beware&amp;#95;of&amp;#95;features&amp;#95;explosion&quot;&gt;Beware of features explosion&lt;/h3&gt;&lt;p&gt;If your features function generates too many features, then your sample size will tend to explode, and the pathological cases you were mining for will be diluted in falsely special documents. For example, in our DOAJ example, the exact number of keywords or the length of the abstract would be bad features, because these will tend to take very dispersed values that will be interpreted as rare features; when dealing with cardinalities like this, it's better to use logarithmic buckets instead of exact values.&lt;/p&gt;&lt;h3 id=&quot;design&amp;#95;your&amp;#95;features&amp;#95;function&amp;#95;well&quot;&gt;Design your features function well&lt;/h3&gt;&lt;p&gt;More generally, the entire principle of this sampling algorithm relies on emitting features that correspond well to special cases. There's no one-size-fits-all solution for this: you will have to look at the data and make ad hoc guesses.&lt;/p&gt;&lt;h3 id=&quot;do&amp;#95;not&amp;#95;use&amp;#95;diversified&amp;#95;sampling&amp;#95;for&amp;#95;statistics&quot;&gt;Do not use Diversified Sampling for statistics&lt;/h3&gt;&lt;p&gt;Do not use the diversified sample to compute aggregates like the average number of keywords. By design, Diversified Sampling selects mostly outliers which are not representative of the trends in your data. Naive samples are better for this.&lt;/p&gt;
</description>
<pubDate>
Fri, 13 Sep 2019 00:00:00 +0200
</pubDate>
</item>
<item>
<guid>
http://vvvvalvalval.github.io/posts/2018-11-12-datomic-event-sourcing-without-the-hassle.html
</guid>
<link>
http://vvvvalvalval.github.io/posts/2018-11-12-datomic-event-sourcing-without-the-hassle.html
</link>
<title>
Datomic: Event Sourcing without the hassle
</title>
<description>
&lt;p&gt;&lt;img style=&quot;text-align:center;&quot; src=&quot;/img/chess-both-incremental-and-absolute.png&quot; width=&quot;100%&quot;&gt;&lt;/p&gt;&lt;p&gt;When I got started using the &lt;a href='https://www.datomic.com'&gt;Datomic&lt;/a&gt; database, I remember someone describing it to me as 'Event Sourcing without the hassle'. Having built Event Sourcing systems both with and without Datomic, I think this is very well put, although it might not be obvious, especially if you don't have much experience with Datomic.&lt;/p&gt;&lt;p&gt;In this article, we'll describe briefly what Event Sourcing is, how it's conventionally implemented, analyze the limitations of that, and contrast that with how Datomic enables you to achieve the same benefits. We'll see that, for most use cases, Datomic enables us to implement Event Sourcing with much less effort, and (more importantly) with more agility. &lt;span class=&quot;sn&quot;&gt;By which I mean: less anticipation / planning&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; I'm not affiliated to the Datomic team in any way other than being a user of Datomic.  &lt;/p&gt;&lt;h2 id=&quot;why&amp;#95;event&amp;#95;sourcing?&quot;&gt;Why Event Sourcing?&lt;/h2&gt;&lt;p&gt;As of today, most information systems are implemented with a centralized database storing the 'current state'  (or you might say 'current knowledge') of the system. This database is usually a big mutable shared data structure, supported by database systems such as PostgreSQL / MongoDB / ElasticSearch / ... or a combination of those.   &lt;/p&gt;&lt;p&gt;For instance, a Q&amp;A website such as &lt;a href='https://stackoverflow.com/'&gt;StackOverflow&lt;/a&gt; could be backed with a SQL database, with tables  such as &lt;code&gt;Question&lt;/code&gt;, &lt;code&gt;Answer&lt;/code&gt;, &lt;code&gt;User&lt;/code&gt;, &lt;code&gt;Comment&lt;/code&gt;, &lt;code&gt;Tag&lt;/code&gt;, &lt;code&gt;Vote&lt;/code&gt; etc.&lt;/p&gt;&lt;p&gt;When all the data you have is about the 'current state' of the system, you can only ask questions about the   present (Examples: &quot;What's the title of Question 42?&quot; / &quot;Has User 23 answered Question 56?&quot; / etc.). But it turns out you may have important questions that are not about the present:  &lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;How did we get there?&lt;/strong&gt; What's the sequence of events which led you to the current state?  This is useful for audit trails, analytics, etc. (Example: &quot;How many times times do Users typically change the content of a Question?&quot;)&lt;/li&gt;&lt;li&gt;&lt;strong&gt;How was the state previously?&lt;/strong&gt; Especially useful for investigating bugs. (Example: &quot;What were the Tags associated with Question 38 last Monday at 6:23pm?&quot;)&lt;/li&gt;&lt;li&gt;&lt;strong&gt;What changed recently?&lt;/strong&gt; Useful for reacting to change, and in particular for propagating novelty. (Examples: &quot;What Questions have been affected by changes (directly or not) in the last 6 hours?&quot; / &quot;What events have caused the Reputation of User 42 to evolve in the last minute?&quot;)&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;a href='https://martinfowler.com/eaaDev/EventSourcing.html'&gt;Event Sourcing&lt;/a&gt; is an architectural approach designed   to address such questions.  &lt;strong&gt;Event Sourcing consists of keeping track not of the current state, but of the entire sequence of &lt;i&gt;state transitions&lt;/i&gt; which led to it.&lt;/strong&gt;  These state transitions are called &lt;i&gt;Events&lt;/i&gt;, and are the &quot;source of truth&quot; of the system, from which the current state  (or any past state) is inferred (hence the name &lt;i&gt;Event Sourcing&lt;/i&gt;).  &lt;/p&gt;&lt;p&gt;&lt;div style=&quot;text-align:center;&quot;&gt;&lt;img src=&quot;/img/event-sourcing-chess.png&quot; width=&quot;100%&quot;&gt;&lt;/div&gt; &lt;/p&gt;&lt;p&gt;The sequence of events is stored in an &lt;i&gt;Event Log&lt;/i&gt;, and it's important to understand that this Event Log  is &lt;i&gt;accumulate-only&lt;/i&gt;: events are (normally) only ever appended to the Log, never modified or erased.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Benefits of Event Sourcing:&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;You don't lose information&lt;/strong&gt; (since you only ever add to the data you have already written); in particular, it's possible to &lt;strong&gt;reproduce a past state&lt;/strong&gt; of the system.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Data synchronization&lt;/strong&gt; is easier: since you can determine what data has been recently added, you can propagate novelty to other components of the system, which lets you build &lt;strong&gt;materialized views&lt;/strong&gt; (e.g representing your data in search or analytics-optimized query engines such as ElasticSearch), send &lt;strong&gt;notifications&lt;/strong&gt; (e.g to a browser UI), etc. &lt;/li&gt;&lt;/ul&gt;&lt;h2 id=&quot;how&amp;#95;event&amp;#95;sourcing&amp;#95;is&amp;#95;usually&amp;#95;done&quot;&gt;How Event Sourcing is usually done&lt;/h2&gt;&lt;p&gt;At the time of writing, the conventional way of implementing Event Sourcing is as follows:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;You design a set of &lt;strong&gt;Event Types&lt;/strong&gt; suited to your domain. (For instance: &lt;code&gt;UserCreatedQuestion&lt;/code&gt;, &lt;code&gt;UserUpdatedQuestion&lt;/code&gt;, &lt;code&gt;UserCreatedAnswer&lt;/code&gt;, &lt;code&gt;UserVotedOnQuestion&lt;/code&gt;, etc.).&lt;/li&gt;&lt;li&gt;Each &lt;strong&gt;Event&lt;/strong&gt; is a record containing an Event Type, a timestamp (when it was added to the Log), and data attributes specific to that Event Type (e.g &lt;code&gt;question&amp;#95;id&lt;/code&gt;, &lt;code&gt;user&amp;#95;id&lt;/code&gt; etc.).&lt;/li&gt;&lt;li&gt;Downstream of the Event Log, events are processed by &lt;strong&gt;Event Handlers&lt;/strong&gt; to maintain &lt;strong&gt;Aggregates&lt;/strong&gt; of the data (for instance, a document store containing one document per Question),  or trigger &lt;strong&gt;Reactions&lt;/strong&gt; to events (e.g sending an email to a User when one of her questions was answered). Importantly, for technological reasons, this processing of events is typically &lt;strong&gt;asynchronous&lt;/strong&gt;,  with the implication that the Aggregates are at best &lt;strong&gt;eventually consistent&lt;/strong&gt; with the Log  (Aggregates &quot;lag behind&quot; the Log). &lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;img style=&quot;text-align:center;&quot; src=&quot;/img/event-sourcing-schema.png&quot; width=&quot;100%&quot;&gt; &lt;div style=&quot;text-align: center&quot;&gt;&lt;small&gt;&lt;i&gt;Event Handlers process the Event Log sequentially to maintain Aggregates&lt;/i&gt;&lt;/small&gt;&lt;/div&gt; &lt;/p&gt;&lt;p&gt;Back to our Q&amp;A example, here's what some events could look like in EDN format:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;{:event&amp;#95;type :UserCreatedQuestion
  :event&amp;#95;time #inst &amp;quot;2018-11-07T15:32:09&amp;quot;
  :user&amp;#95;id &amp;quot;jane-hacker3444&amp;quot;
  :question&amp;#95;id &amp;quot;what-is-event-sourcing-3242599&amp;quot;
  :question&amp;#95;title &amp;quot;What is Event Sourcing&amp;quot;
  :question&amp;#95;body &amp;quot;I've heard a lot about Event Sourcing but not sure what it's for exactly, could someone explain?&amp;quot;
  :question&amp;#95;tags &amp;#91;&amp;quot;Programming&amp;quot;&amp;#93;}
 ;; ...
 {:event&amp;#95;type :UserUpdatedQuestion
  :event&amp;#95;time #inst &amp;quot;2018-11-07T15:32:54&amp;quot;
  :user&amp;#95;id &amp;quot;jane-hacker3444&amp;quot;
  :question&amp;#95;id &amp;quot;what-is-event-sourcing-3242599&amp;quot;
  :question&amp;#95;title &amp;quot;What is Event Sourcing?&amp;quot;}
 ;; ...
 {:event&amp;#95;type :UserCreatedAnswer
  :event&amp;#95;time #inst&amp;quot;2018-11-08T14:16:33.825-00:00&amp;quot;
  :user&amp;#95;id &amp;quot;alice-doe32099&amp;quot;
  :question&amp;#95;id &amp;quot;what-is-event-sourcing-3242599&amp;quot;
  :answer&amp;#95;id #uuid&amp;quot;af1722d5-c9bb-4ac2-928e-cf31e77bb7fa&amp;quot;
  :answer&amp;#95;body &amp;quot;Event Sourcing is about &amp;#91;...&amp;#93;&amp;quot;}
 ;; ...
 {:event&amp;#95;type :UserVotedOnQuestion
  :event&amp;#95;time #inst&amp;quot;2018-11-08T14:19:31.855-00:00&amp;quot;
  :user&amp;#95;id &amp;quot;bob980877&amp;quot;
  :question&amp;#95;id &amp;quot;what-is-event-sourcing-3242599&amp;quot;
  :vote&amp;#95;direction :vote&amp;#95;up}&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;In this sequence of events, User &lt;code&gt;&amp;quot;jane-hacker3444&amp;quot;&lt;/code&gt; created a Question about Event Sourcing,   then updated it, presumably to correct its title. User &lt;code&gt;&amp;quot;alice-doe32099&amp;quot;&lt;/code&gt; then created an Answer  to that Question, and User &lt;code&gt;&amp;quot;bob980877&amp;quot;&lt;/code&gt; upvoted the Question.  &lt;/p&gt;&lt;p&gt;This could feed an Aggregate representing questions as JSON-like documents, such as:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;json&quot;&gt;{
  &amp;quot;question&amp;#95;id&amp;quot;: &amp;quot;what-is-event-sourcing-3242599&amp;quot;,
  &amp;quot;question&amp;#95;title&amp;quot;: &amp;quot;What is Event Sourcing?&amp;quot;,
  &amp;quot;question&amp;#95;body&amp;quot;: &amp;quot;I've heard a lot about Event Sourcing but not sure what it's for exactly, could someone explain?&amp;quot;,
  &amp;quot;question&amp;#95;tags &amp;quot;:&amp;#91;&amp;quot;Programming&amp;quot;&amp;#93;,
  &amp;quot;question&amp;#95;n&amp;#95;upvotes&amp;quot;: 1,
  &amp;quot;question&amp;#95;n&amp;#95;downvotes&amp;quot;: 0,
  &amp;quot;question&amp;#95;author&amp;quot;: {
    &amp;quot;user&amp;#95;id&amp;quot;: &amp;quot;jane-hacker3444&amp;quot;,
    &amp;quot;user&amp;#95;name&amp;quot;: &amp;quot;Jane P. Hacker&amp;quot;,
    &amp;quot;user&amp;#95;reputation&amp;quot;: 32342
  },
  &amp;quot;question&amp;#95;answers&amp;quot;: &amp;#91;{
    &amp;quot;answer&amp;#95;id&amp;quot;: &amp;quot;af1722d5-c9bb-4ac2-928e-cf31e77bb7fa&amp;quot;,
    &amp;quot;answer&amp;#95;body&amp;quot;: &amp;quot;Event Sourcing is about &amp;#91;...&amp;#93;&amp;quot;,
    &amp;quot;answer&amp;#95;author&amp;quot;: {
      &amp;quot;user&amp;#95;id&amp;quot;: &amp;quot;alice-doe32099&amp;quot;,
      &amp;quot;user&amp;#95;name&amp;quot;: &amp;quot;Alice Doe&amp;quot;,
      &amp;quot;user&amp;#95;reputation&amp;quot;: 12665
    }
  }&amp;#93;
}
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;difficulties&amp;#95;of&amp;#95;conventional&amp;#95;event&amp;#95;sourcing&quot;&gt;Difficulties of conventional Event Sourcing&lt;/h2&gt;&lt;p&gt;Regardless of the implementation technologies used (&lt;a href='https://eventstore.org'&gt;EventStore&lt;/a&gt; / &lt;a href='https://kafka.apache.org/'&gt;Kafka&lt;/a&gt; / plain old SQL...), common difficulties arise from the 'conventional Event Sourcing' approach described above. We'll try to categorize them in this section.&lt;/p&gt;&lt;h3 id=&quot;designing&amp;#95;event&amp;#95;types&amp;#95;and&amp;#95;event&amp;#95;handlers&amp;#95;is&amp;#95;hard&amp;#95;work&quot;&gt;Designing Event Types and Event Handlers is hard work&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Case study: &lt;i&gt;the many ways to update a Question&lt;/i&gt;&lt;/strong&gt; &lt;/p&gt;&lt;p&gt;&lt;i&gt;You're designing the initial version of the Q&amp;A website, and wondering what the proper Event Types should be for updating Questions. You're thinking &lt;code&gt;UserUpdatedQuestion&lt;/code&gt;, but maybe that's not granular enough? Should it be the finer-grained &lt;code&gt;UserUpdatedQuestionTitle&lt;/code&gt;? But then maybe that'd make too many Event Types to handle, and implementing the Event Handlers will take forever? Should you opt for the more general &lt;code&gt;UserUpdatedFieldOfEntity&lt;/code&gt;, but then the Log will become harder to make sense of? Also, since a Question may be changed by someone else than her author, maybe &lt;code&gt;QuestionTitleChanged&lt;/code&gt; is a better way to go... but then , how do you track that the action was caused by a User?&lt;/i&gt;  &lt;/p&gt;&lt;p&gt;&lt;i&gt;[...]&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;6 months later, the system is in production. Tom, the Key Account Manager, bursts into your office.&lt;/i&gt;   &lt;i&gt;&quot;So, there's this high-profile expert I convinced to come answer one of the popular questions, in exchange for an exceptional gift of 500 points of reputation; could you make that happen for tonight?&quot;&lt;/i&gt;  &lt;i&gt;You think for a minute. There's no Event type for exceptional changes to reputation.&lt;/i&gt;   &lt;i&gt;&quot;I'm sorry,&quot; you reply. &quot;For now it's impossible to change the reputation of a User without it coming from votes. We'd need to make a specific development.&quot;&lt;/i&gt;&lt;/p&gt;&lt;p&gt;In the good old days of the 'current state in one database' approach, all you had to do was design a suitable representation for your state space,  and then you had all the power of a query language to navigate in that space.   For example, in a relational database, you would declare a set of tables and columns, and then you had   all the power of SQL to change the data you stored.  &lt;/p&gt;&lt;p&gt;Life is not so easy with conventional Event Sourcing, because you have to anticipate every change you're going  to want to apply to your state, design an Event Type for it, and implement the Event Handlers for this Event Type.  &lt;strong&gt;Ad hoc writes&lt;/strong&gt; are especially difficult, because any new way to write calls for new code.  &lt;/p&gt;&lt;p&gt;What's more, &lt;strong&gt;naming, granularity and semantics are hard to get right&lt;/strong&gt; when designing Event Types - and you had better get that   right in the first place, because unless you rewrite your Event Log any Event Type will have to be processed by your Event Handlers  for the entire lifetime of your codebase (since re-processing the entire Log is assumed to be a frequent operation).  Too many Event Types may result in more work for implementing Event Handlers; on the other hand, coarse-grained Event Types  are less reusable.  &lt;/p&gt;&lt;p&gt;I think the lesson here is that &lt;strong&gt;an enumeration of application-defined Event Types is a weak language for describing change.&lt;/strong&gt; &lt;/p&gt;&lt;h3 id=&quot;detecting&amp;#95;indirect&amp;#95;changes&amp;#95;is&amp;#95;still&amp;#95;hard&quot;&gt;Detecting indirect changes is still hard&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Case study: &lt;i&gt;linking Question upvotes to User reputation&lt;/i&gt;&lt;/strong&gt; &lt;/p&gt;&lt;p&gt;&lt;i&gt;You're writing the Event Handler for an Aggregate that keeps track of the reputation score of each User: it's a basic key-value store that associates each &lt;code&gt;user&amp;#95;id&lt;/code&gt; to a number.&lt;/i&gt;  &lt;i&gt;In particular, each time there's an upvote on a Question, it must increment the reputation of the Question's author.&lt;/i&gt;  &lt;i&gt;The problem is, in its current form, the &lt;code&gt;UserVotedOnQuestion&lt;/code&gt; Event Type does not contain the &lt;code&gt;user&amp;#95;id&lt;/code&gt; of the Question's author, only the id of the Question...&lt;/i&gt;  &lt;/p&gt;&lt;p&gt;&lt;i&gt;What should you do?&lt;/i&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;i&gt;Should you change the &lt;code&gt;UserVotedOnQuestion&lt;/code&gt; Event Type so that it explicitly contains the id of the author? But that would be redundant, and then who knows how many more things you will want to add later to the Event Types, as you make new Aggregates?&lt;/i&gt;&lt;/li&gt;&lt;li&gt;&lt;i&gt;Should you change the Aggregate so that it also keeps track of the Question -&gt; User relationship? But that would make it more complex, and is likely to be redundant with the work of other Aggregates...&lt;/i&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;An Event Log gives you precise data about what changed between 2 points in time; but that does not mean that data is trivially actionable.  To update an Aggregate based on an Event, you need to compute if and how the Event &lt;i&gt;affects&lt;/i&gt; the Aggregate.  When dealing with a relational information model, an Event may be about some entity A and indirectly affect another Entity B,  but the relationship between A and B is not apparent in the Event; in the above example, an Event of type &lt;code&gt;UserVotedOnQuestion&lt;/code&gt;  affects a User entity without directly referencing it.  &lt;strong&gt;We need query power to determine how an Event affects the downstream Aggregates, but an Event Log on its own offers very little query power.&lt;/strong&gt;&lt;br /&gt;&lt;/p&gt;&lt;p&gt;There are several strategies to mitigate this problem, all with important caveats:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;You can 'denormalize' the Event Types to add more data to them, effectively doing some pre-computations for the Aggregates.  This means the code that produces the Events needs to anticipate all the ways in which the Events will be consumed - the sort of   coupling we're trying to get away from with Event Sourcing.&lt;/li&gt;&lt;li&gt;You can enrich each Aggregate to keep track of relational information it needs. This makes Event Handlers more complex to implement, and potentially redundant. &lt;/li&gt;&lt;li&gt;You can add an 'intermediary' Aggregate that only keeps track of relational information and produces a stream of 'enriched' Events. This is probably better than both solutions above, but it still takes work, and it still needs to be aware of the needs  of all downstream Aggregates.&lt;/li&gt;&lt;/ol&gt;&lt;h3 id=&quot;transactionality&amp;#95;is&amp;#95;difficult&amp;#95;to&amp;#95;achieve&quot;&gt;Transactionality is difficult to achieve&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Case study: &lt;i&gt;preventing double Answers&lt;/i&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;You're investigating a bug of the Q&amp;A website: some User managed to create 2 Answers to a Question, which is not supposed to happen... Indeed, when a User tries to create the Answer, the code checks via the &lt;code&gt;QuestionsById&lt;/code&gt; Aggregate that this User has not yet created an Answer to this Question, and no &lt;code&gt;UserCreatedAnswer&lt;/code&gt; Event is emitted if that check fails.&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;You then realize this is caused by a race condition: between the time the 1st Answer was added to the Log  and the time it made its way into the &lt;code&gt;QuestionsById&lt;/code&gt; Aggregate, the 2nd Answer was added, thus passing the check...&lt;/i&gt;  &lt;/p&gt;&lt;p&gt;&lt;i&gt;'Great', you think. 'I love debugging concurrency issues.'&lt;/i&gt; &lt;/p&gt;&lt;p&gt;Some programs consist only of aggregating information from various data sources, and presenting this information in a new way; analytics dashboards and accounting systems are examples of such programs. Event Sourcing is relatively easy to implement for those. But most systems can't be described so simply. When you buy something on an e-commerce website, you don't just &lt;i&gt;inform them&lt;/i&gt; that you are buying something; you &lt;i&gt;request&lt;/i&gt; them to make a purchase, and if your payment information is correct and the inventories are not exhausted, then the e-commerce &lt;i&gt;decides&lt;/i&gt; to create an order. Even basic administration features can be enough to get you out of the 'only aggregating information' realm. &lt;/p&gt;&lt;p&gt;Here we see arise the need for &lt;i&gt;transactions&lt;/i&gt;, and that's the catch: &lt;strong&gt;transactions are hardly compatible with eventually consistent writes,&lt;/strong&gt; which is what you get by default when processing the Event Log asynchronously.&lt;/p&gt;&lt;p&gt;You can mitigate this issue by having an Aggregate which is updated &lt;i&gt;synchronously&lt;/i&gt; with the Event Log.  This means adding an Event is no longer as simple as appending a data record at the end of a queue: you must  atomically do that &lt;i&gt;and&lt;/i&gt; update some queryable representation of the current state (e.g a relational database).&lt;/p&gt;&lt;p&gt;It's also important to realize that transactions are not just for &lt;i&gt;allowing&lt;/i&gt; Events into the Log, but also for &lt;i&gt;computing&lt;/i&gt; them. For instance, when you order a ticket for a show online, the ticketing system must consult the inventory and &lt;i&gt;choose&lt;/i&gt; a seat number for you (even if it's just for adding it to your cart, it must happen transactionally). Which leads us to the distinction between Commands and Events.&lt;/p&gt;&lt;h3 id=&quot;conflating&amp;#95;commands&amp;#95;and&amp;#95;events&quot;&gt;Conflating Commands and Events&lt;/h3&gt;&lt;p&gt;In conventional Event Sourcing, another common approach for addressing the transactionality issues outlined above is to add another sort of Events, which request a change without committing to it. For instance, you could add a &lt;code&gt;UserWantedToCreateAnswer&lt;/code&gt; Event, which later on will be processed by an Event Handler that will emit either a &lt;code&gt;UserCreatedAnwser&lt;/code&gt; Event or an &lt;code&gt;EventCreationWasRejected&lt;/code&gt; Event and add it to the Log; this Event Handler will of course need to maintain an Aggregate to keep track of Answer creations.&lt;/p&gt;&lt;p&gt;This approach has the advantage of freeing you from some race conditions, but it adds significant complexity. Handling events is now side-effectful and cannot be idempotent. Since those special new Events should be handled exactly once, you will have to be careful when re-processing the Log (see Martin Fowler's &lt;a href='https://martinfowler.com/eaaDev/EventSourcing.html'&gt;article on Event Sourcing&lt;/a&gt; for more details on these caveats). Finally, this means you're forcing an asynchronous workflow on the producers of these Events (as in: &lt;i&gt;&quot;Hey, thank you for submitting this form, unfortunately we have no idea if and when your request will be processed. Stay tuned!&quot;&lt;/i&gt;). &lt;/p&gt;&lt;p&gt;To me, this complexity arises from the fact that &lt;strong&gt;conventional Event Sourcing tempts you to forget the essential distinctions between Commands and Events.&lt;/strong&gt; A small refresher about these notions:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;A &lt;strong&gt;Command&lt;/strong&gt; is a &lt;i&gt;request for change&lt;/i&gt;. It's usually formulated in the imperative mood (e.g &lt;code&gt;AddItemToCart&lt;/code&gt;). You typically want them to be ephemeral and processed exactly once.&lt;/li&gt;&lt;li&gt;An &lt;strong&gt;Event&lt;/strong&gt;, as we already mentioned, &lt;i&gt;describes a change that happened&lt;/i&gt;. It's usually formulated in the past tense and indicative mood (e.g &lt;code&gt;ItemAddedToCart&lt;/code&gt;). You typically want them to be durable, and processed as many times as you like.&lt;/li&gt;&lt;li&gt;From this perspective, a transactional engine is a process which turns Commands into Events.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Commands and Events play &lt;i&gt;very&lt;/i&gt; different roles, and it's no surprise that conflating them results in complexity.&lt;/p&gt;&lt;h2 id=&quot;how&amp;#95;datomic&amp;#95;does&amp;#95;it&quot;&gt;How Datomic does it&lt;/h2&gt;&lt;h3 id=&quot;datomic's&amp;#95;model&quot;&gt;Datomic's model&lt;/h3&gt;&lt;p&gt;&lt;i&gt;(See also the &lt;a href='https://docs.datomic.com/cloud/whatis/data-model.html'&gt;official documentation&lt;/a&gt;).&lt;/i&gt;&lt;/p&gt;&lt;p&gt;Datomic models information as a collection of facts. Each fact is represented by a &lt;strong&gt;Datom:&lt;/strong&gt; a Datom is a 5-tuple &lt;code&gt;&amp;#91;entity-id attribute value transaction-id added?&amp;#93;&lt;/code&gt;, in which:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;entity-id&lt;/code&gt; is an integer identifying the entity (e.g a User or a Question) described by the fact (akin to a row number in a relational database)&lt;/li&gt;&lt;li&gt;&lt;code&gt;attribute&lt;/code&gt; could be something like &lt;code&gt;:user&amp;#95;first&amp;#95;name&lt;/code&gt; or &lt;code&gt;:question&amp;#95;author&lt;/code&gt; (akin to a column in a relational database)&lt;/li&gt;&lt;li&gt;&lt;code&gt;value&lt;/code&gt; is the 'content' of the attribute for this entity (e.g &lt;code&gt;&amp;quot;John&amp;quot;&lt;/code&gt;)&lt;/li&gt;&lt;li&gt;&lt;code&gt;transaction-id&lt;/code&gt; identifies the &lt;i&gt;transaction&lt;/i&gt; at which the datom was added (a transaction is itself an entity)&lt;/li&gt;&lt;li&gt;&lt;code&gt;added?&lt;/code&gt; is a boolean, determining if the datom is &lt;i&gt;added&lt;/i&gt; (we now know this fact) or &lt;i&gt;retracted&lt;/i&gt; (we no longer know this fact)&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;For instance, the Datom &lt;code&gt;#datom &amp;#91;42 :question&amp;#95;title &amp;quot;What is Event Sourcing&amp;quot; 213130 true&amp;#93;&lt;/code&gt; could be translated in English: &quot;We learned from Transaction 213130 that Entity 42, which is a Question, has title 'What is Event Sourcing&quot;'.&lt;/p&gt;&lt;p&gt;A Datomic &lt;strong&gt;Database Value&lt;/strong&gt; represents the state of the system at a point in time, or more accurately the &lt;i&gt;knowledge&lt;/i&gt; accumulated by the system up to a point in time. From a logical standpoint, a Database value is just a collection of Datoms. For instance, here's an extract of our Q&amp;A database:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;def db-value-extract
  &amp;#91;;; ...
   #datom &amp;#91;38 :user&amp;#95;id &amp;quot;jane-hacker3444&amp;quot; 896647 true&amp;#93;
   ;; ...
   #datom &amp;#91;234 :question&amp;#95;id &amp;quot;what-is-event-sourcing-3242599&amp;quot; 896770 true&amp;#93;
   #datom &amp;#91;234 :question&amp;#95;author 38 896770 true&amp;#93;
   #datom &amp;#91;234 :question&amp;#95;title &amp;quot;What is Event Sourcing&amp;quot; 896770 true&amp;#93;
   #datom &amp;#91;234 :question&amp;#95;body &amp;quot;I've heard a lot about Event Sourcing but not sure what it's for exactly, could someone explain?&amp;quot; 896770 true&amp;#93;
   ;;
   #datom &amp;#91;234 :question&amp;#95;title &amp;quot;What is Event Sourcing&amp;quot; 896773 false&amp;#93;
   #datom &amp;#91;234 :question&amp;#95;title &amp;quot;What is Event Sourcing?&amp;quot; 896773 true&amp;#93;
   ;; ...
   #datom &amp;#91;456 :answer&amp;#95;id #uuid&amp;quot;af1722d5-c9bb-4ac2-928e-cf31e77bb7fa&amp;quot; 896789 true&amp;#93;
   #datom &amp;#91;456 :answer&amp;#95;question 234 896789 true&amp;#93;
   #datom &amp;#91;456 :answer&amp;#95;author 43 896789 true&amp;#93;
   #datom &amp;#91;456 :answer&amp;#95;body &amp;quot;Event Sourcing is about &amp;#91;...&amp;#93;&amp;quot; 896789 true&amp;#93;
   ;; ...
   #datom &amp;#91;774 :vote&amp;#95;question 234 896823 true&amp;#93;
   #datom &amp;#91;774 :vote&amp;#95;direction :vote&amp;#95;up 896823 true&amp;#93;
   #datom &amp;#91;774 :vote&amp;#95;author 41 896823 true&amp;#93;
   ;; ...
   &amp;#93;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;In practice, a Datomic Database Value is not implemented as a basic list; it's a sophisticated data structures comprising multiple indexes, which allows for expressive and fast queries using &lt;a href='http://www.learndatalogtoday.org/'&gt;Datalog&lt;/a&gt;, a query language for relational data. But &lt;i&gt;logically&lt;/i&gt;, a Database value is just a list of datoms. Surprisingly, this very simple model allows for representing and querying data no less effectively than conventional databases (SQL / document stores / graph databases /etc.).&lt;/p&gt;&lt;p&gt;A Datomic deployment is a succession of (growing) Database Values. Writing to Datomic consists of submitting a &lt;strong&gt;Transaction Request&lt;/strong&gt; (a data structure representing the change that we want applied); this Transaction Request gets applied to the current Database value, which consists of computing a set of Datoms to add to it (a &lt;strong&gt;Transaction&lt;/strong&gt;), thus yielding the next Database Value.&lt;/p&gt;&lt;p&gt;For instance, a Transaction Request for changing the title of a Question could look like this:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;def tx-request-changing-question-title
  &amp;#91;&amp;#91;:db/add &amp;#91;:question&amp;#95;id &amp;quot;what-is-event-sourcing-3242599&amp;quot;&amp;#93; :question&amp;#95;title &amp;quot;What is Event Sourcing?&amp;quot;&amp;#93;&amp;#93;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This would result in a Transaction, where we recognize some Datoms of &lt;code&gt;db-value-extract&lt;/code&gt; above:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;comment &amp;quot;Writing to Datomic&amp;quot;
  @&amp;#40;d/transact conn tx-request-changing-question-title&amp;#41;
  =&amp;gt; {:db-before datomic.Db @3414ae14                       ;; the Database Value to which the Transaction Request was applied
      :db-after datomic.Db @329932cd                        ;; the resulting next Database Value
      :tx-data                                              ;; the Datoms that were added by the Transaction
      &amp;#91;#datom &amp;#91;234 :question&amp;#95;title &amp;quot;What is Event Sourcing&amp;quot; 896773 false&amp;#93;
       #datom &amp;#91;234 :question&amp;#95;title &amp;quot;What is Event Sourcing?&amp;quot; 896773 true&amp;#93;
       #datom &amp;#91;896773 :db/txInstant #inst &amp;quot;2018-11-07T15:32:54&amp;quot; 896773 true&amp;#93;&amp;#93;}
  &amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Now we start to see the deep similarities between Datomic and the Event Sourcing notions we've laid out so far:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Transaction Requests correspond to Commands&lt;/li&gt;&lt;li&gt;Transactions correspond to Events&lt;/li&gt;&lt;li&gt;a Datomic database corresponds to an Event Log&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;We also see some important differences:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Events consist of a combination of fine-grained Datoms; there is no Event Type with a prescribed structure.&lt;/li&gt;&lt;li&gt;Events are directly not produced by application code; Transaction Requests (Commands) are.&lt;/li&gt;&lt;/ul&gt;&lt;h3 id=&quot;processing&amp;#95;events&amp;#95;with&amp;#95;datomic&quot;&gt;Processing Events with Datomic&lt;/h3&gt;&lt;p&gt;We'll now study how we can implement an Event Sourcing system with Datomic.&lt;/p&gt;&lt;p&gt;First, let's note that &lt;strong&gt;a Datomic Database Value can be viewed as an Aggregate; one that is maintained synchronously with no extra effort, contains all of the data stored in Events, and can be queried expressively.&lt;/strong&gt; This Aggregate will probably cover most of your querying needs; from what I've seen, the most likely use cases for adding downstream Aggregates are search, low-latency aggregations, and data exports.&lt;/p&gt;&lt;p&gt;It's also worth noting that you can obtain any past value of a Datomic Database, and so you can reproduce a past state out-of-the-box - no need to re-process the entire Log:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;def db-at-last-xmas 
  &amp;#40;d/as-of db #inst &amp;quot;2017-12-25&amp;quot;&amp;#41;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;You can use the &lt;a href='https://docs.datomic.com/on-prem/log.html'&gt;Log API&lt;/a&gt; to get the Transactions between 2 points in time:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;comment &amp;quot;Reading the changes between t1 and t2 as a sequence of Transactions:&amp;quot;
  &amp;#40;d/tx-range &amp;#40;d/log conn&amp;#41; t0 t1&amp;#41;
  =&amp;gt; &amp;#91;{:tx-data &amp;#91;#datom &amp;#91;234 :question&amp;#95;id &amp;quot;what-is-event-sourcing-3242599&amp;quot; 896770 true&amp;#93;
                 #datom &amp;#91;234 :question&amp;#95;author 38 896770 true&amp;#93;
                 #datom &amp;#91;234 :question&amp;#95;title &amp;quot;What is Event Sourcing&amp;quot; 896770 true&amp;#93;
                 #datom &amp;#91;234 :question&amp;#95;body &amp;quot;I've heard a lot about Event Sourcing but not sure what it's for exactly, could someone explain?&amp;quot; 896770 true&amp;#93;
                 #datom &amp;#91;896770 :db/txInstant #inst &amp;quot;2018-11-07T15:32:09&amp;quot;&amp;#93;&amp;#93;}
      ;; ...
      {:tx-data &amp;#91;#datom &amp;#91;234 :question&amp;#95;title &amp;quot;What is Event Sourcing&amp;quot; 896773 false&amp;#93;
                 #datom &amp;#91;234 :question&amp;#95;title &amp;quot;What is Event Sourcing?&amp;quot; 896773 true&amp;#93;
                 #datom &amp;#91;896773 :db/txInstant #inst &amp;quot;2018-11-07T15:32:54&amp;quot;&amp;#93;&amp;#93;}
      ;; ...
      {:tx-data &amp;#91;#datom &amp;#91;456 :answer&amp;#95;id #uuid&amp;quot;af1722d5-c9bb-4ac2-928e-cf31e77bb7fa&amp;quot; 896789 true&amp;#93;
                 #datom &amp;#91;456 :answer&amp;#95;question 234 896789 true&amp;#93;
                 #datom &amp;#91;456 :answer&amp;#95;author 43 896789 true&amp;#93;
                 #datom &amp;#91;456 :answer&amp;#95;body &amp;quot;Event Sourcing is about &amp;#91;...&amp;#93;&amp;quot; 896789 true&amp;#93;
                 #datom &amp;#91;896789 :db/txInstant #inst&amp;quot;2018-11-08T14:16:33.825-00:00&amp;quot;&amp;#93;&amp;#93;}
      ;; ...
      {:tx-data &amp;#91;#datom &amp;#91;774 :vote&amp;#95;question 234 896823 true&amp;#93;
                 #datom &amp;#91;774 :vote&amp;#95;direction :vote&amp;#95;up 896823 true&amp;#93;
                 #datom &amp;#91;774 :vote&amp;#95;author 41 896823 true&amp;#93;
                 #datom &amp;#91;896823 :db/txInstant #inst&amp;quot;2018-11-08T14:19:31.855-00:00&amp;quot;&amp;#93;&amp;#93;}&amp;#93;
  &amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Notice that, although they describe change in a very minimal form, &lt;strong&gt;Transactions can be combined with Database Values to compute the effect of a change in a straightforward way.&lt;/strong&gt;  You don't need to 'enrich' your Events to make them easier to process; they are &lt;i&gt;already&lt;/i&gt; enriched with entire Database Values.&lt;/p&gt;&lt;p&gt;&lt;div style=&quot;text-align:center;&quot;&gt;&lt;img src=&quot;/img/chess-both-incremental-and-absolute.png&quot; width=&quot;100%&quot;&gt; &lt;small&gt;&lt;i&gt;The best of both worlds: you get both absolute and incremental views of the state at each transition.&lt;/i&gt;&lt;/small&gt;&lt;/div&gt;&lt;/p&gt;&lt;p&gt;For instance, here's a query that determines which Users must have their reputation re-computed because of Votes:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;comment &amp;quot;Computes a set of Users whose reputation may have been affected by Votes&amp;quot;
  &amp;#40;d/q '&amp;#91;:find &amp;#91;?user-id ...&amp;#93;
         :in $ ?log ?t1 ?t2                                 ;; query inputs
         :where
         &amp;#91;&amp;#40;tx-ids ?log ?t1 ?t2&amp;#41; &amp;#91;?tx ...&amp;#93;&amp;#93;                  ;; reading the Transactions
         &amp;#91;&amp;#40;tx-data ?log ?tx&amp;#41; &amp;#91;&amp;#91;?vote ?a ?v &amp;#95; ?op&amp;#93;&amp;#93;&amp;#93;         ;; reading the Datoms
         &amp;#91;?vote :vote&amp;#95;question ?q&amp;#93;                          ;; navigating from Votes to Questions
         &amp;#91;?q :question&amp;#95;author ?user&amp;#93;                        ;; navigating from Questions to Users
         &amp;#91;?user :user&amp;#95;id ?user-id&amp;#93;&amp;#93;
    db &amp;#40;d/log conn&amp;#41; t1 t2&amp;#41;
  =&amp;gt; &amp;#91;&amp;quot;jane-hacker3444&amp;quot;
      &amp;quot;john-doe12232&amp;quot;
      ;; ...
      &amp;#93;
  ;; Now it will be easy to update our 'UserReputation' Aggregate
  ;; by re-computing the reputation of this &amp;#40;probably small&amp;#41; set of Users.
  &amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;When it comes to change detection, the basic approach described in the above example gets you surprisingly far. However, sometimes, you don't just want to know what changed: you want to know &lt;i&gt;why&lt;/i&gt; or &lt;i&gt;how&lt;/i&gt; it changed. For instance:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;you may want to keep track of what User caused the change&lt;/li&gt;&lt;li&gt;you may want to know from what UI action the change originated&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;The recommended way to do that with Datomic is using &lt;a href='https://docs.datomic.com/cloud/transactions/transaction-processing.html#reified-transactions'&gt;Reified Transactions&lt;/a&gt;: Datomic Transactions being Entities themselves, you can add facts about them. For example:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;comment &amp;quot;Annotating the Transaction&amp;quot;
  @&amp;#40;d/transact conn
     &amp;#91;;; Fact about the Question
      &amp;#91;:db/add &amp;#91;:question&amp;#95;id &amp;quot;what-is-event-sourcing-3242599&amp;quot;&amp;#93; :question&amp;#95;title &amp;quot;What is Event Sourcing?&amp;quot;&amp;#93;
      ;; Facts about the Transaction
      &amp;#91;:db/add &amp;quot;datomic.tx&amp;quot; :transaction&amp;#95;done&amp;#95;by&amp;#95;user &amp;#91;:user&amp;#95;id &amp;quot;jane-hacker3444&amp;quot;&amp;#93;&amp;#93;
      &amp;#91;:db/add &amp;quot;datomic.tx&amp;quot; :transaction&amp;#95;done&amp;#95;via&amp;#95;ui&amp;#95;action :UserEditedQuestion&amp;#93;&amp;#93;&amp;#41;
  =&amp;gt; {:db-before datomic.Db@3414ae14
      :db-after datomic.Db@329932cd
      :tx-data
      &amp;#91;#datom &amp;#91;234 :question&amp;#95;title &amp;quot;What is Event Sourcing&amp;quot; 896773 false&amp;#93;
       #datom &amp;#91;234 :question&amp;#95;title &amp;quot;What is Event Sourcing?&amp;quot; 896773 true&amp;#93;
       #datom &amp;#91;896773 :db/txInstant #inst &amp;quot;2018-11-07T15:32:54&amp;quot; 896773 true&amp;#93;
       #datom &amp;#91;896773 :transaction&amp;#95;done&amp;#95;by&amp;#95;user 38 896773 true&amp;#93;
       #datom &amp;#91;896773 :transaction&amp;#95;done&amp;#95;via&amp;#95;ui&amp;#95;action :UserEditedQuestion 896773 true&amp;#93;&amp;#93;}
  &amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;cost-benefit&amp;#95;analysis&quot;&gt;Cost-benefit analysis&lt;/h3&gt;&lt;p&gt;Whether or not the usage of Datomic we described is 'true Event Sourcing' depends on your definition of Event Sourcing; but what's more important in my opinion is whether or not we get the benefits, and at what cost.&lt;/p&gt;&lt;p&gt;So let's revisit the objectives and common difficulties of Event Sourcing that we described above. &lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; &lt;strong&gt;Do we get the benefits of Event Sourcing?&lt;/strong&gt; &lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;Yes:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;All state transitions are described in a Log of Events (accessible by Datomic's Log API)&lt;/li&gt;&lt;li&gt;We have a high query power (Datalog) to consume that Log of Events and derive Aggregates from it&lt;/li&gt;&lt;li&gt;We get a rich default Aggregate (Datomic database values) for free, with which we can reproduce past states out-of-the-box (&lt;code&gt;db.asOf&amp;#40;t&amp;#41;&lt;/code&gt;).&lt;/li&gt;&lt;/ul&gt;&lt;blockquote&gt;&lt;p&gt; &lt;strong&gt;Do we still have the difficulties of conventional Event Sourcing?&lt;/strong&gt; &lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;Well, let's see:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;'Designing Event Types and Event Handlers is hard':&lt;/strong&gt; we don't design Event Types any more; we design only our database schema (which tends to map naturally to our domain model), and Datomic will do the work of describing changes in terms of Datoms, which can be handled generically. For the few cases where that description is not enough, we can extend it using Reified Transactions. Regarding Event Handlers, a lot of them are no longer needed because we have a good enough default Aggregate (Database Values).&lt;/li&gt;&lt;li&gt;&lt;strong&gt;'Detecting indirect changes is hard':&lt;/strong&gt; it's now straightforward to compute the effects of each change on downstream Aggregates, since we have both incremental and global views of each state transition (Transactions and Database Values) with high query power.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;'Transactionality is hard to achieve':&lt;/strong&gt; no issues there, Datomic is fully ACID with an expressive language for writes.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;'Conflating Commands and Events':&lt;/strong&gt; there's not really room for confusion here - Datomic does not let us even emit Events, we can only write with Commands.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Of course, &lt;strong&gt;Datomic has limitations,&lt;/strong&gt; and to get those benefits you have to make sure these limitations are not prohibitive for your use case:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Write scale:&lt;/strong&gt; Don't expect to make tens of thousands of writes per seconds on one Datomic system. (Read scale is okay. Datomic scales horizontally for reads, and hopefully this article has made it clear that it's easy to offload reads to specialized stores.)&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Dataset size:&lt;/strong&gt; If you need to store petabytes of data, you will need to either complement or replace Datomic with something else.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Data model:&lt;/strong&gt; You data must lend itself well to being represented in Datomic. Datomic's &lt;a href='https://docs.datomic.com/cloud/whatis/data-model.html#universal'&gt;Universal Schema&lt;/a&gt;, inspired by &lt;a href='https://www.w3.org/RDF/'&gt;RDF&lt;/a&gt;, is good at modeling what you would store in table, document or graph-oriented databases, but with some imagination you could probably come up with something that's hard to represent in Datomic. (By the way, contrary to popular belief, Datomic is not &lt;a href='https://vvvvalvalval.github.io/posts/2017-07-08-Datomic-this-is-not-the-history-youre-looking-for.html'&gt;especially good&lt;/a&gt; at representing historical data.)&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Infrastructure:&lt;/strong&gt; Datomic is good for running on big server machines, typically in the Cloud - not on mobile devices or embedded systems.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Proprietary:&lt;/strong&gt; Datomic is not open-source, for some people that's a dealbreaker.&lt;/li&gt;&lt;/ul&gt;&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;&lt;p&gt;In addition to the Log of changes, Datomic provides a queriable snapshot (a ‘state’) of the entire database yielded by each change, all of this being directed by transactional writes. &lt;strong&gt;This is a significant technological feat, which explains why we can reap the benefits of Event Sourcing with much less effort and limitations than with conventional Event Sourcing implementations.&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;In more traditional CQRS parlance: Datomic gives you all in synchrony an expressive Command language (Datomic transaction requests), actionable Events (transactions as sets of added Datoms) and a powerful, relational default Aggregate (Datomic database values).&lt;/p&gt;&lt;p&gt;Hopefully this shows that &lt;strong&gt;Event Sourcing does not have to be as demanding as we've got accustomed to,&lt;/strong&gt; so long as we're willing to rethink a bit our assumptions of how it should be implemented.&lt;/p&gt;&lt;p&gt;Finally, I should mention that this article offers a very &lt;i&gt;narrow&lt;/i&gt; view of Datomic. There is &lt;a href='https://augustl.com/blog/2018/datomic_look_at_all_the_things_i_am_not_doing/'&gt;more&lt;/a&gt; to Datomic than just being good at Event Sourcing! (The development workflow, the testing story, the composable writes, the flexible schema, the operational aspects...)&lt;/p&gt;&lt;p&gt;I've been overly politically correct in this entire article, and that must be pretty boring,  so I'll leave you with this snarky provocative phrase:&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; &lt;i&gt;Any sufficiently advanced conventional Event Sourcing system contains an ad-hoc, informally-specified, bug-ridden, slow implementation of half Datomic.&lt;/i&gt; &lt;/p&gt;&lt;/blockquote&gt;&lt;h2 id=&quot;see&amp;#95;also&quot;&gt;See also&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;&lt;a href='https://martinfowler.com/eaaDev/EventSourcing.html'&gt;Event Sourcing&lt;/a&gt;: by Martin Fowler.&lt;/li&gt;&lt;li&gt;&lt;a href='https://eventstore.org/docs/event-sourcing-basics/index.html'&gt;Event Sourcing basics&lt;/a&gt; from the documentation of EventStore.&lt;/li&gt;&lt;li&gt;&lt;a href='https://kickstarter.engineering/event-sourcing-made-simple-4a2625113224'&gt;Event Sourcing made simple&lt;/a&gt;: an explanation and experience report of Event Sourcing by Kickstarter engineering.&lt;/li&gt;&lt;li&gt;&lt;a href='https://www.youtube.com/watch?v=Cym4TZwTCNU'&gt;Deconstructing the database&lt;/a&gt; by Rich Hickey, creator of Datomic.&lt;/li&gt;&lt;li&gt;&lt;a href='https://martin.kleppmann.com/2018/10/17/kafka-summit.html'&gt;Is Kafka a database?&lt;/a&gt; a talk by Martin Kleppmann.&lt;/li&gt;&lt;li&gt;&lt;a href='https://fr.slideshare.net/ThomasPierrain/as-time-goes-by-episode-2'&gt;As time goes by, episode 2: technical challenges of bi-temporal Event Sourcing&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;EDIT:&lt;/strong&gt; this article has been discussed on &lt;a href='https://news.ycombinator.com/item?id=18431382'&gt;Hacker News&lt;/a&gt;, &lt;a href='https://www.reddit.com/r/programming/comments/9wc8lv/datomic_event_sourcing_without_the_hassle/'&gt;r/programming&lt;/a&gt; and the &lt;a href='https://groups.google.com/d/topic/dddcqrs/x-4jHq7nA5g/discussion'&gt;DDD/CQRS mailing list&lt;/a&gt;.&lt;/p&gt;
</description>
<pubDate>
Mon, 12 Nov 2018 00:00:00 +0100
</pubDate>
</item>
<item>
<guid>
http://vvvvalvalval.github.io/posts/2018-07-23-datascript-as-a-lingua-franca-for-domain-modeling.html
</guid>
<link>
http://vvvvalvalval.github.io/posts/2018-07-23-datascript-as-a-lingua-franca-for-domain-modeling.html
</link>
<title>
DataScript as a Lingua Franca for domain modeling
</title>
<description>
 &lt;p&gt;  &lt;img src=&quot;/img/domain-representation-to-machine-execution-with-refinement.png&quot; width=&quot;100%&quot;&gt;&lt;/img&gt;  &lt;/p&gt;&lt;p&gt;This post discusses an approach to application architecture using &lt;a href='https://github.com/tonsky/datascript'&gt;DataScript&lt;/a&gt;  (an in-memory graph database, cf &lt;a href='#annex:_a_datascript_refresher'&gt;the annex&lt;/a&gt;).  The idea is simply to store metadata representing the &lt;i&gt;Domain Model&lt;/i&gt; of the application  in a DataScript database, and automatically derive the 'machine' aspects of the system   from that metadata.  &lt;/p&gt;&lt;p&gt;If this is enough to give you inspiration for solving your own problems, my main goal for this article is already achieved.  Read on for a more detailed discussion of how, why and when to apply this approach.&lt;/p&gt;&lt;h2 id=&quot;the&amp;#95;approach&quot;&gt;The approach&lt;/h2&gt;&lt;h3 id=&quot;the&amp;#95;domain&amp;#95;model&quot;&gt;The Domain Model&lt;/h3&gt;&lt;p&gt;Every application has some notion of a &lt;i&gt;&lt;a href='https://en.wikipedia.org/wiki/Domain_model'&gt;Domain Model&lt;/a&gt;&lt;/i&gt;,  a system of abstractions and rules describing the reality that the system is meant to address.  Domain Models can take many forms, but in this article what I'm calling the &lt;i&gt;Domain Model&lt;/i&gt; is essentially  what we put in a UML diagram representing a data schema. &lt;/p&gt;&lt;p&gt;As an example, imagine we're developing a tiny Twitter clone named &lt;i&gt;Twitteur&lt;/i&gt;;  we may represent our Domain Model for Twitteur like so:&lt;/p&gt;&lt;p&gt;  &lt;img src=&quot;/img/twitteur-domain-model.png&quot; width=&quot;100%&quot;&gt;&lt;/img&gt;&lt;/p&gt;&lt;p&gt;Very typical stuff: we've defined a couple of Entity types (&lt;code&gt;User&lt;/code&gt; and &lt;code&gt;Tweet&lt;/code&gt;),   each containing a few attributes, each attribute being annotated with a datatypes  and various modifier, for instance:  &lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;user/email&lt;/code&gt; is marked as &lt;i&gt;private&lt;/i&gt;, which is in this case a security concern: it should not be publicly visible to users of the application.&lt;/li&gt;&lt;li&gt;&lt;code&gt;user/n&amp;#95;followers&lt;/code&gt; is in a light color to signify that it's &lt;i&gt;derived&lt;/i&gt;, i.e computed from other attributes.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;There is not enough information here to extract the nifty-gritty details of how the system  should work; but it gives us an important overview of the domain concepts and rules   underlying the system. &lt;/p&gt;&lt;p&gt;This Domain Model is quite small to keep the article readable, but you have to imagine   the approach we're discussing here applied to dozens of Entity types and hundreds of attributes.  &lt;/p&gt;&lt;h3 id=&quot;the&amp;#95;'machine&amp;#95;aspects'&quot;&gt;The 'Machine Aspects'&lt;/h3&gt;&lt;p&gt;In application code, this Domain Model will typically be apparent in many different 'mechanical' aspects of  our application, for instance:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Database schema (SQL tables, &lt;a href='https://www.datomic.com/'&gt;Datomic&lt;/a&gt; attributes, &lt;a href='https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping.html'&gt;ElasticSearch&lt;/a&gt; Mapping Types, etc.)&lt;/li&gt;&lt;li&gt;Database queries&lt;/li&gt;&lt;li&gt;API contracts (&lt;a href='https://graphql.org/'&gt;GraphQL&lt;/a&gt; schema, &lt;a href='https://www.openapis.org/about'&gt;OpenAPI&lt;/a&gt; specification for REST APIs, etc.)&lt;/li&gt;&lt;li&gt;Data validation / representation / packaging / transformation&lt;/li&gt;&lt;li&gt;Enforcement of security rules&lt;/li&gt;&lt;li&gt;Test data generation&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;That's what we call the 'machine aspects' of the system.   In most systems, the code for these machine aspects has an (often implicit) dependency in the Domain Model:  bits of the Domain Model are hardcoded in the middle of the 'Machine Aspects' code.  Today, we're talking about doing something different: making the 'Machine-Aspects' code domain-agnostic,  and &lt;i&gt;parameterizing&lt;/i&gt; it with a representation of the Domain Model.   &lt;/p&gt;&lt;h3 id=&quot;the&amp;#95;problem&quot;&gt;The problem&lt;/h3&gt;&lt;p&gt;As I was growing a relatively large Clojure application over the course of several years,  I noticed that adding any features resulted in a lot of redundancy, which required discipline  to do right. For instance, adding a single Attribute required changes to Datomic schema installation  transactions &lt;i&gt;and&lt;/i&gt; to a GraphQL Field &lt;i&gt;and&lt;/i&gt; to data validation schemas &lt;i&gt;and&lt;/i&gt; to security rules etc.  Forgetting to make any one of these changes would result in bugs, and was an easy error to make   as these various aspects were neither colocated nor explicitly related in code. &lt;br /&gt;&lt;/p&gt;&lt;p&gt;This redundancy created more important problems than just increased volume of code:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;over-specificity:&lt;/strong&gt; the same mechanical patterns got repeated again and again, resulting in a large surface area for bugs to appear (and therefore a large surface area to write tests for).&lt;/li&gt;&lt;li&gt;&lt;strong&gt;implicit, scattered domain logic:&lt;/strong&gt; when reading code, the core domain logic had essentially to be reverse-engineered from bits of mechanical code spread in several places in the codebase.&lt;/li&gt;&lt;/ul&gt;&lt;h3 id=&quot;from&amp;#95;domain&amp;#95;representation&amp;#95;to&amp;#95;machine&amp;#95;execution&quot;&gt;From domain representation to machine execution&lt;/h3&gt;&lt;p&gt;So the idea I'm presenting here is simple:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;represent our Domain Model declaratively, as an in-program data structure (a &lt;i&gt;'meta-database'&lt;/i&gt;).&lt;/li&gt;&lt;li&gt;derive the 'machine' behaviour &lt;i&gt;generically&lt;/i&gt; from this representation.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;This means that your code will tend to be split in 2 parts - a declarative part specific to your domain,   and a generic part implementing your system's machinery. &lt;/p&gt;&lt;p&gt;Your first instinct to implement step 1 may be to represent the Domain Model with common associative data structures: maps, lists, sets, etc.   The problem with these is that you may have a hard time implementing step 2: you will need to query and navigate the   Domain Model representation in non-trivial ways, to which the tree structure resulting from using maps and lists is not well suited.  As we've seen in the UML diagram above, our Domain Model is more graph-like than tree-like.&lt;/p&gt;&lt;p&gt;Which brings me to the second point of this article:  &lt;strong&gt;if you're going to have an in-program representation of the Domain Model, you might as well use DataScript as the supporting data structure (and API).&lt;/strong&gt;&lt;/p&gt;&lt;h3 id=&quot;enter&amp;#95;datascript&quot;&gt;Enter DataScript&lt;/h3&gt;  &lt;br /&gt;&lt;p&gt;&lt;a href='https://github.com/tonsky/datascript'&gt;DataScript&lt;/a&gt; is an in-memory database / data-structure, available as a library   on the JVM or JavaScript, which takes inspiration from the &lt;a href='https://www.datomic.com/'&gt;Datomic&lt;/a&gt; database.  DataScript has many interesting characteristics, but here are the one that are relevant for this discussion:  &lt;/p&gt;&lt;ul&gt;&lt;li&gt;A &lt;strong&gt;flexible, graph-structured data model:&lt;/strong&gt; the databased is logically made of a set of facts about entities (Entity-Attribute-Value triples), which naturally form a graph. Very little about the structure of that graph needs to be declared upfront; it doesn't have the rigid,  statically-defined characteristics of tables in relational databases.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Powerful read APIs:&lt;/strong&gt; you can query a DataScript database using either &lt;i&gt;&lt;a href='http://www.learndatalogtoday.org/'&gt;Datalog&lt;/a&gt;&lt;/i&gt; (a declarative, logic-based query language, which expresses query clauses as pattern matching, as expressive as SQL), the &lt;i&gt;&lt;a href='https://docs.datomic.com/on-prem/entities.html'&gt;Entity API&lt;/a&gt;&lt;/i&gt; (navigation through the database graph via a map-like interface) or the &lt;i&gt;&lt;a href='https://docs.datomic.com/on-prem/pull.html'&gt;Pull API&lt;/a&gt;&lt;/i&gt;  (pulling trees of data out of the database graph, similarly to &lt;a href='https://graphql.org/'&gt;GraphQL&lt;/a&gt;) - or any composition of those!&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Composable writes,&lt;/strong&gt; expressed &lt;strong&gt;as ordinary data structures:&lt;/strong&gt; write requests are expressed with lists and maps (not text like SQL), and it's very easy to make sophisticated writes out of simple ones specified independently, thanks to features like temporary ids and upserts which automatically bring together the pieces of the puzzle.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;See &lt;a href='#annex:_a_datascript_refresher'&gt;the annex&lt;/a&gt; to get a quick tour of DataScript.&lt;/p&gt;&lt;p&gt;DataScript is commonly used to hold data in client-side applications, typically as part of a data-synchronization mechanism.  What we're doing here is very different: we using it to hold &lt;i&gt;meta&lt;/i&gt;-data about our Domain Model. Here's how it goes:  &lt;/p&gt;&lt;ol&gt;&lt;li&gt;We declare assertions about our Domain Model as DataScript writes (so, just data structures).&lt;/li&gt;&lt;li&gt;We merge these Domain Model assertions into a DataScript database.&lt;/li&gt;&lt;li&gt;We query this DataScript database to generate various system components (the 'machine aspects' mentioned above) - and also to inspect our Domain Model representation for day-to-day development.  &lt;/li&gt;&lt;/ol&gt;&lt;p&gt;  &lt;img src=&quot;/img/domain-representation-to-machine-execution.png&quot; width=&quot;100%&quot;&gt;&lt;/img&gt;&lt;/p&gt;&lt;p&gt;Our &lt;i&gt;Domain Model Assertions&lt;/i&gt; may look like this:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;;;;; Model meta-data
;; These 2 values are DataScript Transaction Requests, i.e data structures defining writes to a DataScript database
;; NOTE in a real-world codebase, these 2 would typically live in different files.

&amp;#40;def user-model
  &amp;#91;{:twitteur.entity-type/name :twitteur/User
    :twitteur.schema/doc &amp;quot;a User is a person who has signed up to Twitteur.&amp;quot;
    :twitteur.entity-type/attributes
    &amp;#91;{:twitteur.attribute/name :user/id
      :twitteur.schema/doc &amp;quot;The unique ID of this user.&amp;quot;
      :twitteur.attribute/ref-typed? false
      :twitteur.attribute.scalar/type :uuid
      :twitteur.attribute/unique-identity true}
     {:twitteur.attribute/name :user/email
      :twitteur.schema/doc &amp;quot;The email address of this user &amp;#40;not visible to other users&amp;#41;.&amp;quot;
      :twitteur.attribute/ref-typed? false
      :twitteur.attribute.scalar/type :string
      :twitteur.attribute.security/private? true}                    ;; here's a domain-specific security rule
     {:twitteur.attribute/name :user/name
      :twitteur.schema/doc &amp;quot;The public name of this user on Twitteur.&amp;quot;
      :twitteur.attribute/ref-typed? false
      :twitteur.attribute.scalar/type :string}
     {:twitteur.attribute/name :user/follows
      :twitteur.schema/doc &amp;quot;The Twitteur users whom this user follows.&amp;quot;
      :twitteur.attribute/ref-typed? true                            ;; this attribute is a reference-typed
      :twitteur.attribute.ref-typed/many? true
      :twitteur.attribute.ref-typed/type {:twitteur.entity-type/name :twitteur/User}}
     {:twitteur.attribute/name :user/n&amp;#95;followers
      :twitteur.schema/doc &amp;quot;How many users follow this user.&amp;quot;
      :twitteur.attribute/ref-typed? false
      :twitteur.attribute.ref-typed/many? true
      :twitteur.attribute.scalar/type :long
      :twitteur.attribute/derived? true}                             ;; this attribute is not stored in DB
     {:twitteur.attribute/name :user/tweets
      :twitteur.schema/doc &amp;quot;The tweets posted by this user.&amp;quot;
      :twitteur.attribute/ref-typed? true
      :twitteur.attribute.ref-typed/many? true
      :twitteur.attribute.ref-typed/type {:twitteur.entity-type/name :twitteur/Tweet}
      :twitteur.attribute/derived? true}
     &amp;#93;}&amp;#93;&amp;#41;

&amp;#40;def tweet-model
  ;; NOTE: to demonstrate the flexibility of DataScript, we choose a different but equivalent data layout
  ;; in this one, we define the Entity Type and the Attributes separately
  &amp;#91;;; Entity Type
   {:twitteur.entity-type/name :twitteur/Tweet
    :twitteur.schema/doc &amp;quot;a Tweet is a short message posted by a User on Twitteur, published to all her Followers.&amp;quot;
    :twitteur.entity-type/attributes
    &amp;#91;{:twitteur.attribute/name :tweet/id}
     {:twitteur.attribute/name :tweet/content}
     {:twitteur.attribute/name :tweet/author}
     {:twitteur.attribute/name :tweet/time}&amp;#93;}
   ;; Attributes
   {:twitteur.attribute/name :tweet/id
    :twitteur.schema/doc &amp;quot;The unique ID of this Tweet&amp;quot;
    :twitteur.attribute/ref-typed? false
    :twitteur.attribute.scalar/type :uuid
    :twitteur.attribute/unique-identity true}
   {:twitteur.attribute/name :tweet/content
    :twitteur.schema/doc &amp;quot;The textual message of this Tweet&amp;quot;
    :twitteur.attribute/ref-typed? false
    :twitteur.attribute.scalar/type :string}
   {:twitteur.attribute/name :tweet/author
    :twitteur.schema/doc &amp;quot;The Twitteur user who wrote this Tweet.&amp;quot;
    :twitteur.attribute/ref-typed? true
    :twitteur.attribute.ref-typed/many? false
    :twitteur.attribute.ref-typed/type {:twitteur.entity-type/name :twitteur/User}}
   {:twitteur.attribute/name :tweet/time
    :twitteur.schema/doc &amp;quot;The time at which this Tweet was published, as a timestamp.&amp;quot;
    :twitteur.attribute/ref-typed? false
    :twitteur.attribute.scalar/type :long}&amp;#93;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;As you see, these are just data structures, and you have a lot of flexibility in the shape and locations to define them.&lt;/p&gt;&lt;p&gt;Now, here's how you would merge them into a DataScript database:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;;;;; Writing this metadata to a DataScript db
&amp;#40;require '&amp;#91;datascript.core :as dt&amp;#93;&amp;#41;

&amp;#40;def meta-schema
  {:twitteur.entity-type/name {:db/unique :db.unique/identity}
   :twitteur.entity-type/attributes {:db/valueType :db.type/ref
                                     :db/cardinality :db.cardinality/many}
   :twitteur.attribute/name {:db/unique :db.unique/identity}
   :twitteur.attribute.ref-typed/type {:db/valueType :db.type/ref
                                       :db/cardinality :db.cardinality/one}}&amp;#41;

&amp;#40;defn empty-model-db
  &amp;#91;&amp;#93;
  &amp;#40;let &amp;#91;conn &amp;#40;dt/create-conn meta-schema&amp;#41;&amp;#93;
    &amp;#40;dt/db conn&amp;#41;&amp;#41;&amp;#41;

&amp;#40;def model-db
  &amp;quot;A DataScript database value, holding a representation of our Domain Model.&amp;quot;
  &amp;#40;dt/db-with
    &amp;#40;empty-model-db&amp;#41;
    ;; Composing DataScript transactions is as simple as that: concat
    &amp;#40;concat
      user-model
      tweet-model&amp;#41;&amp;#41;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;  &lt;br /&gt;&lt;p&gt;We can now leverage all the power of DataScript to query our Domain Model, which makes it much easier to generate   the 'machine-aspects' system components we need. Here's an example REPL session demonstrating this sort of queries:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;;;;; Let's query this a bit
&amp;#40;comment
  ;; What are all the attributes names in our Domain Model ?
  &amp;#40;sort
    &amp;#40;dt/q
      '&amp;#91;:find &amp;#91;?attrName ...&amp;#93; :where
        &amp;#91;?attr :twitteur.attribute/name ?attrName&amp;#93;&amp;#93;
      model-db&amp;#41;&amp;#41;
  =&amp;gt; &amp;#40;:tweet/author :tweet/content :tweet/id :tweet/time :user/email :user/follows :user/id :user/n&amp;#95;followers :user/name&amp;#41;

  ;; What do we know about :tweet/author?
  &amp;#40;def tweet-author-attr
    &amp;#40;dt/entity model-db &amp;#91;:twitteur.attribute/name :tweet/author&amp;#93;&amp;#41;&amp;#41;

  tweet-author-attr
  =&amp;gt; {:db/id 10}

  &amp;#40;dt/touch tweet-author-attr&amp;#41;
  =&amp;gt;
  {:twitteur.schema/doc &amp;quot;The Twitteur user who wrote this Tweet.&amp;quot;,
   :twitteur.attribute/name :tweet/author,
   :twitteur.attribute/ref-typed? true,
   :twitteur.attribute.ref-typed/many? false,
   :twitteur.attribute.ref-typed/type {:db/id 1},
   :db/id 10}

  &amp;#40;-&amp;gt; tweet-author-attr :twitteur.attribute.ref-typed/type dt/touch&amp;#41;
  =&amp;gt;
  {:twitteur.schema/doc &amp;quot;a User is a person who has signed up to Twitteur.&amp;quot;,
   :twitteur.entity-type/attributes #{{:db/id 4} {:db/id 6} {:db/id 3} {:db/id 2} {:db/id 5}},
   :twitteur.entity-type/name :twitteur/User,
   :db/id 1}

  ;; What attributes have type :twitteur/User?
  &amp;#40;dt/q '&amp;#91;:find ?attrName ?to-many? :in $ ?type :where
          &amp;#91;?attr :twitteur.attribute.ref-typed/type ?type&amp;#93;
          &amp;#91;?attr :twitteur.attribute/name ?attrName&amp;#93;
          &amp;#91;?attr :twitteur.attribute.ref-typed/many? ?to-many?&amp;#93;&amp;#93;
    model-db &amp;#91;:twitteur.entity-type/name :twitteur/User&amp;#93;&amp;#41;
  =&amp;gt; #{&amp;#91;:tweet/author false&amp;#93; &amp;#91;:user/follows true&amp;#93;}

  ;; What attributes are derived, and therefore should not be stored in the database?
  &amp;#40;-&amp;gt;&amp;gt;
    &amp;#40;dt/q '&amp;#91;:find &amp;#91;?attr ...&amp;#93; :where
            &amp;#91;?attr :twitteur.attribute/derived? true&amp;#93;&amp;#93;
      model-db&amp;#41;
    &amp;#40;map #&amp;#40;dt/entity model-db %&amp;#41;&amp;#41;
    &amp;#40;sort-by :twitteur.attribute/name&amp;#41;
    &amp;#40;mapv dt/touch&amp;#41;&amp;#41;
  =&amp;gt;
  &amp;#91;{:twitteur.schema/doc &amp;quot;The tweets posted by this user.&amp;quot;,
    :twitteur.attribute/derived? true,
    :twitteur.attribute/name :user/follows,
    :twitteur.attribute/ref-typed? true,
    :twitteur.attribute.ref-typed/many? true,
    :twitteur.attribute.ref-typed/type {:db/id 7},
    :db/id 5}
   {:twitteur.schema/doc &amp;quot;How many users follow this user.&amp;quot;,
    :twitteur.attribute/derived? true,
    :twitteur.attribute/name :user/n&amp;#95;followers,
    :twitteur.attribute/ref-typed? false,
    :twitteur.attribute.ref-typed/many? true,
    :twitteur.attribute.scalar/type :long,
    :db/id 6}&amp;#93;

  ;; What attributes are private, and therefore should not be exposed publicly?
  &amp;#40;set
    &amp;#40;dt/q '&amp;#91;:find &amp;#91;?attrName ...&amp;#93; :where
            &amp;#91;?attr :twitteur.attribute.security/private? true&amp;#93;
            &amp;#91;?attr :twitteur.attribute/name ?attrName&amp;#93;&amp;#93;
      model-db&amp;#41;&amp;#41;
  =&amp;gt; #{:user/email}
  &amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;As an example, &lt;a href='https://github.com/vvvvalvalval/datascript-declarative-model-example/blob/master/src/twitteur/lib/graphql.clj'&gt;&lt;strong&gt;here&lt;/strong&gt;&lt;/a&gt;'s  what generating a GraphQL schema could look like (for the &lt;a href='http://lacinia.readthedocs.io/en/latest/overview.html#schema'&gt;Lacinia&lt;/a&gt; library,   which is a Clojure GraphQL wrapper).&lt;/p&gt;&lt;p&gt;It's really important to understand that the DataScript database value is &lt;i&gt;not&lt;/i&gt; a hidden implementation detail here:  &lt;strong&gt;the database &lt;i&gt;is&lt;/i&gt; the API&lt;/strong&gt;. Not only is our Domain Model programmatically accessible, but we didn't even have   to make a custom API for it: we already have the DataScript query API for that. This makes our Domain Model Representation   both &lt;strong&gt;a good programming substrate and an effective communication medium.&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;To make your system more transparent you may want to add another 'refinement' step before generating the system components,  which consists of enriching the meta-database with facts about the Machine Aspects. This way, you can even query the meta-database  about how your Domain Model got translated into system components. The logic for this refinement step is quite reminiscent   of deductive rule engines - for instance &quot;if an Attribute A is not derived, then there is a Datomic schema transaction   for an attribute of the same type as A&quot;.&lt;/p&gt;&lt;p&gt;  &lt;img src=&quot;/img/domain-representation-to-machine-execution-with-refinement.png&quot; width=&quot;100%&quot;&gt;&lt;/img&gt;&lt;/p&gt;&lt;p&gt;Finally, as you may have noticed, our &lt;i&gt;Domain Model assertions&lt;/i&gt; code above is quite verbose and difficult to read.  You may get around this issue by generating appropriate visualizations from the meta-database (e.g HTML pages or GraphViz);  but it's also quite straightforward to make a small ad hoc DSL to make the code more concise and contrasted:   &lt;br /&gt;     &lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;;;;; Let's make our schema code more readable,
;;;; by using some concision helpers

&amp;#40;require '&amp;#91;twitteur.utils.model.dml :as dml&amp;#93;&amp;#41;

&amp;#40;def user-model
  &amp;#91;&amp;#40;dml/entity-type :twitteur/User
     &amp;quot;a User is a person who has signed up to Twitteur.&amp;quot;
     {:twitteur.entity-type/attributes
      &amp;#91;&amp;#40;dml/scalar :user/id :uuid &amp;#40;dml/unique-id&amp;#41; &amp;quot;The unique ID of this user.&amp;quot;&amp;#41;
       &amp;#40;dml/scalar :user/email :string &amp;#40;dml/private&amp;#41; &amp;quot;The email address of this user &amp;#40;not visible to other users&amp;#41;.&amp;quot;&amp;#41;
       &amp;#40;dml/scalar :user/name :string &amp;quot;The public name of this user on Twitteur.&amp;quot;&amp;#41;
       &amp;#40;dml/to-many :user/follows :twitteur/User &amp;quot;The Twitteur users whom this user follows.&amp;quot;&amp;#41;
       &amp;#40;dml/scalar :user/n&amp;#95;followers :long &amp;#40;dml/derived&amp;#41; &amp;quot;How many users follow this user.&amp;quot;&amp;#41;
       &amp;#40;dml/to-many :user/tweets :twitteur/Tweet &amp;#40;dml/derived&amp;#41; &amp;quot;The tweets posted by this user.&amp;quot;&amp;#41;
       &amp;#93;}&amp;#41;&amp;#93;&amp;#41;

&amp;#40;def tweet-model
  &amp;#91;&amp;#40;dml/entity-type :twitteur/Tweet
     &amp;quot;a Tweet is a short message posted by a User on Twitteur, published to all her Followers.&amp;quot;
     {:twitteur.entity-type/attributes
      &amp;#91;&amp;#40;dml/scalar :tweet/id :uuid &amp;quot;The unique ID of this Tweet&amp;quot; &amp;#40;dml/unique-id&amp;#41;&amp;#41;
       &amp;#40;dml/scalar :tweet/content :string &amp;quot;The textual message of this Tweet&amp;quot;&amp;#41;
       &amp;#40;dml/to-one :tweet/author :twitteur/User &amp;quot;The Twitteur user who wrote this Tweet.&amp;quot;&amp;#41;
       &amp;#40;dml/scalar :tweet/time :long &amp;quot;The time at which this Tweet was published, as a timestamp.&amp;quot;&amp;#41;
       &amp;#93;}&amp;#41;&amp;#93;&amp;#41;

;; Note that there's no macro magic above: user-model and tweet-model are still plain data structures,
;; we just use the dml/... functions to assemble them in a more readable way.
;; In particular, you can evaluate any sub-expression above in the REPL and see exactly
;; how it translates to a data structure.
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The &lt;code&gt;dml/...&lt;/code&gt; helper functions used in the above snippet are defined &lt;a href='https://github.com/vvvvalvalval/datascript-declarative-model-example/blob/master/src/twitteur/utils/model/dml.clj#L1'&gt;here&lt;/a&gt;.&lt;/p&gt;&lt;h2 id=&quot;tradeoffs&amp;#95;and&amp;#95;limitations&quot;&gt;Tradeoffs and limitations&lt;/h2&gt; &lt;p&gt;Now that we've described the approach, the question that remains is: 'Should I adopt it?'. We'll discuss this question   from a few different perspectives.   &lt;/p&gt;&lt;h3 id=&quot;prior&amp;#95;art&quot;&gt;Prior art&lt;/h3&gt;  &lt;br /&gt;&lt;p&gt;The idea of writing a representation of the Domain Model in declarative form and automatically deriving machine behaviour   from that is not new. There's a number of popular solutions in the industry in which this idea is embodied:  &lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Database DMLs&lt;/strong&gt; (Data Modeling Languages) e.g in SQL: you describe the shape of your data, and sometimes can query it.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;ORMs&lt;/strong&gt; (Object-Relational Mappers) like ActiveRecord / Hibernate, and more generally &lt;strong&gt;class-based frameworks&lt;/strong&gt;: you represent your 'model' as a class and use class annotations or various metaprogramming features to make your Domain Model assertions&lt;/li&gt;&lt;li&gt;&lt;strong&gt;API schemas&lt;/strong&gt;, like GraphQL schemas for GraphQL, OpenAPI for REST and WSDL for SOAP, also rely on a data representation of some part of your Domain Model&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;I see a number of drawbacks to using these solutions as the representation for your Domain Model.&lt;/p&gt;&lt;p&gt;First, they tend to have a very &lt;strong&gt;biased and incomplete perspective of your system&lt;/strong&gt;.  ORMs and DMLs only talk about your domain in the perspective of data persistence and integrity;   API schemas only talk about your domain in the perspective of data exchange and validation.  I think you lose many benefits of the Domain-Model-in-program approach once your representation stops being all-encompassing.  &lt;/p&gt;&lt;p&gt;Second, they tend to be &lt;strong&gt;not very programmable,&lt;/strong&gt; especially class-based tools like ORMs.  They're usually not portable across runtimes (e.g accessible to both client and server code), they don't offer the   composable, data-based writes and powerful querying features of DataScript, and are usually not open to extensions.&lt;/p&gt;&lt;p&gt;Third, and related to programmability, they often are &lt;strong&gt;not very transparent or tangible.&lt;/strong&gt; When you write annotations in a class,  you don't get a query API to inspect / explore the implications of that annotation; all you get to do is read the documentation   and / or reverse-engineer them from the external behaviour of the system. In particular, even if your framework provides useful   logic to process your Domain Model assertions, you can't really reuse nor rely on that logic to complement that framework  for your own needs. &lt;/p&gt;&lt;p&gt;Finally, I think that these frameworks, because of their genericity, suffer from the fundamental limitation that they  &lt;strong&gt;don't know and cannot know the language of your domain, nor its implications on your software system.&lt;/strong&gt; These frameworks enable your to   address machine aspect with a domain-first approach, but as a byproduct they impose on you a representation of your Domain Model,  and assumptions about the implications in terms of machine aspects. The more advanced your system, the more likely it is that  your framemork of choice will be a misfit for it.   You don't have this problem with DataScript, which only imposes a representation &lt;i&gt;medium&lt;/i&gt; for your Domain Model -   one that offers a lot of leverage and few constraints, as we've seen.&lt;/p&gt;&lt;h3 id=&quot;plumbing-first&amp;#95;vs&amp;#95;domain-first&quot;&gt;Plumbing-first vs Domain-first&lt;/h3&gt;&lt;p&gt;I think there are essentially 2 approaches to developing software, each with their own merits, which I'd call &lt;i&gt;plumbing-first&lt;/i&gt; and &lt;i&gt;domain-first&lt;/i&gt;.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Plumbing-first&lt;/strong&gt; consists of programming by starting with 'mechanical' components - HTTP routes, database queries, etc. -  shaping them until the program's behaviour meets the requirements of the Domain.  &lt;/p&gt;&lt;p&gt;A plumbing-first approach makes for early successes, and is generally a good approach when the Domain is not well-known or very simple.  Of course, the downside is accidental complexity, as well as the problems we mentioned above such as over-specificity and   an implicit, scattered domain model.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Domain-first&lt;/strong&gt; consists of programming by coding a declarative representation of the Domain Model,   then building a generic interpreter (in the broad sense - you don't have to create a new programming language for that)  which executes that representation.&lt;/p&gt;&lt;p&gt;A domain-first approach has the advantage of keeping the domain-specific code focused on the essential, and of making   the machine-specific code relatively concise and very generic, but alse more abstract; in particular, you are combatting   complexity by adopting home-made abstractions, and that means that the development team must be willing to learn new abstractions.  &lt;/p&gt;&lt;p&gt;The approach we're describing is this article is definitely domain-first.&lt;/p&gt;&lt;h3 id=&quot;adaptable&amp;#95;vs&amp;#95;principled&quot;&gt;Adaptable vs Principled&lt;/h3&gt;&lt;p&gt;In his excellent book &lt;i&gt;&lt;a href='https://leanpub.com/elementsofclojure'&gt;Elements of Clojure&lt;/a&gt;&lt;/i&gt;, Zach Tellman draws a distinction between  &lt;strong&gt;principled&lt;/strong&gt; and &lt;strong&gt;adaptable&lt;/strong&gt; systems of abstractions:  &lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; We can build a &lt;strong&gt;principled&lt;/strong&gt; system, which enforces predictable relationships between its abstractions.  Alternately, we can build an &lt;strong&gt;adaptable&lt;/strong&gt; system, which has sparse and flexible relationships between its abstractions.&lt;br /&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;In his talk &lt;a href='https://www.youtube.com/watch?v=x9pxbnFC4aQ&amp;feature=youtu.be&amp;t=31m42s'&gt;On Abstraction&lt;/a&gt;,   Zach Tellman then presents the following tradeoffs to principled or adaptable systems:&lt;/p&gt;&lt;p&gt; &lt;a href=&quot;https://youtu.be/x9pxbnFC4aQ?t=31m42s&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;/img/principled-adaptable-tradeoffs.png&quot; width=&quot;100%&quot;&gt;&lt;/img&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;My understanding of this is that the approach discussed in this article is &lt;i&gt;principled.&lt;/i&gt; We gain predictability and save work  by enforcing an organizing principle about how our Domain Model should be expressed and interpreted, while making a strong  assumption of regularity in our domain requirements.&lt;/p&gt;&lt;p&gt;Zach Tellman suggests that we can cope with the brittleness of principled components by embedding them in an adaptable 'framework' or 'glue',  and in particular by leaving some space between principled components and the periphery of our systems. You should leave   'espace hatches' for edge cases where your Domain Model representation becomes insufficient; for instance, you should preserve the ability  to exceptionnaly define some GraphQL fields or database attributes or REST endpoints without going through your Domain Model representation.   &lt;/p&gt;&lt;h3 id=&quot;you're&amp;#95;in&amp;#95;the&amp;#95;business&amp;#95;of&amp;#95;framework-authoring&quot;&gt;You're in the business of framework-authoring&lt;/h3&gt;&lt;p&gt;The way I see it, if you're adopting the approach described in this post, you're going down the road of building a homemade framework.  That's not necessary a bad thing, because your homemade framework makes assumptions that are by definition aligned with your use case,  and it doesn't need to have the crazy ambitions of the more popular frameworks we see out there (for instance, it doesn't have to pretend  to solve the Object-Relational Impedance Mismatch, or reinvent the web, or try to hide distributed system issues behind method calls, etc.)  &lt;/p&gt;&lt;p&gt;By 'framework', I really mean a set of programmatically-enforced decisions about application architecture. In this sense,   I think making your own framework is viable if you don't try to solve impossible problems, and don't make your assumptions  too broad. In particular, as you can see, I'm not offering any library to embody the approach described in this post, because  I think it would do more harm than good: the entire point is that you, only you, can know how your system should be described in domain terms.  &lt;/p&gt;&lt;p&gt;Still, even if it pays on the long-term, making a framework is not a light endeavour, and if you're going to do it at all  you should &lt;strong&gt;do it thoroughly:&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;&lt;a href='https://www.youtube.com/watch?v=f84n5oFoZBc'&gt;Think it through&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Test it well&lt;/strong&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Document it well.&lt;/strong&gt; In particular, it's incredibly easy to generate HTML documentation (à la JavaDoc) from a DataScript-backed meta-database. This can be a effective strategy to make documentation that is less likely to become stale, and uses your Domain Model  as its own example, making it more accessible to newcomers.&lt;/li&gt;&lt;/ul&gt;&lt;h2 id=&quot;experience&amp;#95;report:&amp;#95;bandsquare&quot;&gt;Experience report: BandSquare&lt;/h2&gt;&lt;p&gt;&lt;a href='https://www.bandsquare.com/'&gt;BandSquare&lt;/a&gt; is a SaaS platform for creating and analyzing marketing campaigns and surveys.  We have applied this approach to BandSquare's backend code for more than 18 months now; at the time of writing,   our Domain Model Representation features over 80 Entity Types and 450 Attributes. The main Machine Aspects we address   are generating GraphQL(ish) schema and handlers, Datomic schema transactions, security rules, and documentation; we're  considering adding more, such as change detection for ETL.&lt;/p&gt;&lt;p&gt;Overall, this approach has been a significant improvement to BandSquare's development. We've found that:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;BandSquare's domain of a 'platform' is a good fit for this approach, as we want to extend the platform to new use cases while leveraging as much of the existing code as possible.&lt;/li&gt;&lt;li&gt;The fact that Datomic and GraphQL are conceptually close has been quite helpful in implementing it.&lt;/li&gt;&lt;/ul&gt;&lt;h2 id=&quot;annex:&amp;#95;a&amp;#95;datascript&amp;#95;refresher&quot;&gt;Annex: a DataScript refresher&lt;/h2&gt;&lt;p&gt;&lt;a href='https://github.com/tonsky/datascript'&gt;DataScript&lt;/a&gt; is an in-memory data structure, with similar read and write APIs to a Datomic database. As such, DataScript   can be compared to other collections:&lt;/p&gt;&lt;p&gt;  &lt;img src=&quot;/img/datascript-api-comparison.png&quot; width=&quot;100%&quot;/&gt;   &lt;/p&gt;&lt;p&gt;With that in mind, check out this &lt;strong&gt;&lt;a href='https://github.com/vvvvalvalval/datascript-declarative-model-example/blob/master/src/datascript_demo.clj#L1'&gt;DataScript Demo&lt;/a&gt;&lt;/strong&gt;  to get a better understanding of how DataScript works.&lt;/p&gt;
</description>
<pubDate>
Mon, 23 Jul 2018 00:00:00 +0200
</pubDate>
</item>
<item>
<guid>
http://vvvvalvalval.github.io/posts/2018-05-01-making-a-datomic-system-gdpr-compliant.html
</guid>
<link>
http://vvvvalvalval.github.io/posts/2018-05-01-making-a-datomic-system-gdpr-compliant.html
</link>
<title>
Making a Datomic system GDPR-compliant
</title>
<description>
&lt;p&gt;&lt;div style=&quot;text-align:center;&quot;&gt;&lt;img src=&quot;/img/keep-calm-indirection.png&quot; width=&quot;100%&quot;&gt;&lt;/div&gt;&lt;/p&gt;&lt;p&gt;There have been some concerns in the &lt;a href='https://www.datomic.com/'&gt;Datomic&lt;/a&gt; community lately that the soon-to-be-enforced  &lt;a href='https://www.eugdpr.org/'&gt;EU General Data Protection Regulation&lt;/a&gt; would force many businesses give up on using Datomic,   due to its lack of practical ways of erasing data. This post describes an approach to eliminate these concerns, and how  to implement it in practice (this may turn into a library someday). I'm happy to say that at &lt;a href='https://www.bandsquare.com/'&gt;BandSquare&lt;/a&gt;  we've been able to apply these ideas to our entire system in a matter of days.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;TL;DR:&lt;/strong&gt; For cases where &lt;a href='https://docs.datomic.com/on-prem/excision.html'&gt;Datomic Excision&lt;/a&gt; is not a viable way to achieve GDPR-compliance,  we avoid storing privacy-sensitive data in Datomic by storing it as values in a complementary, domain-agnostic Key/Value-store,  while having the keys referenced from Datomic. To our surprise, we've found that this approach preserves almost all of the architectural  advantages of Datomic, while requiring relatively little additional effort, thanks to the generic data manipulation capabilities of   Datomic and Clojure.&lt;/p&gt;&lt;p&gt;I'm also using this post as an opportunity to experiment with a new way of writing: giving exercises to the reader,  which is something I quite appreciate in learning resources. Feedback welcome on that too.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;DISCLAIMER:&lt;/strong&gt; this article is not legal advice; its goal is to give you options, not to tell you what you're supposed to do.&lt;/p&gt;&lt;h2 id=&quot;background:&amp;#95;about&amp;#95;the&amp;#95;gdpr&quot;&gt;Background: about the GDPR&lt;/h2&gt;&lt;p&gt;The &lt;a href='https://www.eugdpr.org/'&gt;General Data Protection Regulation&lt;/a&gt; (GDPR) is a data-privacy regulation which was approved  by the EU Parliament in April 2016, and will be enforced starting from May 25, 2018. It concerns not just EU companies,   but also any company which holds private data of EU citizens. &lt;br /&gt;&lt;/p&gt;&lt;p&gt;Among other things, the GDPR &lt;a href='https://www.eugdpr.org/key-changes.html'&gt;mandates&lt;/a&gt; that companies apply the &lt;strong&gt;Right to be Forgotten,&lt;/strong&gt;  which implies:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;having the ability to erase all personal data of a person upon request,&lt;/li&gt;&lt;li&gt;in many cases, erasing any personal data after a certain retention period (typically 3 to 5 years)&lt;/li&gt;&lt;/ol&gt;&lt;h2 id=&quot;datomic&amp;#95;excision,&amp;#95;and&amp;#95;its&amp;#95;limitations&quot;&gt;Datomic Excision, and its limitations&lt;/h2&gt;&lt;p&gt;One fundamental principle of Datomic is that information is &lt;a href='https://www.infoq.com/presentations/Datomic-Database-Value'&gt;always only accumulated, never modified / deleted&lt;/a&gt;;  this is great for building robust information systems quickly, but is directly in conflict with GDPR's Right to be Forgotten. &lt;/p&gt;&lt;p&gt;Because making exceptions to this principle is sometimes necessary, Datomic has long provided a way to erase data:  &lt;a href='https://docs.datomic.com/on-prem/excision.html'&gt;Excision&lt;/a&gt;. However, using Excision can be very costly in performance  and therefore operationnally constraining, as it can trigger massive rewrites of Datomic indexes. For this reason,  the Datomic team themselves recommend that Excision should be used very infrequently.  &lt;/p&gt;&lt;p&gt;This implies that Datomic Excision may not be a practical solution for all businesses, especially businesses that process   a lot of consumer data, and especially for use cases where personal data has a limited retention period, which means   that data erasure is no longer an exceptional event. &lt;/p&gt;&lt;p&gt;What's more, at the time of writing, Excision is &lt;a href='https://docs.datomic.com/on-prem/moving-to-cloud.html#sec-4-5'&gt;not supported&lt;/a&gt;   on &lt;a href='https://docs.datomic.com/cloud/index.html'&gt;Datomic Cloud&lt;/a&gt;.&lt;br /&gt;&lt;/p&gt;&lt;h2 id=&quot;proposed&amp;#95;solution:&amp;#95;complementing&amp;#95;datomic&amp;#95;with&amp;#95;an&amp;#95;erasure-aware&amp;#95;key/value&amp;#95;store&quot;&gt;Proposed solution: complementing Datomic with an erasure-aware key/value store&lt;/h2&gt;&lt;p&gt;In cases where Excision is not a viable solution, the solution I've come up with is store to privacy-sensitive values in a complementary,  mutable KV store, and referencing the corresponding keys from Datomic.&lt;/p&gt;&lt;p&gt;So instead of this:&lt;/p&gt;&lt;p&gt;&lt;script src=&quot;https://gist.github.com/vvvvalvalval/27e362efa38404e211c581ca8223ede2.js&quot;&gt;&lt;/script&gt;&lt;/p&gt;&lt;p&gt;... you want this:&lt;/p&gt;&lt;p&gt;&lt;script src=&quot;https://gist.github.com/vvvvalvalval/b554a00372cf2413f1e12a64ecfa253c.js&quot;&gt;&lt;/script&gt;&lt;/p&gt;&lt;p&gt;Of course, this PrivateDataStore needs an API, preferrably a simple one. At a minimum, the operations we need are:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Adding a value to the store,&lt;/li&gt;&lt;li&gt;Looking up a previously-stored value by its key,&lt;/li&gt;&lt;li&gt;Erasing the value at a key.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;To make things more explicit, let's represent this API as a Java interface:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;java&quot;&gt;import java.util.UUID;

public interface PrivateDataStore&amp;lt;V&amp;gt; {
    /&amp;#42;&amp;#42;
     &amp;#42; Adds a value to this PrivateDataStore,
     &amp;#42; returning the generated key.
     &amp;#42; @param v the value to store.
     &amp;#42; @return the key generated for this value, a UUID.
     &amp;#42;/
    UUID addValue&amp;#40;V v&amp;#41;;

    /&amp;#42;&amp;#42;
     &amp;#42; Looks-up a key in this PrivateDataStore,
     &amp;#42; returning the &amp;#40;potentially&amp;#41; found value
     &amp;#42; wrapped in a LookupResult.
     &amp;#42; @param k the key to look up, which should have been returned by addValue&amp;#40;&amp;#41;.
     &amp;#42; @return the corresponding LookupResult.
     &amp;#42;/
    LookupResult&amp;lt;V&amp;gt; lookupKey&amp;#40;UUID k&amp;#41;;

    interface LookupResult&amp;lt;V&amp;gt;{
        LookupStatus status&amp;#40;&amp;#41;;
        V value&amp;#40;&amp;#41;;
    }

    enum LookupStatus {
        FOUND, ERASED, UNKNOWN&amp;#95;KEY
    }

    /&amp;#42;&amp;#42;
     &amp;#42; Erases the value at the supplied key.
     &amp;#42; @param k
     &amp;#42;/
    void eraseValue&amp;#40;UUID k&amp;#41;;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;What's important to notice here is that this store is completely generic: it &lt;strong&gt;knows nothing about our domain&lt;/strong&gt; (we're not   migrating our user data from Datomic to a User Table; we're just migrating the values).&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Exercise 1:&lt;/strong&gt; write an in-memory implementation of &lt;code&gt;PrivateDataStore&lt;/code&gt; in Clojure.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Improvement:&lt;/strong&gt; the above interface is a bit naïve, as it is likely to suffer from the N+1 problem. To improve performance,  you will probably want to make the reads and writes in batches (for example by bundling the inputs and outputs in lists of tuples),   and potentially in a non-blocking fashion (for instance by using &lt;a href='https://github.com/ztellman/manifold#deferreds'&gt;Manifold Deferreds&lt;/a&gt;).&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Exercise 2.a:&lt;/strong&gt; Design a batching version of &lt;code&gt;PrivateDataStore&lt;/code&gt; in Clojure. Define a Clojure protocol &lt;code&gt;BatchingPrivateDataStore&lt;/code&gt; for it,   and write Clojure Specs for it.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Exercise 2.b:&lt;/strong&gt; Write a PostgreSQL-based implementation of &lt;code&gt;BatchingPrivateDataStore&lt;/code&gt;.   &lt;i&gt;Hint:&lt;/i&gt; JSONB is probably the easiest way to represent batches of composite inputs in PostgreSQL.&lt;/p&gt;&lt;h2 id=&quot;reclaiming&amp;#95;power&quot;&gt;Reclaiming power&lt;/h2&gt;&lt;p&gt;Theoretically, this is all we need to store privacy-sensitive data; but of course, compared to a Datomic-only system, our application  code has just lost a lot of expressive power, since there are now 2 data stores to interact with, including one which has a much   less expressive API than Datomic. Surprisingly, a lot of that power can be reclaimed with just a few generic helpers,  by leveraging Clojure's generic data manipulation capabilities. &lt;/p&gt;&lt;h3 id=&quot;writing&quot;&gt;Writing&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Problem:&lt;/strong&gt; In pure Datomic, writes are &lt;a href='https://docs.datomic.com/on-prem/transactions.html'&gt;defined as plain data structures&lt;/a&gt;,   which is great, as they can be constructed from many independent parts, conveyed to arbitrary locations, and executed downstream.&lt;br /&gt;  We have lost this property with our &lt;code&gt;PrivateDataStore&lt;/code&gt; API, which is defined in term of calling side-effectful functions.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Solution:&lt;/strong&gt; We can still construct writes as pure data, by using a new data type to wrap privacy-sensitive values, e.g:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;def tx-data
  &amp;quot;A trasaction which adds Sam Bagwell to our user base&amp;quot;
  &amp;#91;{:db/id &amp;quot;new-user&amp;quot;
    :user/id #uuid&amp;quot;cb8d5391-b6b8-451c-95f5-719257ed4e93&amp;quot;
    :user/email--k #privacy/private-value &amp;#91;&amp;quot;sam.bagwell@gmail.com&amp;quot; 0&amp;#93;
    :user/first-name--k #privacy/private-value &amp;#91;&amp;quot;Sam&amp;quot; 1&amp;#93;
    :user/last-name--k #privacy/private-value &amp;#91;&amp;quot;Bagwell&amp;quot; 2&amp;#93;
    :user/subscribed-at #inst &amp;quot;2018&amp;quot;}&amp;#93;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We can then use a generic function to execute such &quot;extended&quot; transactions:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;privacy-helpers/transact-async private-data-store conn tx-data&amp;#41;
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;Exercise 3.a:&lt;/strong&gt; define a new data type for wrapping such values.   Then, write a generic function &lt;code&gt;&amp;#40;replace-private-values private-data-store v&amp;#41;&lt;/code&gt;, which must:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;collect wrapped values from the nested data structure &lt;code&gt;v&lt;/code&gt;,&lt;/li&gt;&lt;li&gt;add them to the &lt;code&gt;PrivateDataStore&lt;/code&gt; (you may assume a batching interface as defined in Exercise 2.a),&lt;/li&gt;&lt;li&gt;replace the wrapped values by the corresponding generated keys in &lt;code&gt;v&lt;/code&gt;.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;i&gt;Hint:&lt;/i&gt; use Specter's &lt;a href='https://github.com/nathanmarz/specter/wiki/List-of-Navigators#walker'&gt;&lt;code&gt;walker&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Exercise 3.b:&lt;/strong&gt; Using the above-defined &lt;code&gt;replace-private-values&lt;/code&gt;, implement &lt;code&gt;privacy-helpers/transact-async&lt;/code&gt;, which   must return a similar value to &lt;code&gt;datomic.api/transact-async&lt;/code&gt;.&lt;/p&gt;&lt;h3 id=&quot;querying&quot;&gt;Querying&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Problem:&lt;/strong&gt; we can still query Datomic with the usual APIs (Datalog, Pull API, Entity API), but we have no out-of-the-box way  of replacing the &lt;code&gt;PrivateDataStore&lt;/code&gt; keys with their values when necessary (Note: it may not be necessary very often).&lt;/p&gt;&lt;h4 id=&quot;solution&amp;#95;a:&amp;#95;tagging&amp;#95;keys&quot;&gt;Solution A: tagging keys&lt;/h4&gt;&lt;p&gt;In some cases, we can use a similar strategy as above for writes: tagging &lt;code&gt;PrivateDataStore&lt;/code&gt; keys, then using a generic function  on the query results which fetches the values and replaces the keys. This can be make easier by using a generic Datalog rule   to tag keys; here's an example:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;d/q
  '&amp;#91;:find ?user ?id ?email-k ?last-name-k
    :in % $ &amp;#91;?user ...&amp;#93;
    :where
    &amp;#91;?user :user/id ?id&amp;#93;
    &amp;#40;read-private-key ?user :user/email--k ?email-k&amp;#41;
    &amp;#40;read-private-key ?user :user/last-name--k ?last-name-k&amp;#41;&amp;#93;
  ;; A generic Datalog rule for tagging PrivateDataStore values, using Clojure Tagged Literals
  '&amp;#91;&amp;#91;&amp;#40;read-private-key &amp;#91;?e ?a&amp;#93; ?tagged-k&amp;#41;
     &amp;#91;?e ?a ?k&amp;#93;
     &amp;#91;&amp;#40;clojure.core/tagged-literal 'privacy/key ?k&amp;#41; ?tagged-k&amp;#93;&amp;#93;&amp;#93;
  db
  &amp;#91;&amp;#91;:user/id #uuid&amp;quot;cb8d5391-b6b8-451c-95f5-719257ed4e93&amp;quot;&amp;#93;
   &amp;#91;:user/id #uuid&amp;quot;2abbd931-4cfa-47f0-abe4-ffd57c944999&amp;quot;&amp;#93;&amp;#93;&amp;#41;
=&amp;gt; #{&amp;#91;100 #uuid&amp;quot;cb8d5391-b6b8-451c-95f5-719257ed4e93&amp;quot; #privacy/key #uuid&amp;quot;fb23991a-d7c7-4850-9735-904345325281&amp;quot; #privacy/key #uuid&amp;quot;348f0967-c2d5-45d5-8dbc-a562f75bbbd6&amp;quot;&amp;#93;
     &amp;#91;101 #uuid&amp;quot;2abbd931-4cfa-47f0-abe4-ffd57c944999&amp;quot; #privacy/key #uuid&amp;quot;60dce0c1-0258-4e20-91a2-3e0a4f20f0d8&amp;quot; #privacy/key #uuid&amp;quot;3a180f2e-f1c5-48aa-be0b-09c088ed023d&amp;quot;&amp;#93;}

&amp;#40;privacy-helpers/replace-tagged-keys private-data-store {:when-erased &amp;quot;&amp;#40;deleted&amp;#41;&amp;quot;} &amp;#42;1&amp;#41;
=&amp;gt; #{&amp;#91;100 #uuid&amp;quot;cb8d5391-b6b8-451c-95f5-719257ed4e93&amp;quot; &amp;quot;john.doe@gmail.com&amp;quot; &amp;quot;Doe&amp;quot;&amp;#93;
     &amp;#91;101 #uuid&amp;quot;2abbd931-4cfa-47f0-abe4-ffd57c944999&amp;quot; &amp;quot;&amp;#40;deleted&amp;#41;&amp;quot; &amp;quot;&amp;#40;deleted&amp;#41;&amp;quot;&amp;#93;}
`&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;Exercise 4:&lt;/strong&gt; Implement the &lt;code&gt;privacy-helpers/replace-tagged-keys&lt;/code&gt; function.   &lt;i&gt;Hint:&lt;/i&gt; use Specter's &lt;a href='https://github.com/nathanmarz/specter/wiki/List-of-Navigators#walker'&gt;&lt;code&gt;walker&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;&lt;h4 id=&quot;solution&amp;#95;b:&amp;#95;replacing&amp;#95;keys&amp;#95;at&amp;#95;explicit&amp;#95;paths&quot;&gt;Solution B: replacing keys at explicit paths&lt;/h4&gt;&lt;p&gt;The above Solution A is very generic, and has the advantage of being completely decoupled from queries.   However, it is not always viable, because we don't always have enough control on the production of query results  for tagging keys, for example when using the Pull API. In such cases, we will need a little more knowledge of the   data shape of the query results.&lt;/p&gt;&lt;h5 id=&quot;extracting&amp;#95;values&amp;#95;from&amp;#95;an&amp;#95;entity&quot;&gt;Extracting values from an Entity&lt;/h5&gt;&lt;p&gt;First, it can be useful to have a function which extract some values from an entity into a map, for instance:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;def user-data 
  {:user/id #uuid&amp;quot;cb8d5391-b6b8-451c-95f5-719257ed4e93&amp;quot;
   :user/email--k #uuid&amp;quot;fb23991a-d7c7-4850-9735-904345325281&amp;quot;
   :user/first-name--k #uuid&amp;quot;e6f7ac4e-70a3-4427-9d5a-93488adc134a&amp;quot;
   :user/last-name--k #uuid&amp;quot;348f0967-c2d5-45d5-8dbc-a562f75bbbd6&amp;quot;
   :user/subscribed-at #inst&amp;quot;2018-04-23T15:04:10.674-00:00&amp;quot;}&amp;#41;

&amp;#40;privacy-helpers/private-values-into-map 
  private-data-store 
  {:user/email {:from-key :user/email--k 
                :when-erased &amp;quot;&amp;#40;deleted&amp;#41;&amp;quot;}
   :user/first-name {:from-key :user/first-name--k
                     :when-erased &amp;quot;&amp;#40;deleted&amp;#41;&amp;quot;}}
  user-data&amp;#41;
=&amp;gt; {:user/email &amp;quot;john.doe@gmail.com&amp;quot;
    :user/first-name &amp;quot;John&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;&lt;h5 id=&quot;replacing&amp;#95;privacy&amp;#95;keys&amp;#95;at&amp;#95;arbitrary&amp;#95;paths&quot;&gt;Replacing privacy keys at arbitrary paths&lt;/h5&gt;&lt;p&gt;&lt;strong&gt;Exercise 5:&lt;/strong&gt; Implement the &lt;code&gt;privacy-helpers/private-values-into-map&lt;/code&gt; function. It should accept a map as well as a Datomic Entity  as an input.&lt;/p&gt;&lt;p&gt;The above solution can be enough for basic use cases, but falls short when dealing with nested collections, as returned   by the Pull API for example. In such cases, a more powerful approach is to replace &lt;code&gt;PrivateDataStore&lt;/code&gt; keys at explicit paths,  using the &lt;a href='https://github.com/nathanmarz/specter'&gt;Specter&lt;/a&gt; library:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;require '&amp;#91;com.rpl.specter :as sp&amp;#93;&amp;#41;

;; raw Pull:
&amp;#40;d/pull
  db
  &amp;#91;:blog.post/id
   :blog.post/title
   {:blog.comment/&amp;#95;post &amp;#91;:blog.comment/id
                         :blog.comment/title
                         {:blog.comment/author &amp;#91;:user/id
                                                :user/email--k
                                                :user/subscribed-at&amp;#93;}&amp;#93;}&amp;#93;
  &amp;#91;:blog.post/id &amp;quot;21412312113&amp;quot;&amp;#93;&amp;#41;
=&amp;gt; {:blog.post/id &amp;quot;21412312113&amp;quot;
    :blog.post/title &amp;quot;Why GDPR matters&amp;quot;
    :blog.comment/&amp;#95;post &amp;#91;{:blog.comment/id 324242423222
                          :blog.comment/title &amp;quot;I agree!&amp;quot;
                          :blog.comment/author {:user/id #uuid&amp;quot;cb8d5391-b6b8-451c-95f5-719257ed4e93&amp;quot;
                                                :user/email--k #uuid&amp;quot;fb23991a-d7c7-4850-9735-904345325281&amp;quot;
                                                :user/subscribed-at #inst&amp;quot;2018-04-23T15:04:10.674-00:00&amp;quot;}}
                         {:blog.comment/id 324242423223
                          :blog.comment/title &amp;quot;I disagree!&amp;quot;
                          :blog.comment/author {:user/id #uuid&amp;quot;2abbd931-4cfa-47f0-abe4-ffd57c944999&amp;quot;
                                                :user/email--k #uuid&amp;quot;60dce0c1-0258-4e20-91a2-3e0a4f20f0d8&amp;quot;
                                                :user/subscribed-at #inst&amp;quot;2017-07-07T00:00:00.000-00:00&amp;quot;}}&amp;#93;}

;; Transforming the result to replace PrivateDataStore keys:
&amp;#40;privacy-helpers/replace-private-entries-at-path 
  privacy-data-store
  &amp;#91;:blog.comment/&amp;#95;post sp/ALL :blog.comment/author&amp;#93;
  {:user/email {:from-key :user/email--k
                :when-erased &amp;quot;&amp;#40;deleted&amp;#41;&amp;quot;}}
  &amp;#42;1&amp;#41;
=&amp;gt; {:blog.post/id &amp;quot;21412312113&amp;quot;
    :blog.post/title &amp;quot;Why GDPR matters&amp;quot;
    :blog.comment/&amp;#95;post &amp;#91;{:blog.comment/id 324242423222
                          :blog.comment/title &amp;quot;I agree!&amp;quot;
                          :blog.comment/author {:user/id #uuid&amp;quot;cb8d5391-b6b8-451c-95f5-719257ed4e93&amp;quot;
                                                :user/email &amp;quot;john.doe@gmail.com&amp;quot;
                                                :user/subscribed-at #inst&amp;quot;2018-04-23T15:04:10.674-00:00&amp;quot;}}
                         {:blog.comment/id 324242423223
                          :blog.comment/title &amp;quot;I disagree!&amp;quot;
                          :blog.comment/author {:user/id #uuid&amp;quot;2abbd931-4cfa-47f0-abe4-ffd57c944999&amp;quot;
                                                :user/email &amp;quot;&amp;#40;deleted&amp;#41;&amp;quot;
                                                :user/subscribed-at #inst&amp;quot;2017-07-07T00:00:00.000-00:00&amp;quot;}}&amp;#93;}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;Exercise 6:&lt;/strong&gt; implement the &lt;code&gt;privacy-helpers/replace-private-entries-at-path&lt;/code&gt; function.  You may assume a batching API for looking up PrivateDataStore keys, as defined in Exercise 2.a.&lt;/p&gt;&lt;h4 id=&quot;solution&amp;#95;c:&amp;#95;using&amp;#95;graph&amp;#95;data&amp;#95;access&amp;#95;layers&quot;&gt;Solution C: using graph data access layers&lt;/h4&gt;&lt;p&gt;Finally, another solution for resolving privacy-sensitive values is to make it part of the data-fetching logic of a Graph API,  e.g in a &lt;a href='https://graphql.org/'&gt;GraphQL&lt;/a&gt; resolver or &lt;a href='http://book.fulcrologic.com/#_query_parsing'&gt;Fulcro&lt;/a&gt; parser. In particular, a  Graph API server can be a good alternative to Datomic Pull (for other reasons than the GDPR!). &lt;/p&gt;&lt;h3 id=&quot;querying&amp;#95;and&amp;#95;transacting&amp;#95;by&amp;#95;value&quot;&gt;Querying and transacting by value&lt;/h3&gt;&lt;p&gt;The approach we have described so far does not cover cases when we want to query by value, for instance:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Find the user whose &lt;code&gt;:user/email&lt;/code&gt; is &lt;code&gt;&amp;quot;john.doe@gmail.com&amp;quot;&lt;/code&gt;&lt;/li&gt;&lt;li&gt;Create a user account for email &lt;code&gt;&amp;quot;john.doe@gmail.com&amp;quot;&lt;/code&gt;, failing if one already exists&lt;/li&gt;&lt;li&gt;Find users in the database whose &lt;code&gt;:user/last-name&lt;/code&gt; is something like &lt;code&gt;&amp;quot;Doe&amp;quot;&lt;/code&gt;.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;Use case &lt;code&gt;2.&lt;/code&gt; is especially challenging, because it must be part of a transaction, and is therefore likely to happen in the   Transactor where calling our &lt;code&gt;PrivateDataStore&lt;/code&gt; won't be an option.&lt;/p&gt;&lt;h4 id=&quot;solution&amp;#95;a:&amp;#95;hash-based&amp;#95;equality&amp;#95;and&amp;#95;uniqueness&quot;&gt;Solution A: Hash-based equality and uniqueness&lt;/h4&gt;&lt;p&gt;For the many cases where strict equality is acceptable, querying by value can be done via hashed values, which can be indexed   in Datomic without exposing sensitive information.&lt;/p&gt;&lt;p&gt;Continuing with our &lt;code&gt;:user/email&lt;/code&gt; example, we can add a string-typed, indexed &lt;code&gt;:user/email&amp;ndash;hash&lt;/code&gt; attribute, which values are   computed e.g by securely hashing then base64-encoding the emails of the users.   This solves our use cases &lt;code&gt;1.&lt;/code&gt; and &lt;code&gt;2.&lt;/code&gt; mentioned above.&lt;/p&gt;&lt;p&gt;If you don't know what library to use for hashing, I recommend &lt;a href='http://funcool.github.io/buddy-core/latest/'&gt;buddy-core&lt;/a&gt;.&lt;/p&gt;&lt;h4 id=&quot;solution&amp;#95;b:&amp;#95;adding&amp;#95;indexes&amp;#95;to&amp;#95;privatedatastore&quot;&gt;Solution B: Adding indexes to PrivateDataStore&lt;/h4&gt;&lt;p&gt;For non-transactional reads, another strategy is to add a 'search by value' operation in our &lt;code&gt;PrivateDataStore&lt;/code&gt;. &lt;/p&gt;&lt;p&gt;For instance, we could modify our &lt;code&gt;PrivateDataStore&lt;/code&gt; interface to the following:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;java&quot;&gt;import java.util.Collection;
import java.util.UUID;

public interface PrivateDataStore&amp;lt;V&amp;gt; {
    /&amp;#42;&amp;#42;
     &amp;#42; Adds a value to this PrivateDataStore,
     &amp;#42; returning the generated key.
     &amp;#42; @param v the value to store.
     &amp;#42; @param indexName the name of the index referencing v,
     &amp;#42;                  or null if v is not to be indexed.
     &amp;#42; @return the key generated for this value, a UUID.
     &amp;#42;/
    UUID addValue&amp;#40;V v, String indexName&amp;#41;; // NOTE modified

    /&amp;#42;&amp;#42;
     &amp;#42; Searches for keys matching a given value in a given index.
     &amp;#42; @param indexName the name of the index in which the value
     &amp;#42;                  was potentially added
     &amp;#42; @param searchV the value to search for
     &amp;#42; @return the &amp;#40;potentially empty&amp;#41; list of keys
     &amp;#42; referencing searchV in indexName.
     &amp;#42;/
    Collection&amp;lt;UUID&amp;gt; searchByValue &amp;#40;String indexName, V searchV&amp;#41;; // NOTE new operation

    // the other operations remain the same
    // &amp;#91;...&amp;#93;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;You could also imagine adding options to make the search fuzzy, etc.&lt;/p&gt;&lt;h4 id=&quot;solution&amp;#95;c:&amp;#95;searching&amp;#95;in&amp;#95;materialized&amp;#95;views&quot;&gt;Solution C: Searching in Materialized Views&lt;/h4&gt;&lt;p&gt;It is common practice for modern information systems to evolve so that their storage is divided into 2 categories:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;A &lt;strong&gt;System of Records,&lt;/strong&gt; which acts as a source of truth and supports transactional writes.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Materialized Views,&lt;/strong&gt; which are data stores specialized in certain query patterns, containing data which is derived from the System of Records. &lt;/li&gt;&lt;/ul&gt;&lt;p&gt;It is unusually easy to set up this sort of architecture with Datomic acting as the System of Records,   because the &lt;a href='https://docs.datomic.com/on-prem/log.html'&gt;Log API&lt;/a&gt; makes it almost trivial to detect changes in the source of truth  and update the Materialized Views accordingly.&lt;/p&gt;&lt;p&gt;For instance, you could use the Log API to periodically (or continuously) keep an ElasticSearch index of users documents up-to-date;   as privacy-sensitive fields get erased from the &lt;code&gt;PrivateDataStore&lt;/code&gt;,   they will also get automatically erased from the ElasticSearch documents.  You then have all the power of ElasticSearch to search customers by their privacy-sensitive fields, with the only caveat   that this search will only be eventually consistent with your System of Records (this is usually acceptable; note that even in Datomic,  fulltext indexes are eventually consistent).&lt;/p&gt;&lt;h3 id=&quot;mocking&amp;#95;and&amp;#95;forking&quot;&gt;Mocking and forking&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;The problem:&lt;/strong&gt; &lt;a href='https://vvvvalvalval.github.io/posts/2016-01-03-architecture-datomic-branching-reality.html'&gt;in my opinion&lt;/a&gt;, a lot of Datomic's   leverage comes from its ability to do some speculative work, then discard it. This leads to the powerful notion of &lt;i&gt;forking&lt;/i&gt;   Datomic connections in-memory, which can for instance be applied to easily write system-level tests, and safely dry-run   migrations and patches to the database. We'd like to preserve the ability to fork our entire database, which is now a composite   of Datomic &lt;i&gt;and&lt;/i&gt; our &lt;code&gt;PrivateDataStore&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;It turns out it's fairly straightforward to write an in-memory implementation of &lt;code&gt;PrivateDataStore&lt;/code&gt; which consists of forking a   source &lt;code&gt;PrivateDataStore&lt;/code&gt;, by adding and erasing values locally, and forwarding reads to the source &lt;code&gt;PrivateDataStore&lt;/code&gt;.  You can also choose to only erase locally and add remotely; because the generated keys are UUIDs, there is no real potential for conflict;  this can be desirable e.g for staging environments.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Exercise 7.a:&lt;/strong&gt; write a &lt;code&gt;ForkedPrivateDataStore&lt;/code&gt; in-memory implementation of &lt;code&gt;PrivateDataStore&lt;/code&gt; which is constructed from  an existing implementation, and use it to define a &lt;i&gt;fork&lt;/i&gt; operation on &lt;code&gt;PrivateDataStore&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Exercise 7.b:&lt;/strong&gt; write an in-memory implementation of &lt;code&gt;PrivateDataStore&lt;/code&gt; based on &lt;code&gt;ForkedPrivateDataStore&lt;/code&gt;. &lt;/p&gt;&lt;h2 id=&quot;migrating&amp;#95;an&amp;#95;existing&amp;#95;system&quot;&gt;Migrating an existing system&lt;/h2&gt;&lt;p&gt;If you have an existing system with privacy-sensitive attributes, you will not only need to change the code using the   above-described techniques, but also perform a data migration, preferrably with no or little downtime. At the end,   the privacy-sensitive values must have been migrated to your &lt;code&gt;PrivateDataStore&lt;/code&gt;, and erased from your Datomic system.&lt;/p&gt;&lt;p&gt;I recommend taking the following steps to allow for a smooth transition:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Install the new attributes (e.g &lt;code&gt;:user/email&amp;ndash;k&lt;/code&gt;) on your production system.&lt;/li&gt;&lt;li&gt;Deploy of new version of your code which will write to both the old &lt;strong&gt;and&lt;/strong&gt; new attributes (e.g &lt;code&gt;:user/email&lt;/code&gt; and &lt;code&gt;:user/email&amp;ndash;k&lt;/code&gt;), but read &lt;strong&gt;only&lt;/strong&gt; from the old attributes (e.g &lt;code&gt;:user/email&lt;/code&gt;). Having done this, the set of datoms which  still have to be migrated will only ever be shrinking.&lt;/li&gt;&lt;li&gt;As an offline job, extract the datoms of the old attributes which need to be migrated (example &lt;a href='https://gist.github.com/vvvvalvalval/416187b53b4f641b67f6bde7a98c6163#file-extract-privacy-sensitive-datoms-clj'&gt;here&lt;/a&gt;), write their values to the &lt;code&gt;PrivateDataStore&lt;/code&gt;, then gradually transact the generated keys into the new attributes (you may  want to use a transaction function to make sure you don't write keys for outdated values, example  &lt;a href='https://gist.github.com/vvvvalvalval/991cd9a62890ec93d99fc1a414c71a3e'&gt;here&lt;/a&gt;)&lt;/li&gt;&lt;li&gt;Deploy a new version of your code which now writes to &lt;strong&gt;and&lt;/strong&gt; reads from the new attributes (e.g &lt;code&gt;:user/email&amp;ndash;k&lt;/code&gt;), and no longer uses the old attributes at all (e.g &lt;code&gt;:user/email&lt;/code&gt;).&lt;/li&gt;&lt;li&gt;Erase the values of the old attributes. This may not always be trivial, so see the next section for the details of how to do that.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;Note that this approach will eventually yield a valid &lt;i&gt;&lt;strong&gt;present&lt;/strong&gt;&lt;/i&gt; value of the database, but will not update history to add   the new attributes. I can imagine ways of adding the new attributes to the history, but I won't describe them here, because   I don't want to encourage you in this direction: as I've &lt;a href='http://vvvvalvalval.github.io/posts/2017-07-08-Datomic-this-is-not-the-history-youre-looking-for.html'&gt;said before&lt;/a&gt;,  your application code should &lt;strong&gt;not&lt;/strong&gt; rely on history.&lt;/p&gt;&lt;h3 id=&quot;erasing&amp;#95;legacy&amp;#95;attributes&quot;&gt;Erasing legacy attributes&lt;/h3&gt;&lt;p&gt;&lt;a href='https://docs.datomic.com/on-prem/excision.html'&gt;Datomic Excision&lt;/a&gt; is the preferred way to erase values from Datomic, but is  not always a viable option:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;At the time of writing, Excision is not available on Datomic Cloud.&lt;/li&gt;&lt;li&gt;Excision will not erase the fulltext indices for &lt;code&gt;:db/fulltext&lt;/code&gt; attributes.&lt;/li&gt;&lt;li&gt;Excision can trigger massive online index rewrites, which can have a significant performance impact and effectively make you system unavailable for writes for some time.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;For such cases, there is an alternative to Excision for erasing data from your system: see  &lt;a href='https://gist.github.com/vvvvalvalval/6e1888995fe1a90722818eefae49beaf'&gt;this Gist&lt;/a&gt;.&lt;/p&gt;&lt;h2 id=&quot;experience&amp;#95;report&quot;&gt;Experience report&lt;/h2&gt;&lt;p&gt;To give you an idea about the context in which we applied these ideas:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;BandSquare is a SaaS platform which provides businesses with insights about their audiences and new ways to interact with them&lt;/li&gt;&lt;li&gt;Both business-facing and consumer-facing&lt;/li&gt;&lt;li&gt;With a broad spectrum of technical challenges, from Web / UX to Analytics and data exploration&lt;/li&gt;&lt;li&gt;BandSquare's backend is a 2-years old, 35 kLoC Clojure system&lt;/li&gt;&lt;li&gt;which uses (mostly) Datomic as the System of Records, and (mostly) ElasticSearch as a Materialized View&lt;/li&gt;&lt;li&gt;about 35M datoms in over 400 attributes&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;I was pleasantly suprised by how few places privacy-sensitive attributes appeared in: mostly signup/login, some transaction emails, ETL,  some logging and search. The vast majority of the advanced business logic simply didn't touch them.&lt;/p&gt;&lt;p&gt;The main leverage we have gotten since adopting Datomic (and Clojure along with that) has been ease of testing, a productive interactive workflow,  decoupled querying, agile information modeling, ease of debugging, and last but not least the ease of setting up derived data systems.  See &lt;a href='https://medium.com/@val.vvalval/what-datomic-brings-to-businesses-e2238a568e1c'&gt;this article&lt;/a&gt; for a more in-depth description.  These benefits have not significantly degraded since adopting this &lt;code&gt;PrivateDataStore&lt;/code&gt; approach.&lt;/p&gt;&lt;p&gt;The main regression compared to the previous architecture was the loss of code/data locality in some places, which was alleviated   by using batching reads. &lt;a href='https://github.com/nathanmarz/specter'&gt;Specter&lt;/a&gt; was instrumental in achieving clean, generic solutions  to these problems, not just by bringing expressive power, but also by bringing the right abstractions.&lt;/p&gt;&lt;p&gt;More generally, the generic data manipulation facilities of both Clojure (via its data structures) and Datomic (via its universal, reified schema)  were very useful for getting the migration done with a little, generic, well-tested code rather than a lot of application-specific code  scattered all across the codebase. Namespaced keys were very helpful to refactor reliably: its a great situation to be able to   track all the places where a piece of information is used across the whole stack with just one text search.&lt;/p&gt;&lt;p&gt;The amount of code we had to add to implement these ideas in this post is about 1200 LoC: this includes PostgreSQL and in-memory  implementations of something akin to &lt;code&gt;PrivateDataStore&lt;/code&gt;, generic helpers, and about 400 LoC of tests. It did take some trial and  error to get the abstractions right; hopefully this is a work you will not have to do having read this post.&lt;/p&gt;
</description>
<pubDate>
Tue, 01 May 2018 00:00:00 +0200
</pubDate>
</item>
<item>
<guid>
http://vvvvalvalval.github.io/posts/2018-01-06-so-yeah-about-clojures-syntax.html
</guid>
<link>
http://vvvvalvalval.github.io/posts/2018-01-06-so-yeah-about-clojures-syntax.html
</link>
<title>
So yeah, about Clojure's syntax...
</title>
<description>
&lt;p&gt;For many experienced programmers, the first encounter with Clojure's syntax ranges from slightly disturbing to downright &lt;i&gt;shocking.&lt;/i&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; Why on Earth would you put the function &lt;i&gt;inside&lt;/i&gt; the parens? That's just &lt;i&gt;weird!&lt;/i&gt; &lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;We programmers can get very emotional about syntax. I guiltily remember my Java days, and how I enjoyed the ceremony of typing  things like &lt;code&gt;protected final void etc&amp;#40;&amp;#41;{...}&lt;/code&gt;. But we also need to be pragmatic, and if we're able to overcome these subjective biases,  we can make more lucid technical decisions.&lt;/p&gt;&lt;p&gt;So the goal of this article is to help you understand &lt;i&gt;why&lt;/i&gt; some of us choose to leave the familiar comfort of C-style syntax   for this strange world of brackets and parentheses - and how rewarding it can be.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Disclaimer:&lt;/strong&gt; this article does not try to &lt;i&gt;prove&lt;/i&gt; the benefits of Clojure's syntax - merely to communicate my perception of them.  I believe the right tool for assessing language design is experience using it, not rethoric.&lt;/p&gt;&lt;h2 id=&quot;does&amp;#95;syntax&amp;#95;matter?&quot;&gt;Does syntax matter?&lt;/h2&gt;&lt;p&gt;First, let me start by saying this: &lt;strong&gt;syntax is NEVER a good reason to use or dismiss a programming language.&lt;/strong&gt;  If your approach for choosing a language is 'I (don't) like the syntax', you're doing it wrong - choosing a language for the syntax  is like choosing a car for the texture of the wheel. In practice, the semantics of a language, its execution model, its ecosystem, its performance characteristics, etc. are &lt;i&gt;always&lt;/i&gt; much more important factors - and whatever your initial think of the syntax, you get used to it.&lt;/p&gt;&lt;p&gt;Developers face many technical difficulties when building real-world systems; the most painful of these difficulties tend  to last fo years and get worse over time. So if being unfamiliar with some language syntax is your most painful problem  at work, I envy you, because you can be 100% confident that this problem will be over in a matter of days.&lt;/p&gt;&lt;p&gt;Does this mean that syntax does not matter for language design? Of course it matters!  &lt;strong&gt;Syntax matters, because it encourages or inhibits certain programming idioms.&lt;/strong&gt; You &lt;i&gt;could&lt;/i&gt; write Java programs in the same style as Clojure programs, but that would be extremely  unwieldy, to the point that no team would be willing to sustain such an effort (not to mention a whole ecosystem).&lt;/p&gt;&lt;p&gt;As we'll see, Clojure's syntax is an enabler for many desirable things.&lt;/p&gt;&lt;h2 id=&quot;the&amp;#95;ingredients&amp;#95;of&amp;#95;clojure's&amp;#95;syntax&quot;&gt;The ingredients of Clojure's syntax&lt;/h2&gt;&lt;p&gt;Clojure's syntax is simple enough that most of it can be described in a blog post.  If you're accustomed to C-lineage languages, this syntax may look scary to you; trust me,  it's only a matter of familiarity. As someone who has programmed in Java and other C-looking languages  for 8 years before using Clojure, I can testify that it's no less readable and convenient to edit.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;EDIT:&lt;/strong&gt; I realize Shaun Lebron did a better job than me at this in his article  &lt;a href='https://github.com/shaunlebron/ClojureScript-Syntax-in-15-minutes'&gt;ClojureScript syntax in 15 minutes&lt;/a&gt;.&lt;/p&gt;&lt;h3 id=&quot;data&amp;#95;literals&quot;&gt;Data literals&lt;/h3&gt;&lt;p&gt;The textual syntax of Clojure is actually just a notation for data structures. You can think of it as 'JSON on steroids':  less verbose (commas are optional), richer and extensible set of data types, maps can have arbitrary keys, etc.&lt;/p&gt;&lt;p&gt;Examples in code:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;; comments are preceded by a semicolon ';'

;;;; scalar types

0 -1 2048 3.14 3/4 6.022e23 ;; numbers
true false ;; booleans
nil ;; null / nothing
&amp;quot;hello&amp;quot; ;; strings
&amp;quot;multi
line
string&amp;quot;
;; Clojure has 2 symbolic types: keywords and symbols
:a :hello :org.my-company/foo ;; keywords - programmatic identifiers, a bit like enums, 'represent themselves', often used as keys in maps
a hello fn my.ns/foo-bar ArrayList + &amp;#42; - &amp;lt;div&amp;gt; ;; symbols - typically used to 'name' some other value

;;;; collection types

;; lists: sequential collections that 'grow at the front', delimited by parentheses &amp;#40;...&amp;#41;
&amp;#40;1 -2 42&amp;#41; ;; a list of 3 numbers
&amp;#40;:a :b :c&amp;#41; ;; a list of 3 keywords
&amp;#40;:a b &amp;quot;c&amp;quot; :d 42&amp;#41; ;; lists can be heterogeneous
&amp;#40;&amp;#41; ;; the empty list
&amp;#40;&amp;#40;&amp;#41; &amp;#40;:a b&amp;#41;&amp;#41; ;; a list of 2 lists
&amp;#40;x
 :y
 &amp;quot;z&amp;quot;&amp;#41; ;; can span multiple lines

;; vectors: also sequential collections, but 'grow at the end', and support random access &amp;#40;like arrays&amp;#41;, delimited by square brackets &amp;#91;...&amp;#93;
&amp;#91;1 -2 42&amp;#93;
&amp;#91;:a b &amp;quot;c&amp;quot;&amp;#93;
&amp;#91;&amp;#93;
&amp;#91;&amp;#40;&amp;#41;&amp;#91;&amp;#93;&amp;#91;&amp;#40;&amp;#41;&amp;#93;&amp;#93;
&amp;#91;1
 2
 3&amp;#93;

;; maps: sets of key-value pairs &amp;#40;a.k.a 'dictionaries' or 'hashes' in other languages&amp;#41;, delimited by brackets {...}
{:k1 &amp;quot;v1&amp;quot; :k2 &amp;quot;v2&amp;quot; :k3 &amp;quot;v3&amp;quot;} ;; a map of 3 key-value pairs; in this case, the keys are keywords, and the values strings
{:k1 &amp;quot;v1&amp;quot;, :k2 &amp;quot;v2&amp;quot;, :k3 &amp;quot;v3&amp;quot;} ;; you can add commas if they make you feel better; in Clojure, commas are whitespace.
{} ;; empty map
;; keys and values can be of any type, the only constraint is that keys must be distinct
{:k1 :v1
 &amp;quot;k2&amp;quot; v2
 k3 &amp;#91;:v 3&amp;#93;
 &amp;#91;&amp;#93; &amp;#40;1 2 3&amp;#41;
 12 nil
 :a {:b :c
     :d &amp;#91;:e :f&amp;#93;}
 nil true}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;So the Clojure compiler does not really compile text: instead, it compiles data structures, each data structure being  treated as an expression. Consider for example this code:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;defn square &amp;#91;x&amp;#93;
  &amp;#40;&amp;#42; x x&amp;#41;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;In terms of syntax, this is actually a &lt;i&gt;list&lt;/i&gt; of 4 elements:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;defn    ;; the symbol 'defn'
 square  ;; the symbol 'square'
 &amp;#91;x&amp;#93;     ;; a vector of 1 element, which is the symbol 'x'
 &amp;#40;&amp;#42; x x&amp;#41; ;; a list of 3 elements &amp;#40;all symbols&amp;#41;
&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;When these data structures are 'executed', some data types are evaluated using some special rules:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;symbols&lt;/strong&gt; are evaluated to the value that they 'name' (a function parameter, or a global constant, or a local variable, etc.)&lt;/li&gt;&lt;li&gt;&lt;strong&gt;lists&lt;/strong&gt; (example: &lt;code&gt;&amp;#40;op x y z...&amp;#41;&lt;/code&gt;) represent 'invoking an operation': by default invoking a function (e.g &lt;code&gt;&amp;#40;myfun x &amp;quot;y&amp;quot; 42&amp;#41;&lt;/code&gt; is equivalent to &lt;code&gt;myfun&amp;#40;x, &amp;quot;y&amp;quot;, 42&amp;#41;&lt;/code&gt; in C-style syntax), but sometimes another sort of operation.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;For instance, &lt;code&gt;&amp;#40;defn my-fun &amp;#91;x y&amp;#93; ...&amp;#41;&lt;/code&gt; is the operation: 'define a function named &lt;code&gt;my-fun&lt;/code&gt;, that has 2 arguments &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt;, etc.'&lt;/p&gt;&lt;p&gt;In particular, these special operations can be &lt;i&gt;macros&lt;/i&gt;, which we'll describe in the next section.&lt;/p&gt;&lt;h3 id=&quot;macros&quot;&gt;Macros&lt;/h3&gt;&lt;p&gt;As explained above, in Clojure, some of the operations that you call with lists are evaluated specially.&lt;/p&gt;&lt;p&gt;A handful of these special operations are built-in to the language, and called &lt;i&gt;special forms:&lt;/i&gt;,&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;;;;; examples of special forms

;; def - creates a named global constant
&amp;#40;def my-constant 42&amp;#41;

;; let - names local values
&amp;#40;let &amp;#91;x 3
      y 4&amp;#93;
  &amp;#40;+ x y&amp;#41;&amp;#41;

;; if - control flow, evaluates one expression or the other depending on the first expression's value
&amp;#40;if &amp;#40;even? n&amp;#41;
  :even
  :odd&amp;#41;

;; fn - creates an anonymous function, or 'lambda'
&amp;#40;fn &amp;#91;x&amp;#93;
  &amp;#40;&amp;#42; x x&amp;#41;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;All the other special operations are &lt;strong&gt;macros&lt;/strong&gt;.&lt;/p&gt;&lt;p&gt;Macros essentially &lt;i&gt;rewrite&lt;/i&gt; the code that you pass to them to other code: just like a function accept values and return  a value, a macro accepts code expressions and return a new code expression.&lt;/p&gt;&lt;p&gt;For instance, in Clojure, the &lt;code&gt;or&lt;/code&gt; operator (equivalent to &lt;code&gt;||&lt;/code&gt; is C-style languages) is a macro that emits code using  the lower-level &lt;code&gt;if&lt;/code&gt;:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;;; the following expression, which uses the 'or' macro:

&amp;#40;or x y z&amp;#41;

;; ...expands to something like:

&amp;#40;if x
  x
  &amp;#40;if y
    y
    &amp;#40;if z
      z
      nil&amp;#41;&amp;#41;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Importantly, in Clojure, &lt;strong&gt;the programmer can define her own macros&lt;/strong&gt;  (using &lt;a href='https://clojuredocs.org/clojure.core/defmacro'&gt;&lt;code&gt;defmacro&lt;/code&gt;&lt;/a&gt;; we won't delve into how to use it,  as that would require a proper Clojure tutorial, but it's basically just like defining a function).&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Some observations about macros:&lt;/strong&gt;&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Macros accept code expressions &lt;i&gt;as data structures&lt;/i&gt;, and return a code expression &lt;i&gt;as a data structure&lt;/i&gt;. So defining a macro consists simply of defining a function that manipulates data structures (which is what programmers do every day).&lt;/li&gt;&lt;li&gt;This 'syntax as a data notation' aspect exists precisely to make macros easy to write&lt;/li&gt;&lt;li&gt;Macros essentially let you attach 'nex meanings' to syntax.&lt;/li&gt;&lt;li&gt;You can think of macros as giving you the opportunity to transform the &lt;a href='https://en.wikipedia.org/wiki/Abstract_syntax_tree'&gt;AST&lt;/a&gt; of the program during compilation (more accurately, its Concrete Syntax Tree).&lt;/li&gt;&lt;li&gt;Macros enable 'zero-cost abstractions', i.e abstractions that have no runtime performance cost (since they operate at compile-time).&lt;/li&gt;&lt;li&gt;Macros can do anything to compute the returned expression: use previously-defined functions, make network calls, call a database, etc.&lt;/li&gt;&lt;li&gt;LISP-style macros aren't the same thing &lt;i&gt;at all&lt;/i&gt; than C/C++-style macros: don't judge the former because you've been bitten by the latter&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;If you want to know more precisely how this all works, I recommend reading &lt;a href='https://clojure.org/reference/evaluation'&gt;the reference on clojure.org&lt;/a&gt;.&lt;/p&gt;&lt;h2 id=&quot;consequences&quot;&gt;Consequences&lt;/h2&gt;&lt;h3 id=&quot;verbosity&amp;#95;is&amp;#95;a&amp;#95;solved&amp;#95;problem&quot;&gt;Verbosity is a solved problem&lt;/h3&gt;&lt;p&gt;The first consequence of having concise data literals and macros is that verbosity never gets in your way when programming:  whatever the program design you're considering, you know the code will never 'get too tedious', because you will be able  to factor out the repetition and noise from the code (more often by using existing macros than by using new ones).&lt;/p&gt;&lt;p&gt;A famous example is GUI programming in Java using the Swing toolkit, which is knowingly tedious, especially when nesting components.  The following code uses the &lt;code&gt;doto&lt;/code&gt; macro to achieve more concision and clarity than the Java equivalent, while still embracing  the original Swing API:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;doto &amp;#40;JFrame.&amp;#41;
  &amp;#40;.add &amp;#40;doto &amp;#40;JLabel. &amp;quot;Hello World&amp;quot;&amp;#41;
          &amp;#40;.setHorizontalAlignment SwingConstants/CENTER&amp;#41;&amp;#41;&amp;#41;
  .pack .show&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The Java equivalent would be:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;java&quot;&gt;JFrame f = new JFrame&amp;#40;&amp;#41;;
JLabel l = new JLabel&amp;#40;&amp;quot;Hello World&amp;quot;&amp;#41;;
l.setHorizontalAlignment&amp;#40;SwingConstants.CENTER&amp;#41;;
f.add&amp;#40;l&amp;#41;;
l.pack&amp;#40;&amp;#41;;
l.show&amp;#40;&amp;#41;;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Data literals also work towards this goal at a higher level: by encouraging you to write programs mostly as data instead of code,  which makes them fundamentally more flexible, regular, and easier to operate and instrument. Data literals, by helping you  embed data in code, make for a smooth transition from code to data.&lt;/p&gt;&lt;p&gt;A nice example of this is Datomic's &lt;a href='http://docs.datomic.com/query.html'&gt;Datalog&lt;/a&gt;, the main query language for the Datomic database.  Writing Datalog using Clojure data literals is no less concise than SQL, but it's much more &lt;i&gt;programmable&lt;/i&gt;: for instance,  generating advanced Datalog queries is much easier and more fool-proof than generating SQL queries. Example:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;ns movies-example
  &amp;#40;:require &amp;#91;datomic.api :as d&amp;#93;&amp;#41;&amp;#41;

;; example 1: a simple ordinary query
&amp;#40;defn actors-of-movie
  &amp;quot;find all actors who played in the given movie&amp;quot;
  &amp;#91;db movie-id&amp;#93;
  &amp;#40;d/query
    ;; this is Datolog, embedded in Clojure code using data literals
    '{:find &amp;#91;&amp;#91;?actor ...&amp;#93;&amp;#93;
      :in &amp;#91;$ ?movie-id&amp;#93;
      :where
      &amp;#91;&amp;#91;?movie :movie/id ?movie-id&amp;#93;
       &amp;#91;?actor :person/acted-in ?movie&amp;#93;&amp;#93;}
    db movie-id&amp;#41;&amp;#41;

;; example 2: generating a Datalog query
&amp;#40;defn movies-with-all-actors
  &amp;quot;Finds the movies starring all the given actors&amp;quot;
  &amp;#91;db actors-ids&amp;#93;
  &amp;#40;let &amp;#91;inputs &amp;#40;-&amp;gt;&amp;gt; actors-ids
                 &amp;#40;map-indexed &amp;#40;fn &amp;#91;i actor-id&amp;#93;
                                &amp;#91;&amp;#40;symbol &amp;#40;str &amp;quot;?actor-&amp;quot; i&amp;#41;&amp;#41;
                                 actor-id&amp;#93;&amp;#41;&amp;#41;&amp;#41;
        q {:find '&amp;#91;&amp;#91;?movie ...&amp;#93;&amp;#93;
           :in &amp;#40;concat '&amp;#91;$&amp;#93; &amp;#40;map first inputs&amp;#41;&amp;#41;
           :where
           &amp;#40;for &amp;#91;?actor-i &amp;#40;map first inputs&amp;#41;&amp;#93;
             &amp;#91;?actor-i :person/acted-in '?movie&amp;#93;&amp;#41;}&amp;#93;
    &amp;#40;apply d/query q
      db &amp;#40;map second inputs&amp;#41;&amp;#41;&amp;#41;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;A more extreme example of this philosophy is the &lt;a href='http://www.onyxplatform.org/'&gt;Onyx&lt;/a&gt; data processing platform,  which lets you express entire workflows using just data.&lt;/p&gt;&lt;h3 id=&quot;separation&amp;#95;of&amp;#95;concerns:&amp;#95;code&amp;#95;layout&amp;#95;⊥&amp;#95;program&amp;#95;structure&quot;&gt;Separation of concerns: code layout ⊥ program structure&lt;/h3&gt;&lt;p&gt;There is more to macros than just eliminating boilerplate: macros enable you to design your programs without having to  anticipate how the calling code is going to look, making these independent choices.&lt;/p&gt;&lt;p&gt;So you could say &lt;strong&gt;macros separate 2 concerns:&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;program structure&lt;/strong&gt; (writing programs which are reusable, flexible, composable, decoupled etc.)&lt;/li&gt;&lt;li&gt;&lt;strong&gt;code look and feel&lt;/strong&gt; (clarity, concision, organization, visual layout etc.)&lt;/li&gt;&lt;/ul&gt;&lt;h4 id=&quot;example:&amp;#95;the&amp;#95;builder&amp;#95;pattern&quot;&gt;Example: the Builder Pattern&lt;/h4&gt;&lt;p&gt;What happens when these concerns are not separated? Then programmers face dilemmas, which drag away their focus from  essential problems. One of these dilemmas is whether or not to use the &lt;a href='https://en.wikipedia.org/wiki/Builder_pattern'&gt;Builder Pattern&lt;/a&gt;.  Let's see an example of that&lt;/p&gt;&lt;p&gt;&lt;a href='http://underscorejs.org/'&gt;UnderscoreJs&lt;/a&gt; is a popular JavaScript library providing utilities for manipulating collections.  Examples:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;javascript&quot;&gt;var &amp;#95; = require&amp;#40;'underscore'&amp;#41;;

var numbers = &amp;#95;.range&amp;#40;100&amp;#41;;

// keep only the even numbers
&amp;#95;.filter&amp;#40;numbers, function&amp;#40;n&amp;#41;{return n % 2 === 0;}&amp;#41;;

// squaring the numbers
&amp;#95;.map&amp;#40;numbers, function&amp;#40;n&amp;#41;{return n &amp;#42; n;}&amp;#41;;

// summing the numbers
&amp;#95;.reduce&amp;#40;numbers, function&amp;#40;sum, n&amp;#41;{return sum + n;}, 0&amp;#41;;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;These functions are powerful, but chaining them can be impractical. Continuing with our example, imagine you want to sum  the squares of even numbers smaller than 100:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;javascript&quot;&gt;&amp;#95;.reduce&amp;#40;
  &amp;#95;.map&amp;#40;
    &amp;#95;.filter&amp;#40;
      &amp;#95;.range&amp;#40;100&amp;#41;,
      function&amp;#40;n&amp;#41;{return n % 2 === 0;}&amp;#41;,
    function&amp;#40;n&amp;#41;{return n &amp;#42; n;}&amp;#41;,
  function&amp;#40;sum, n&amp;#41;{return sum + n;},
  0&amp;#41;;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;You see the readability problem with this code: it displays the operations as nested from the inside out, when we think  of them as successive.&lt;/p&gt;&lt;p&gt;UnderscoreJs addresses this problem by providing a &lt;code&gt;chain&lt;/code&gt; operation, which uses the Builder Pattern to make the code  'look' chained:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;javascript&quot;&gt;&amp;#95;.chain&amp;#40;&amp;#95;.range&amp;#40;100&amp;#41;&amp;#41;
 .filter&amp;#40;function&amp;#40;n&amp;#41;{return n % 2 === 0;}&amp;#41;
 .map&amp;#40;function&amp;#40;n&amp;#41;{return n &amp;#42; n;}&amp;#41;
 .reduce&amp;#40;function&amp;#40;sum, n&amp;#41;{return sum + n;}, 0&amp;#41;
 .value&amp;#40;&amp;#41;;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This approach solves the surface readability problem, but brings new, deeper problems:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;The set of operations available in a &lt;code&gt;&amp;#95;.chain&amp;#40;&amp;#41; &amp;#40;...&amp;#41; .value&amp;#40;&amp;#41;&lt;/code&gt; context is not extensible, making it hostile to abstraction. For instance, you can no longer contract the 'square' and 'sum' steps into a single 'sumSquares' step - which you could easily do when using plain old functions.&lt;/li&gt;&lt;li&gt;The source code of the underlying operation is much harder to write and reason about. How long would it take you to re-implement a robust version of &lt;code&gt;&amp;#95;.chain&lt;/code&gt;?&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Now let's see how Clojure does when applied to the same problem. Clojure's standard library provides similar functions  to UnderscoreJs:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;def numbers &amp;#40;range 100&amp;#41;&amp;#41;

&amp;#40;filter &amp;#40;fn &amp;#91;n&amp;#93; &amp;#40;= &amp;#40;mod n 2&amp;#41; 0&amp;#41;&amp;#41; numbers&amp;#41;

&amp;#40;map &amp;#40;fn &amp;#91;n&amp;#93; &amp;#40;&amp;#42; n n&amp;#41;&amp;#41; numbers&amp;#41;

&amp;#40;reduce + 0 numbers&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Chaining these functions calls directly by nesting them looks just as messy as it did in JS:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;reduce + 0
  &amp;#40;map &amp;#40;fn &amp;#91;n&amp;#93; &amp;#40;&amp;#42; n n&amp;#41;&amp;#41;
    &amp;#40;filter &amp;#40;fn &amp;#91;n&amp;#93; &amp;#40;= &amp;#40;mod n 2&amp;#41; 0&amp;#41;&amp;#41;
      &amp;#40;range 100&amp;#41;&amp;#41;&amp;#41;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;However, Clojure gives us a very nice tool for solving the readability problem: the &lt;a href='http://clojuredocs.org/clojure.core/-%3E%3E'&gt;&lt;code&gt;-&amp;gt;&amp;gt;&lt;/code&gt;&lt;/a&gt; (pronounce: 'thread last') macro:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;-&amp;gt;&amp;gt; &amp;#40;range 100&amp;#41;
  &amp;#40;filter &amp;#40;fn &amp;#91;n&amp;#93; &amp;#40;= &amp;#40;mod n 2&amp;#41; 0&amp;#41;&amp;#41;&amp;#41;
  &amp;#40;map &amp;#40;fn &amp;#91;n&amp;#93; &amp;#40;&amp;#42; n n&amp;#41;&amp;#41;&amp;#41;
  &amp;#40;reduce + 0&amp;#41;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This code is much clearer, and I want to emphasize that &lt;code&gt;map&lt;/code&gt;, &lt;code&gt;filter&lt;/code&gt; and &lt;code&gt;reduce&lt;/code&gt; are exactly the same functions here as  we used above. Actually, all &lt;code&gt;-&amp;gt;&amp;gt;&lt;/code&gt; does is 're-write' the code in the previous, messy form, as we can verify using &lt;code&gt;macroexpand&lt;/code&gt;:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;macroexpand
  '&amp;#40;-&amp;gt;&amp;gt; &amp;#40;range 100&amp;#41;
     &amp;#40;filter &amp;#40;fn &amp;#91;n&amp;#93; &amp;#40;= &amp;#40;mod n 2&amp;#41; 0&amp;#41;&amp;#41;&amp;#41;
     &amp;#40;map &amp;#40;fn &amp;#91;n&amp;#93; &amp;#40;&amp;#42; n n&amp;#41;&amp;#41;&amp;#41;
     &amp;#40;reduce + 0&amp;#41;&amp;#41;&amp;#41;
=&amp;gt; &amp;#40;reduce + 0 &amp;#40;map &amp;#40;fn &amp;#91;n&amp;#93; &amp;#40;&amp;#42; n n&amp;#41;&amp;#41; &amp;#40;filter &amp;#40;fn &amp;#91;n&amp;#93; &amp;#40;= &amp;#40;mod n 2&amp;#41; 0&amp;#41;&amp;#41; &amp;#40;range 100&amp;#41;&amp;#41;&amp;#41;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;code&gt;-&amp;gt;&amp;gt;&lt;/code&gt; is also fairly easy to implement: all you have to do is think of the expressions as data structure, and  re-arrange them to the desired form. Here's an implementation off the top of my head:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;defmacro -&amp;gt;&amp;gt;
  &amp;#91;start &amp;amp; more&amp;#93;
  &amp;#40;reduce
    &amp;#40;fn &amp;#91;inner outer&amp;#93;
      &amp;#40;let &amp;#91;outer &amp;#40;if &amp;#40;list? outer&amp;#41; outer &amp;#40;list outer&amp;#41;&amp;#41;&amp;#93;
        &amp;#40;into &amp;#40;list inner&amp;#41; &amp;#40;reverse outer&amp;#41;&amp;#41;&amp;#41;&amp;#41;
    start more&amp;#41;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;What's neat about the above solution is that &lt;strong&gt;we haven't compromised at all on program structure in order to make the code pretty.&lt;/strong&gt;  We just composed 2 orthogonal tools, each solving a separate concern:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;a &lt;strong&gt;syntactic tool&lt;/strong&gt; (the &lt;code&gt;-&amp;gt;&amp;gt;&lt;/code&gt; macro) to solve a syntactic problem (organizing the code visually)&lt;/li&gt;&lt;li&gt;a &lt;strong&gt;semantic tool&lt;/strong&gt; (the &lt;code&gt;map&lt;/code&gt; / &lt;code&gt;filter&lt;/code&gt; / &lt;code&gt;reduce&lt;/code&gt; functions) to make a correct, well-structured program.&lt;/li&gt;&lt;/ul&gt;&lt;h3 id=&quot;code&amp;#95;=&amp;#95;data&amp;#95;=&amp;#95;data&amp;#95;viz&quot;&gt;Code = Data = Data Viz&lt;/h3&gt;&lt;p&gt;There's a famous Lisp aphorism that &lt;i&gt;'code is data'&lt;/i&gt;, meaning that the syntax for Lisp is a &lt;i&gt;notation&lt;/i&gt; for data structures  that can easily be manipulated by the language (after all, LISP stands for LISt Processing). In the case of Clojure, these  data structures are lists, vectors and maps. This is what makes macros so easy to write in Clojure.&lt;/p&gt;&lt;p&gt;Another aspect of Clojure's syntax, as we saw above, is that it's a very human-friendly notation for structured data.  As such, Clojure's syntax is a good tool for doing &lt;strong&gt;both data reprensentation and data visualization.&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;This last aspect is critical to Clojure's interactive development story. When you evaluate an expression at the Clojure  REPL, the result is presented to you in Clojure's syntax: this makes it easy to analyze (especially when pretty-printed  and syntax-highlighted), but it also makes it immediately available as a code expression, to be reused for further exploration  or persisted in source files.&lt;/p&gt;&lt;p&gt;&lt;a href='https://vimeo.com/230220635'&gt;&lt;img src=&quot;/img/repl.gif&quot; width=&quot;100%&quot;&gt;&lt;/img&gt;&lt;/a&gt;&lt;/p&gt;&lt;h3 id=&quot;tooling&amp;#95;as&amp;#95;libraries&quot;&gt;Tooling as libraries&lt;/h3&gt;&lt;p&gt;When you have macros, a huge part of the external tools that are commonplace in other languages become obsolete.  Macros are typically used as a replacement for:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;source code generation / transformation&lt;/li&gt;&lt;li&gt;debugging tools&lt;/li&gt;&lt;li&gt;syntax extensions / 'transpilers'&lt;/li&gt;&lt;li&gt;bytecode manipulation&lt;/li&gt;&lt;li&gt;annotations&lt;/li&gt;&lt;li&gt;documentation generation&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Macros have several advantages in this area:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;they're easy to install, since they're available as libraries&lt;/li&gt;&lt;li&gt;they're portable (a macro is not limited to Build Tool X or Editor Y or Framework Z)&lt;/li&gt;&lt;li&gt;they require little effort to create (it typically takes a few week-ends to a lone developer to make such a library, not a few months to an engineering department at a big company)&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;div class=&quot;my-tweet-wrapper&quot;&gt;  &lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;  “I don’t need macros, they’re too complicated and not useful,” says the programmer as they use Flow with JSX with Babel with two dozen plugins and maintain two hundred line webpack configs for code with machine-checked comments that parses CSS in template strings at runtime and—&lt;/p&gt;&amp;mdash; Alexis King (@lexi_lambda)  &lt;a href='https://twitter.com/lexi_lambda/status/948435311058599936?ref_src=twsrc%5Etfw'&gt;January 3, 2018&lt;/a&gt;  &lt;/blockquote&gt; &lt;/div&gt;&lt;/p&gt;&lt;h3 id=&quot;an&amp;#95;'all-tracks'&amp;#95;language:&amp;#95;embedding&amp;#95;paradigms&quot;&gt;An 'all-tracks' language: embedding paradigms&lt;/h3&gt;&lt;p&gt;Every non-trivial applications sooner or later reaches a point where it cannot be served well  with just one programming paradigm. Some part of your program may need a declarative way of  building UI trees (HTML templating / PHP / JSP / ERB / etc.), whereas another just needs some  procedural glue. Some parts of your business logic may be well expressed in a functional style,  when some other would benefit more from using logic programming (Prolog, MiniKanren) or  a production rules system. Some computation may need an imperative algorithm (e.g in C), when others  are best expressed as graphs of computational steps.&lt;/p&gt;&lt;p&gt;Because Clojure's syntax is not opinionated about semantics (remember, it's just data structures),  it welcomes any programming paradigm; and because it's so programmable (again, it's just data structures),  it lets users provide implementations of those paradigms as libraries (either by building interpreters for structures,  or via macros).&lt;/p&gt;&lt;p&gt;The 'default' paradigm of Clojure is dynamically-typed, functional programming, i.e lambda-expressions  evaluating to generic, immutable data structures, or functions of those. However, many other paradigms  are available as libraries, for example:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Logic programming (&lt;a href='https://github.com/clojure/core.logic'&gt;core.logic&lt;/a&gt;)&lt;/li&gt;&lt;li&gt;Production rules (&lt;a href='http://www.clara-rules.org/'&gt;Clara Rules&lt;/a&gt;)&lt;/li&gt;&lt;li&gt;ML-style Pattern Matching (&lt;a href='https://github.com/clojure/core.match/wiki/Overview'&gt;core.match&lt;/a&gt;)&lt;/li&gt;&lt;li&gt;'DAG computing' (&lt;a href='https://github.com/plumatic/plumbing#graph-the-functional-swiss-army-knife'&gt;Plumatic/Graph&lt;/a&gt;)&lt;/li&gt;&lt;li&gt;SQL querying (&lt;a href='https://github.com/jkk/honeysql'&gt;HoneySQL&lt;/a&gt;)&lt;/li&gt;&lt;li&gt;Golang-style CSPs (&lt;a href='https://github.com/clojure/core.async'&gt;core.async&lt;/a&gt;)&lt;/li&gt;&lt;li&gt;Static type checking (&lt;a href='https://github.com/clojure/core.typed'&gt;core.typed&lt;/a&gt;)&lt;/li&gt;&lt;li&gt;HTML templating (&lt;a href='https://github.com/weavejester/hiccup'&gt;Hiccup&lt;/a&gt;), CSS (&lt;a href='https://github.com/noprompt/garden'&gt;Garden&lt;/a&gt;)&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Having one syntax to host all these paradigms makes it much more practical to compose them together,  because their implementations can &lt;strong&gt;share a lot of the language's infrastructure&lt;/strong&gt; (runtime, editors, tooling,  dependency management, code modularization, etc.)&lt;/p&gt;&lt;p&gt;You could however argue that having different syntaxes for different paradigms is beneficial,  because using them in separate source files forces programmers to separate concerns.  That's not the case in my experience, because &lt;strong&gt;in a typical program, different paradigms don't address different concerns, rather different aspects of the same concern.&lt;/strong&gt;&lt;/p&gt;&lt;h4 id=&quot;example:&amp;#95;web&amp;#95;uis&quot;&gt;Example: Web UIs&lt;/h4&gt;&lt;p&gt;For example, one of the biggest lies that are told to novice Web programmers is that  HTML, CSS and JavaScript are respectively for content, style and logic. For today's web  applications, this is not true at all, and trying to enforce this separation actually creates  much more complexity than it eliminates. The reasons for this separation are actually historical;  the modern best practice is to separate UI into &lt;i&gt;components&lt;/i&gt;, each component having its own  DOM templating, styles and logic. In the JavaScript world, inline styles and JSX are approaches  for co-locating them in code.&lt;/p&gt;&lt;p&gt;Here's an example of such a component in ClojureScript, from one of my personal projects.  Note that this is just plain old Clojure: no build tooling is involved in making this work.&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;ns m12.widgets.gtab
  &amp;#40;:require &amp;#91;rum.core :as rum&amp;#93;
            &amp;#91;m12.widgets.ui-toolkit :as utk&amp;#93;&amp;#41;
  &amp;#40;:require-macros
    &amp;#91;rum.core :as rum :refer &amp;#91;defc defcs&amp;#93;&amp;#93;&amp;#93;&amp;#41;&amp;#41;

;; a 'guitar tablature' component
&amp;#40;defc &amp;lt;guitar-tab&amp;gt; &amp;lt; rum/static rum/reactive
  &amp;#91;props
   {:as opts, :keys &amp;#91;n-strings length string-heights&amp;#93;
    :or {n-strings 6}}
   items content&amp;#93;
  &amp;#40;let &amp;#91;strings-items &amp;#40;group-by ::string items&amp;#41;&amp;#93;
    &amp;#91;:div.gtab props
     &amp;#40;for &amp;#91;i &amp;#40;range n-strings&amp;#41;&amp;#93;
       &amp;#91;:div.gtab-string {:key &amp;#40;str &amp;quot;gtr-string-&amp;quot; i&amp;#41;}
        &amp;#91;:div.gtab-string-inner
         &amp;#40;-&amp;gt;&amp;gt; &amp;#40;strings-items i&amp;#41;
           &amp;#40;map-indexed
             &amp;#40;fn &amp;#91;k {:as item, x ::x}&amp;#93;
               &amp;#91;:div.gtab-item
                {:style {:left &amp;#40;str &amp;#40;&amp;#42; 100 &amp;#40;/ x length&amp;#41;&amp;#41; &amp;quot;%&amp;quot;&amp;#41;}
                 :key &amp;#40;str &amp;quot;gtab-item-&amp;quot; k&amp;#41;}
                &amp;#40;content item i&amp;#41;&amp;#93;
               &amp;#41;&amp;#41;&amp;#41;&amp;#93;
        &amp;#40;when-let &amp;#91;h &amp;#40;get string-heights i&amp;#41;&amp;#93;
          &amp;#91;:div.gtab-item.gtab-string-height
           &amp;#91;:div.gtab-note &amp;#40;utk/&amp;lt;height&amp;gt; h&amp;#41;&amp;#93;&amp;#93;&amp;#41;&amp;#93;&amp;#41;&amp;#93;&amp;#41;&amp;#41;

;; ...
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;saner&amp;#95;language&amp;#95;stewardship&quot;&gt;Saner language stewardship&lt;/h3&gt;&lt;p&gt;History has shown than one of the most important guidelines in developing a programming language  is preserving its ability to evolve, because language developers cannot anticipate all the future  needs of their users. Guy Steele articulated this very well in his talk  &lt;a href='https://www.youtube.com/watch?v=_ahvzDzKdB0'&gt;Growing a Language&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/_ahvzDzKdB0&quot; frameborder=&quot;0&quot; gesture=&quot;media&quot; allow=&quot;encrypted-media&quot; allowfullscreen&gt;&lt;/iframe&gt;&lt;/p&gt;&lt;p&gt;Macros play an interesting role in this regard, because they essentially enable users to 'add features'  to the language. For instance, Clojure does not natively ship with ML-style pattern matching, encouraging  instead a combination of destructuring and polymorphism (via &lt;a href='https://clojure.org/reference/multimethods'&gt;multimethods&lt;/a&gt;).  However, the &lt;a href='https://github.com/clojure/core.match/wiki/Overview'&gt;core.match&lt;/a&gt;  library provides a macro for pattern-matching when that's really a better fit.&lt;/p&gt;&lt;p&gt;Macros have the implication that, if some Clojure users are missing some language features for a particular project,  they can write it themselves right away, instead of having to lobby the core developers of the language.  They can make this new feature available as a library, and if not everyone agrees that this feature is beneficial, well,  not everyone has to use the library. Eventually, there may be a consensus that this feature should be added  to the core of the language, and by that time there will be empirical evidence that it's really useful. It also  means that the language developers can focus on the long-term, strategic evolutions of the language, instead  of solving the specific, short-term needs of their users.&lt;/p&gt;&lt;p&gt;What happens when users can't extend the language? Then language developers take various approaches  to handle requests from the users. Some languages are very conservative and just leave their users wanting,  which is bad enough, especially when it leads the users to hack around this limitation by adding 'language features'  via tooling (see for example the proliferation of 'transpiler' plugins in the JS ecosystem).&lt;/p&gt;&lt;p&gt;Some languages take the opposite approach and will add new language features as quickly as possible,  which is even worse. &lt;strong&gt;Adding features too readily to the core of a language will please some users on the short term, but can have very bad consequences to its ecosystem on the long term:&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;It adds complexity to the language, which makes it harder to learn for beginners and harder to maintain for language developers&lt;/li&gt;&lt;li&gt;It creates a 'combinatorial explosion' of programming styles, which paralyzes programmers when writing code (&quot;Should I use a lambda for this? Or maybe a block? Or maybe a subclass? ...&quot;) and puzzles them when reading code written by others&lt;/li&gt;&lt;li&gt;Some language features seem like elegant ideas, then experience proves they're just harmful&lt;/li&gt;&lt;li&gt;As more and more features get added, the 'idiomatic way' to code evolves significantly, encouraging major (often breaking) changes in the ecosystem (PHP would be a good example of that)&lt;/li&gt;&lt;li&gt;When a new feature is added to the core of a language, it encourages all users to use it, even if only an influent minority actually needs it.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;In contrast, growing the language via libraries mitigates these issues, because you have more nuanced options than 'add feature X or leave it out'.&lt;/p&gt;&lt;p&gt;&lt;div class=&quot;my-tweet-wrapper&quot;&gt; &lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot; data-cards=&quot;show&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;stable core with additive innovation in libraries &lt;a href=&quot;https://twitter.com/hashtag/clojure?src=hash&amp;amp;ref&lt;i&gt;src=twsrc%5Etfw&quot;&gt;#clojure&lt;/a&gt; &lt;a href=&quot;https://t.co/dhBYdEWSRB&quot;&gt;https://t.co/dhBYdEWSRB&lt;/a&gt;&lt;/p&gt;&amp;mdash; stuarthalloway (@stuarthalloway) &lt;a href=&quot;https://twitter.com/stuarthalloway/status/949343240435720198?ref&lt;/i&gt;src=twsrc%5Etfw&quot;&gt;January 5, 2018&lt;/a&gt;&lt;/blockquote&gt; &lt;/div&gt;&lt;/p&gt;&lt;p&gt;Having said that, you could reasonably argue that giving &lt;i&gt;every&lt;/i&gt; user the ability to extend the language gives them  more power to shoot themselves in the foot. From what I've seen, this hasn't really be the case with Clojure so far:  only a minority of Clojure programmers write macros, and the 'leadership' of the language has done a good job  educating the community to the perils of macros.&lt;/p&gt;&lt;p&gt;Finally, this 'growing via libraries' aspect has led Clojure to be a very stable language: its users aren't really  asking for new features. In this sense, Clojure is more mature than older, mainstream languages like JavaScript and Java,  which keep undergoing major evolutions (most of which are welcomed, but with unforeseen consequences).&lt;/p&gt;&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;&lt;p&gt;Because Clojure's syntax is just an effective notation for data structures, it serves as a generic representation  for structured thought. Macros can then be used to attach new &lt;i&gt;meanings&lt;/i&gt; to syntax, which relieves programmers of  many incidental concerns, and has been an 'unfair advantage' to Clojure's ecosystem, allowing it with relatively little effort  to achieve very good stability and tooling, while providing access to a rich set of programming paradigms.&lt;/p&gt;&lt;p&gt;Again, I realize these are bold claims. If you're skeptical, I would encourage you to give Clojure a try and make your own mind.&lt;/p&gt;&lt;p&gt;Finally, it should be noted that a lot of what was said above applies to other languages of the LISP family, not just Clojure.&lt;/p&gt;
</description>
<pubDate>
Sat, 06 Jan 2018 00:00:00 +0100
</pubDate>
</item>
<item>
<guid>
http://vvvvalvalval.github.io/posts/using-postgresql-temporary-views-for-expressing-business-logic.html
</guid>
<link>
http://vvvvalvalval.github.io/posts/using-postgresql-temporary-views-for-expressing-business-logic.html
</link>
<title>
Using PostgreSQL temporary views for expressing business logic
</title>
<description>
&lt;p&gt;I recently worked on a project which consisted of merging related data exports from a variety of sources and extracting  accounting information from them. Because the problem was inherently very relational, I was naturally led to use an SQL  database in the project (in this case PostgreSQL).&lt;/p&gt;&lt;p&gt;I ended up expressing much more of the business logic than I thought using pure SQL - more precisely, &lt;i&gt;temporary SQL Views&lt;/i&gt; -  so I thought I'd share my findings here.&lt;/p&gt;&lt;h2 id=&quot;why&amp;#95;sql?&quot;&gt;Why SQL?&lt;/h2&gt;&lt;p&gt;A lot of programmers think of SQL merely as a protocol for interacting with data storage, and prefer to express  domain logic in a general-purpose language (JavaScript, Ruby, C#, ...). It's a shame, because SQL is actually very expressive!  When applied to business logic, SQL can make for programs that are not only more concise and readable, but also more &lt;strong&gt;declarative&lt;/strong&gt;  (that is, programs that express only their intent, not how to achieve it) which is a very effective way of eliminating  &lt;a href='https://github.com/papers-we-love/papers-we-love/blob/master/design/out-of-the-tar-pit.pdf'&gt;accidental complexity&lt;/a&gt; from your code.&lt;/p&gt;&lt;p&gt;More concretely, I believe the advantages of SQL come from:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;relations being &lt;strong&gt;more powerful data abstractions&lt;/strong&gt; than the ones available in general-purpose languages (arrays, structs, maps, lists, objects etc.)&lt;/li&gt;&lt;li&gt;the fact that the data is centralized and &lt;i&gt;at hand&lt;/i&gt; eliminates many difficult concerns associated with moving data (encoding and packaging the data, validation, distributed systems issues etc.)&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Modern SQL engines such as &lt;a href='https://www.postgresql.org/'&gt;PostgreSQL&lt;/a&gt; also offer several practical benefits:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;they provide an &lt;strong&gt;interactive&lt;/strong&gt; programming environment&lt;/li&gt;&lt;li&gt;they come with an expressive, yet relatively flexible &lt;strong&gt;static type system&lt;/strong&gt;&lt;/li&gt;&lt;li&gt;they achieve quite good &lt;strong&gt;performance&lt;/strong&gt; for the level of abstraction for which you typically use them&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Finally, SQL is very &lt;strong&gt;portable&lt;/strong&gt;. SQL is much more universally known that JavaScript / Ruby / C# / etc., which means SQL  code is more accessible and reusable. Fun fact: this was quite useful for the data processing project I mentioned. For  reasons inherent to the company, it had to be shipped in PHP, but since PHP makes for a poor experimental environment for  data manipulation, I did the 'exploratory' phase of the project in Clojure then migrated it to PHP. Because most of the advanced  logic was expressed in SQL, I was able to do the migration without too much effort, while having explored the domain with  a fast feedback loop.&lt;/p&gt;&lt;h2 id=&quot;why&amp;#95;sql&amp;#95;views?&quot;&gt;Why SQL views?&lt;/h2&gt;&lt;p&gt;&lt;a href='https://www.postgresql.org/docs/current/static/sql-createview.html'&gt;SQL views&lt;/a&gt; are the primary mechanism for abstraction in SQL, playing a similar  role to functions in procedural languages, or methods in class-based languages:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;they factor our repetition, by replacing an SQL expression with a name&lt;/li&gt;&lt;li&gt;they hide implementation details: code that calls a view only knows the shape of the data, not how it is computed&lt;/li&gt;&lt;li&gt;they provide a level of indirection between how data is stored and how it is queried&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;So SQL views are quite effective; however, the fact that they're stored durably by default brings several operational problems.  This is where &lt;strong&gt;temporary views&lt;/strong&gt; come in, as we'll see in the next section.&lt;/p&gt;&lt;h3 id=&quot;example:&amp;#95;e-commerce&amp;#95;cash&amp;#95;flow&quot;&gt;Example: e-commerce cash flow&lt;/h3&gt;&lt;p&gt;As an example, imagine you have to compute the cash flow of an e-commerce company. Here are the business requirements:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;The company receives money via Orders: each Order consists of several Line Items, each Line Item being a certain quantity of a Product&lt;/li&gt;&lt;li&gt;The company spends money via Purchases&lt;/li&gt;&lt;li&gt;The cash flow consists of the Cash Movements corresponding to Orders and Purchases&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;This can be expressed with the following SQL:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;sql&quot;&gt;CREATE VIEW orders&amp;#95;cash&amp;#95;movements AS &amp;#40;
  SELECT
    order&amp;#95;id,
    order&amp;#95;time AS cash&amp;#95;movement&amp;#95;time,
    SUM&amp;#40;li&amp;#95;amount&amp;#41; AS cash&amp;#95;movement&amp;#95;amount
  FROM &amp;#40;
    SELECT
      o.order&amp;#95;id,
      o.order&amp;#95;time,
      &amp;#40;li.line&amp;#95;item&amp;#95;quantity &amp;#42; p.product&amp;#95;price&amp;#41; AS li&amp;#95;amount
    FROM orders o
    JOIN line&amp;#95;items li ON li.order&amp;#95;id = o.order&amp;#95;id
    JOIN products p ON li.product&amp;#95;id = p.product&amp;#95;id
  &amp;#41; AS li
  GROUP BY order&amp;#95;id, order&amp;#95;time
&amp;#41;;

CREATE VIEW purchases&amp;#95;cash&amp;#95;movements AS &amp;#40;
  SELECT
    purchase&amp;#95;id,
    purchase&amp;#95;time AS cash&amp;#95;movement&amp;#95;time,
    &amp;#40;-1 &amp;#42; purchase&amp;#95;amount&amp;#41; AS cash&amp;#95;movement&amp;#95;amount
  FROM purchases
&amp;#41;;

CREATE VIEW cash&amp;#95;movements AS &amp;#40;
  SELECT cash&amp;#95;movement&amp;#95;time, cash&amp;#95;movement&amp;#95;amount FROM orders&amp;#95;cash&amp;#95;movements
  UNION ALL
  SELECT cash&amp;#95;movement&amp;#95;time, cash&amp;#95;movement&amp;#95;amount FROM purchases&amp;#95;cash&amp;#95;movements
&amp;#41;;

&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;why&amp;#95;temporary&amp;#95;views?&quot;&gt;Why temporary views?&lt;/h2&gt;&lt;h3 id=&quot;durable&amp;#95;information,&amp;#95;ephemeral&amp;#95;logic&quot;&gt;Durable information, ephemeral logic&lt;/h3&gt;&lt;p&gt;Let's go back to the basics: an &lt;i&gt;information system&lt;/i&gt; consists of:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;information&lt;/strong&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;business logic&lt;/strong&gt; processing this information&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;We usually want information to be &lt;strong&gt;stored durably&lt;/strong&gt;, because we don't want to lose any of it.&lt;/p&gt;&lt;p&gt;On the other hand, we typically &lt;strong&gt;don't want to commit durably to our business logic&lt;/strong&gt;; we want to be able to change our minds  about how our business logic handles information (because we made a bug, because business requirements changed, etc.)&lt;/p&gt;&lt;p&gt;This is why information systems are traditionally made of a durable database storing raw information, and processes executing  business-logic code in an ephemeral way (usually written in languages such as JavaScript / C# / Ruby / etc.)&lt;/p&gt;&lt;h3 id=&quot;the&amp;#95;problem&amp;#95;with&amp;#95;stored&amp;#95;sql&amp;#95;views&quot;&gt;The problem with stored SQL views&lt;/h3&gt;&lt;p&gt;The problem with ordinary SQL views is that they don't have this 'ephemeral' property: if you want to change the logic of  an SQL view, you have to make a database migration, which will affect all the database clients at the same time, making it  difficult to manage operationally. For many applications, this operational overhead is a deal breaker for using SQL views.&lt;/p&gt;&lt;h3 id=&quot;temporary&amp;#95;views&amp;#95;to&amp;#95;the&amp;#95;rescue!&quot;&gt;TEMPORARY views to the rescue!&lt;/h3&gt;&lt;p&gt;This is why &lt;a href='https://www.postgresql.org/docs/current/static/sql-createview.html'&gt;&lt;strong&gt;temporary&lt;/strong&gt; SQL views&lt;/a&gt; are useful.  A temporary SQL view is scoped to an SQL session, which means that both its visibility and its lifecycle will be limited  to a single database client.&lt;/p&gt;&lt;h3 id=&quot;how&amp;#95;do&amp;#95;you&amp;#95;use&amp;#95;temporary&amp;#95;views?&quot;&gt;How do you use temporary views?&lt;/h3&gt;&lt;p&gt;You define a temporary view in SQL code by adding the TEMPORARY keyword to the CREATE VIEW command.  Continuing with our cash flow example:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;sql&quot;&gt;CREATE TEMPORARY VIEW orders&amp;#95;cash&amp;#95;movements AS &amp;#40;
  -- &amp;#91;...&amp;#93;
&amp;#41;;

CREATE TEMPORARY VIEW purchases&amp;#95;cash&amp;#95;movements AS &amp;#40;
  -- &amp;#91;...&amp;#93;
&amp;#41;;

CREATE TEMPORARY VIEW cash&amp;#95;movements AS &amp;#40;
  -- &amp;#91;...&amp;#93;
&amp;#41;;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;These &lt;code&gt;CREATE TEMPORARY VIEW&lt;/code&gt; commands should be executed once each time a database connection is created.  Modern SQL connection pooling libraries can be configured to execute an SQL statement each time a connection is created;  for instance, for the &lt;a href='https://github.com/brettwooldridge/HikariCP'&gt;HikariCP&lt;/a&gt; library,  this is the done via the &lt;code&gt;connectionInitSql&lt;/code&gt; option.&lt;/p&gt;&lt;h3 id=&quot;caching&amp;#95;without&amp;#95;materialized&amp;#95;views&quot;&gt;Caching without Materialized Views&lt;/h3&gt;&lt;p&gt;A popular strategy for caching with PostgreSQL is to use &lt;a href='https://www.postgresql.org/docs/current/static/rules-materializedviews.html'&gt;Materialized Views&lt;/a&gt;.  For instance, we could use a Materialized View to cache our cash flow computation example:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;sql&quot;&gt;-- WON'T WORK

-- defining the materialized view
CREATE MATERIALIZED VIEW cash&amp;#95;flow&amp;#95;cache&amp;#95;v0 AS &amp;#40;
  SELECT &amp;#42; FROM cash&amp;#95;movements;
&amp;#41;;

-- &amp;#91;...&amp;#93;

-- refreshing the materialized view
REFRESH MATERIALIZED VIEW cash&amp;#95;flow&amp;#95;cache&amp;#95;v0;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This won't work, because a PostgreSQL Materialized View is a durable object, whereas a Temporary View is a temporary object;  therefore, a Materialized View cannot depend on a Temporary View.&lt;/p&gt;&lt;p&gt;One way to circumvent this limitation is to define only the schema for the cache table, and let the client refresh the caching  table with a plain old query:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;sql&quot;&gt;-- defining the cache table
CREATE TABLE cash&amp;#95;flow&amp;#95;cache&amp;#95;v0 &amp;#40;
  cash&amp;#95;movement&amp;#95;time TIMESTAMP,
  cash&amp;#95;movement&amp;#95;amount INTEGER
&amp;#41;;

-- &amp;#91;...&amp;#93;

-- refreshing the cache table
-- &amp;#40;preferrable to do this in a transaction&amp;#41;

TRUNCATE TABLE cash&amp;#95;flow&amp;#95;cache&amp;#95;v0;
INSERT INTO cash&amp;#95;flow&amp;#95;cache&amp;#95;v0 &amp;#40;cash&amp;#95;movement&amp;#95;time, cash&amp;#95;movement&amp;#95;amount&amp;#41;
  SELECT cash&amp;#95;movement&amp;#95;time, cash&amp;#95;movement&amp;#95;amount FROM cash&amp;#95;movements;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This has the advantage of minimizing the amount of business logic that we need to put in our stored caching code.&lt;/p&gt;&lt;h2 id=&quot;what's&amp;#95;missing:&amp;#95;'parameterized'&amp;#95;temporary&amp;#95;views&quot;&gt;What's missing: 'parameterized' temporary views&lt;/h2&gt;&lt;p&gt;One thing I've found to be lacking in SQL is the ability to define views that are parameterized with other values -  in particular, parameterized with other relations.&lt;/p&gt;&lt;p&gt;For instance, going back to our cash flow example, imagine we want to compute the following aggregations:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;revenue per day&lt;/li&gt;&lt;li&gt;expenses per day&lt;/li&gt;&lt;li&gt;total cash flow per day&lt;/li&gt;&lt;/ul&gt;&lt;pre&gt;&lt;code&gt;CREATE TEMPORARY VIEW revenue&amp;#95;per&amp;#95;day AS &amp;#40;
  SELECT day, SUM&amp;#40;cash&amp;#95;movement&amp;#95;amount&amp;#41; AS amount
  FROM &amp;#40;
    SELECT
      date&amp;#95;trunc&amp;#40;cash&amp;#95;movement&amp;#95;time, 'day'&amp;#41; AS day,
      cash&amp;#95;movement&amp;#95;amount
    FROM cash&amp;#95;movements
    WHERE cash&amp;#95;movement&amp;#95;amount &amp;gt; 0
  &amp;#41; AS x
  GROUP BY day
&amp;#41;;

CREATE TEMPORARY VIEW expenses&amp;#95;per&amp;#95;day AS &amp;#40;
  SELECT day, SUM&amp;#40;cash&amp;#95;movement&amp;#95;amount&amp;#41; AS amount
  FROM &amp;#40;
    SELECT
      date&amp;#95;trunc&amp;#40;cash&amp;#95;movement&amp;#95;time, 'day'&amp;#41; AS day,
      cash&amp;#95;movement&amp;#95;amount
    FROM cash&amp;#95;movements
    WHERE cash&amp;#95;movement&amp;#95;amount &amp;lt; 0
  &amp;#41; AS x
  GROUP BY day
&amp;#41;;

CREATE TEMPORARY VIEW cash&amp;#95;flow&amp;#95;per&amp;#95;day AS &amp;#40;
  SELECT day, SUM&amp;#40;cash&amp;#95;movement&amp;#95;amount&amp;#41; AS amount
  FROM &amp;#40;
    SELECT
      date&amp;#95;trunc&amp;#40;cash&amp;#95;movement&amp;#95;time, 'day'&amp;#41; AS day,
      cash&amp;#95;movement&amp;#95;amount
    FROM cash&amp;#95;movements
  &amp;#41; AS x
  GROUP BY day
&amp;#41;;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;That's a lot of code duplication! I wish I could do something like the following instead:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;sql&quot;&gt;CREATE TEMPORARY VIEW aggregate&amp;#95;cash&amp;#95;flow&amp;#95;by&amp;#95;day &amp;#40;cash&amp;#95;movmts&amp;#41; -- mind the parameter here
AS &amp;#40;
  SELECT day, SUM&amp;#40;cash&amp;#95;movement&amp;#95;amount&amp;#41; AS amount
  FROM &amp;#40;
    SELECT
      date&amp;#95;trunc&amp;#40;cash&amp;#95;movement&amp;#95;time, 'day'&amp;#41; AS day,
      cash&amp;#95;movement&amp;#95;amount
    FROM cash&amp;#95;movmts
  &amp;#41; AS x
  GROUP BY day
&amp;#41;;

CREATE TEMPORARY VIEW revenue&amp;#95;per&amp;#95;day AS &amp;#40;
  SELECT &amp;#42; FROM aggregate&amp;#95;cash&amp;#95;flow&amp;#95;by&amp;#95;day&amp;#40;
    SELECT &amp;#42; FROM cash&amp;#95;movements
    WHERE cash&amp;#95;movement&amp;#95;amount &amp;gt; 0
  &amp;#41;
&amp;#41;;

CREATE TEMPORARY VIEW expenses&amp;#95;per&amp;#95;day AS &amp;#40;
  SELECT &amp;#42; FROM aggregate&amp;#95;cash&amp;#95;flow&amp;#95;by&amp;#95;day&amp;#40;
    SELECT &amp;#42; FROM cash&amp;#95;movements
    WHERE cash&amp;#95;movement&amp;#95;amount &amp;lt; 0
  &amp;#41;
&amp;#41;;

CREATE TEMPORARY VIEW cash&amp;#95;flow&amp;#95;per&amp;#95;day AS &amp;#40;
  SELECT &amp;#42; FROM aggregate&amp;#95;cash&amp;#95;flow&amp;#95;by&amp;#95;day&amp;#40;
    SELECT &amp;#42; FROM cash&amp;#95;movements
  &amp;#41;
&amp;#41;;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Going back to our SQL views / functions / methods analogy: in their current form, SQL views give us the equivalent of  0-arguments functions, or static methods. I wish we could have the equivalent of functions with arbitrary arity!  This would give us much more leverage for code reuse and decoupling.&lt;/p&gt;&lt;p&gt;Note that stored procedures can't really help us achieve this, as they are not temporary. The best way to emulate them currently  is probably to use a client SQL-generating library.&lt;/p&gt;&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;&lt;p&gt;I have found that:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;SQL is very powerful for expressing domain logic: consider using it for other purposes than just shipping data to/from storage!&lt;/li&gt;&lt;li&gt;SQL views are useful for code reuse and abstraction, but because they store business logic globally and durably, they create operational difficulties&lt;/li&gt;&lt;li&gt;PostgreSQL TEMPORARY views eliminate most of these operational difficulties&lt;/li&gt;&lt;li&gt;If SQL views could be parameterized, they would get insanely more powerful.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Please feel free to challenge these assertions in comments!&lt;/p&gt;
</description>
<pubDate>
Sun, 05 Nov 2017 00:00:00 +0100
</pubDate>
</item>
<item>
<guid>
http://vvvvalvalval.github.io/posts/what-makes-a-good-repl.html
</guid>
<link>
http://vvvvalvalval.github.io/posts/what-makes-a-good-repl.html
</link>
<title>
What makes a good REPL?
</title>
<description>
&lt;p&gt; &lt;i&gt;Dear Reader: although this post mentions Clojure as an example, it is not specifically about Clojure; please do not make it part of a language war. If you know other configurations which allow for a productive REPL experience, please describe them in the comments!&lt;/i&gt;&lt;/p&gt;&lt;p&gt; &lt;img src=&quot;/img/repl.gif&quot; width=&quot;100%&quot;&gt;&lt;/img&gt;&lt;/p&gt;&lt;p&gt;Most comparisons I see of Clojure to other programming languages are in terms of its programming language &lt;em&gt;semantics&lt;/em&gt;:  immutability, homoiconicity, data-orientation, dynamic typing, first-class functions, polymorphism 'à la carte'...  All of these are interesting and valuable features, but what actually gets me to &lt;em&gt;choose&lt;/em&gt; Clojure for projects is its interactive  development story, enabled by &lt;em&gt;the REPL&lt;/em&gt; (Read-Eval-Print Loop), which lets you evaluate Clojure expressions in an interactive  shell (including expressions which let you modify the state or behaviour of a running program).  &lt;/p&gt;&lt;p&gt;If you're not familiar with Clojure, you may be surprised that I describe the REPL as Clojure's most differentiating feature:   after all, most industrial programming languages come with REPLs or 'shells' these days (including Python, Ruby, Javascript, PHP, Scala,  Haskell, ...). However, I've never managed to reproduced the productive REPL workflow I had in Clojure with those languages;  the truth is that &lt;strong&gt;not all REPLs are created equal&lt;/strong&gt;.&lt;/p&gt;&lt;p&gt;In this post, I'll try to describe what a 'good' REPL gives you, then list some technical characteristics which make some REPLs   qualify as 'good'. Finally, I'll try to reflect on what programming language features give REPLs the most leverage.&lt;/p&gt;&lt;h2 id=&quot;what&amp;#95;does&amp;#95;a&amp;#95;good&amp;#95;repl&amp;#95;give&amp;#95;you?&quot;&gt;What does a good REPL give you?&lt;/h2&gt;&lt;p&gt;The short answer is: by providing a &lt;i&gt;tight feedback loop&lt;/i&gt;, and making your programs &lt;i&gt;tangible&lt;/i&gt;,  a REPL helps you deliver programs with significantly higher productivity and quality.  If you're wondering why a tight feedback loop is important for creative activities such as programming, I recommend you watch  &lt;a href='https://www.vimeo.com/36579366'&gt;this talk by Bret Victor&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;If you have no idea what REPL-based development looks like, I suggest you watch a few minutes of  &lt;a href=&quot;https://vimeo.com/230220635&quot; target=&quot;_blank&quot;&gt;the following video&lt;/a&gt;:&lt;/p&gt;&lt;p&gt;&lt;iframe src=&quot;https://player.vimeo.com/video/230220635&quot; width=&quot;640&quot; height=&quot;359&quot; frameborder=&quot;0&quot; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;&lt;/p&gt;&lt;p&gt;Now, here's the long answer: &lt;i&gt;A good REPL gives you...&lt;/i&gt;&lt;/p&gt;&lt;h3 id=&quot;a&amp;#95;smooth&amp;#95;transition&amp;#95;from&amp;#95;manual&amp;#95;to&amp;#95;automated&quot;&gt;A smooth transition from manual to automated&lt;/h3&gt;&lt;p&gt;The vast majority of the programs we write essentially automate tasks that humans can do themselves.  Ideally, to automate a complex task, we should be able to break it down into smaller sub-tasks, then gradually automate each of the subtasks until reaching a fully-automated solution.  If you were to build a sophisticated machine like a computer from scratch, you would want to make sure you understand how the individual components work before putting them together, right?  Unfortunately, this is not what we get with the typical write/(compile)/run/watch-stdout workflow, in which we essentially put all the pieces together blindly and pray it works the first time we hit 'run'.  The story is different with a REPL: you will have played with each piece of code in isolation before running the whole program,  which makes you quite confident that each of the sub-tasks is well implemented.&lt;/p&gt;&lt;p&gt;This is also true in the other direction: when a fully-automated program breaks, in order to debug it,  you will want to re-play some of the sub-tasks manually.&lt;/p&gt;&lt;p&gt;Finally, not all programs need be fully automated - sometimes the middle ground between manual and automated is exactly what you want.  For instance, a REPL is a great environment to run ad hoc queries to your database, or perform ad hoc data analysis, while leveraging  all of the automated code you have already written for your project - much better than working with database clients, especially when  you need to query several data stores or reproduce advanced business logic to access the data.&lt;/p&gt;&lt;p&gt;How's life without a REPL? Here's a list of things that we do to cope with these issues when we don't have a REPL:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Experiment with interactive tools such as cURL or database clients, then reproduce what we did in code.  Problem: you can't connect these in any way with your existing codebase. These tools are good at experimenting manually,  but then you have to code all the way to bridge the gap between making it work with these tools and having it work in your project.&lt;/li&gt;&lt;li&gt;Run scripts which call our codebase to print to standard output our files. Problem: you need to know exactly what to output before writing the script; you can't hold on to program state and &lt;em&gt;improvise&lt;/em&gt; from there, as we'll discuss in the next section.&lt;/li&gt;&lt;li&gt;Use unit tests (possibly with auto-reloading), which have a number of limitations in this regard, as we'll see later in this post.&lt;/li&gt;&lt;/ul&gt;&lt;h3 id=&quot;a&amp;#95;repl&amp;#95;lets&amp;#95;you&amp;#95;improvise&quot;&gt;A REPL lets you improvise&lt;/h3&gt;&lt;p&gt;Software programming is primarily and &lt;i&gt;exploratory&lt;/i&gt; activity.  If we had a precise idea of how our programs should work before writing them, we'd be &lt;i&gt;using&lt;/i&gt; code, not writing it.&lt;/p&gt;&lt;p&gt;Therefore, we should be able to write our programs incrementally, one expression at a time, figuring out what to do next at each step,  &lt;i&gt;walking the machine through&lt;/i&gt; our current thinking. This is simply not what the  compile/run-the-whole-thing/look-at-the-logs workflow gives you.&lt;/p&gt;&lt;p&gt;In particular, one situation where this ability is critical is fixing bugs in an emergency.  When you have to reproduce the problem, isolate the cause, simulate the fix and finally apply it, a REPL is often the  difference between minutes and hours.&lt;/p&gt;&lt;p&gt;Fun fact: maybe the most spectacular occurrence of this situation was the fixing of a bug  of the &lt;a href='https://www.youtube.com/watch?v=_gZK0tW8EhQ'&gt;Deep Space 1&lt;/a&gt; probe in 1999,  which fortunately happened to run a Common Lisp REPL while drifting off course several light-minutes away from Earth.&lt;/p&gt;&lt;h3 id=&quot;a&amp;#95;repl&amp;#95;lets&amp;#95;you&amp;#95;write&amp;#95;fewer&amp;#95;tests,&amp;#95;faster&quot;&gt;A REPL lets you write fewer tests, faster&lt;/h3&gt;&lt;p&gt;Automated tests are very useful for expressing what your code is supposed to do,  and giving you confidence that it works and keeps working correctly.&lt;/p&gt;&lt;p&gt;However, when I see some TDD codebases, it seems to me that a lot of unit tests are mostly here to make the code more tangible while developing, which is the same value proposition as using a REPL. However, using unit tests for this purpose comes with its lot of issues:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Having too many unit tests makes your codebase harder to evolve. You ideally want to have as few tests as possible capture as many properties of your domain as possible.&lt;/li&gt;&lt;li&gt;Tests can only ever answer close-ended questions: &quot;does this work?&quot;, but not &quot;how does this work?&quot;, &quot;what does this look like?&quot; etc.&lt;/li&gt;&lt;li&gt;Tests typically won't run in real-world conditions: they'll use simple, artificial data and mocks of services such as databases or API clients. As a result, they don't typically help you understand a problem that only happens on real-life data, nor do they give you confidence that the real-life implementations of the services they emulate do work.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;So it seems to me a lot of unit tests get written for lack of a better solution for interactivity,  even though they don't really pull their weight as unit tests.  When you have a REPL, you can make the choice to only write the tests that matter.&lt;/p&gt;&lt;p&gt;What's more, the REPL &lt;i&gt;helps you&lt;/i&gt; write these tests. Once you have explored from the REPL, you can just copy and paste  some of the REPL history to get both example data and expected output. You can even use the REPL to assist you in writing  the fixture data for your tests by generating it programmatically (everyone who has written comprehensive fixture datasets  by hand knows how tedious this can get). Finally, when writing the tests require implementing some non-trivial logic  (as is the case when doing Property-Based Testing), the productivity benefits of the REPL for writing code applies to writing tests as well.&lt;/p&gt;&lt;p&gt;Again, do &lt;i&gt;not&lt;/i&gt; take from this that a REPL is a replacements for tests. Please do write tests, and let the REPL help you  write the right tests effectively.&lt;/p&gt;&lt;h3 id=&quot;a&amp;#95;repl&amp;#95;makes&amp;#95;you&amp;#95;write&amp;#95;accessible&amp;#95;code&quot;&gt;A REPL makes you write accessible code&lt;/h3&gt;&lt;p&gt;A REPL-based workflow encourages you to write programs which manipulate values that are &lt;strong&gt;&lt;i&gt;easy to fabricate.&lt;/i&gt;&lt;/strong&gt;  If you need to set up a complex graph of objects before you can make a single method call, you won't be very inclined to use the REPL.  &lt;/p&gt;&lt;p&gt;As a result, you'll tend to write &lt;strong&gt;&lt;i&gt;accessible code&lt;/i&gt;&lt;/strong&gt; - with few dependencies, little environmental coupling, high modularity,   and tangible inputs and outputs.  This is likely to make your code more clear, easy to test, and easy to debug.  &lt;/p&gt;&lt;p&gt;To be clear, this &lt;i&gt;is&lt;/i&gt; an additional constraint on your code (it requires some upfront thinking to make your code REPL-friendly,  just likes it requires some upfront thinking to make your code easy to test) - but I believe it's a very beneficial constraint.  When my car engine breaks, I'm glad I can just lift the hood and access all the parts - and making this possible  has certainly put more work on the plate of car designers.&lt;/p&gt;&lt;p&gt;Another way a REPL makes code more accessible is that it makes it easier to learn, by providing a rich playground for beginners to experiment.  This applies to both learning languages and onboarding existing projects.&lt;/p&gt;&lt;h2 id=&quot;what&amp;#95;makes&amp;#95;a&amp;#95;good&amp;#95;repl?&quot;&gt;What makes a good REPL?&lt;/h2&gt;&lt;p&gt;As I said above, not all REPLs give you the same power.  Having experimented with REPLs in various configurations of language and tooling,  this is the list of the main things I believe a REPL should enable you to do to give you the most leverage:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt;Defining new behaviour / modify existing behaviour.&lt;/strong&gt; For instance, in a procedural language, this means defining new functions, and modify the implementation of existing functions.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Saving state in-memory.&lt;/strong&gt; If you can't hold on to the data you manipulate, you will waster a ton of effort re-obtaining it - it's like doing your paperwork without a desk.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Outputting values which can easily be translated to code.&lt;/strong&gt; This means that the textual representation the REPL outputs is suitable for being embedded in code.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Giving you access to your whole project code.&lt;/strong&gt; You should be able to call any piece of code written in your project of its dependencies. As an execution platform, the REPL should reproduce the conditions of running code in production as much as possible.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Putting you in the shoes of your code.&lt;/strong&gt; Given any piece of code in one of your project files, the REPL should let you put yourself in the same 'context' as that piece of code - e.g write some new code as if it was in the same line of the same source file, with the same lexical scope, runtime environment, etc.  (in Clojure, this is provided by the &lt;code&gt;&amp;#40;in-ns ...&amp;#41;&lt;/code&gt; - 'in namespace' - function). &lt;/li&gt;&lt;li&gt;&lt;strong&gt;Interacting with a running program.&lt;/strong&gt; For instance, if you're developing a web server, you want to be able to both run the webserver  and interact with it from the REPL at the same time, e.g changing the implementation of a route and seing the change in your web browser,  or sending a request from your web browser and intercepting it in your REPL. This implies some form of concurrency support,  as the program state needs to be accessed by at least 2 independent logical processes (machine events and REPL interactions).&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Synchronizing REPL state with source code files.&lt;/strong&gt; This means, for instance, 'loading' a source code file in the REPL, and then seeing all behaviour and state it defines effected in the REPL. &lt;/li&gt;&lt;li&gt;&lt;strong&gt;Being editor-friendly.&lt;/strong&gt; That is, exposing a communication interface which can be leveraged programmatically by an editor Desirable features include syntax highlighting, pretty-printing, code completion, sending code from editor buffers to the REPL, pasting editor output to editor buffers, and offering data visualization tools. (To be fair, this depends at least as much on the tooling around the REPL than on the REPL itself)&lt;/li&gt;&lt;/ol&gt;&lt;h2 id=&quot;what&amp;#95;makes&amp;#95;a&amp;#95;programming&amp;#95;language&amp;#95;repl-friendly?&quot;&gt;What makes a programming language REPL-friendly?&lt;/h2&gt;&lt;p&gt;I said earlier that Clojure's semantics were less valuable to me than its REPL; however, these two issues are not  completely separate. Some languages, because their semantics, are more or less compatible with REPL-based development.  Here is my attempt at listing the main programming language features which make a proficient REPL workflow possible:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt;Data literals.&lt;/strong&gt; That is, the values manipulated in the programs have a textual representation which is both readable for humans and executable as code. The most famous form of data literals is the JavaScript object Notation (JSON). Ideally, the programming language should make it idiomatic to write programs in which most of the values can be represented by data literals.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Immutability.&lt;/strong&gt; When programming in a REPL, you're both holding on to evaluation results and viewing them in a serialized form (text in the output); what's more, since most of the work you're doing is experimental, you want to be able confine the effects of evaluating code (most of the time, to no other effect than showing the result and saving it in memory). This means you'll tend to &lt;a href='https://www.infoq.com/presentations/Value-Values'&gt;&lt;i&gt;program with values, not side-effects&lt;/i&gt;&lt;/a&gt;. As such, programming languages which make it practical to program with immutable data structures are more REPL-friendly.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Top-level definitions.&lt;/strong&gt; Working at the REPL consists of (re-)defining data and behaviour globally. Some languages provide limited support for this (especially some class-based languages); sometimes they ship with REPLs that 'patch' some additional features to the language for this sole purpose, but in practice this results in an impedance mismatch between the REPL and an existing codebase - you should really be able to seamlessly transfer code from one to the other. More generally, the language should have semantics for re-defining code while the program is running - interactivity should not be an afterthought in language design!&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Expressive power.&lt;/strong&gt; You may think it's a bit silly to mention this one, but it's not a given. For the levels of sophistication we are aiming for, we need our languages to have clear and concise syntax which can express powerful abstractions that we know how to run efficiently, and there is no level of interactivity that can make up for those needs. This is why we don't write most of our programs as Bash scripts.&lt;/li&gt;&lt;/ol&gt;&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;&lt;p&gt;If you've ever played live music on stage without being able to hear your own instrument,   then you have a good idea of how I feel when I program without a REPL - powerless and unconfident.&lt;/p&gt;&lt;p&gt;We like to discuss the merits of programming languages and libraries in terms of the &lt;i&gt;abstractions&lt;/i&gt; they provide -   yet we have to acknowledge that &lt;i&gt;tooling&lt;/i&gt; plays an equally significant role.  Most of us have experienced it with advanced editors, debuggers, and version control to name a few,   but very few of us have had the chance to experience it with full-featured REPLs.  Hopefully this blog post will contribute to righting that wrong :). &lt;/p&gt;&lt;p&gt;&lt;strong&gt;EDIT 2017-08-28:&lt;/strong&gt; this article has been discussed on &lt;a href='https://news.ycombinator.com/item?id=15113170'&gt;Hacker News&lt;/a&gt;,  &lt;a href='https://www.reddit.com/r/programming/comments/6wbbne/what_makes_a_good_repl/'&gt;r/programming&lt;/a&gt;  and &lt;a href='https://www.reddit.com/r/Clojure/comments/6wbblu/what_makes_a_good_repl/'&gt;r/Clojure&lt;/a&gt;.&lt;/p&gt;
</description>
<pubDate>
Sun, 20 Aug 2017 00:00:00 +0200
</pubDate>
</item>
<item>
<guid>
http://vvvvalvalval.github.io/posts/2017-07-08-Datomic-this-is-not-the-history-youre-looking-for.html
</guid>
<link>
http://vvvvalvalval.github.io/posts/2017-07-08-Datomic-this-is-not-the-history-youre-looking-for.html
</link>
<title>
Datomic: this is not the history you're looking for
</title>
<description>
&lt;p&gt;In this post, I'll describe some common pitfalls regarding the use of the 'time-travel' features of Datomic  (&lt;a href='http://docs.datomic.com/javadoc/datomic/Database.html#asOf-java.lang.Object-'&gt;&lt;code&gt;db.asOf&amp;#40;&amp;#41;&lt;/code&gt;&lt;/a&gt;,  &lt;a href='http://docs.datomic.com/javadoc/datomic/Database.html#history&amp;ndash;'&gt;&lt;code&gt;db.history&amp;#40;&amp;#41;&lt;/code&gt;&lt;/a&gt;,  &lt;a href='http://docs.datomic.com/transactions.html'&gt;&lt;code&gt;:db/txInstant&lt;/code&gt;&lt;/a&gt;).&lt;/p&gt;&lt;p&gt;We'll see that, unlike what many people think when they start using Datomic, these historical features of Datomic are not so useful for implementing custom time-travel features in the business logic of applications - rather for generic database-related tasks.&lt;/p&gt;&lt;p&gt;I'll then try to describe the distinction between 'event time' and 'recording time', which is my analysis of what Datomic historical features essentially represent.&lt;/p&gt;&lt;h2 id=&quot;a&amp;#95;datomic&amp;#95;refresher&quot;&gt;A Datomic refresher&lt;/h2&gt;&lt;p&gt;These are what I call the 'time-travel features' of Datomic in this post:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href='http://docs.datomic.com/javadoc/datomic/Database.html#asOf-java.lang.Object-'&gt;&lt;code&gt;db.asOf&amp;#40;&amp;#41;&lt;/code&gt;&lt;/a&gt; lets you obtain a past version of the database at any point in time&lt;/li&gt;&lt;li&gt;&lt;a href='http://docs.datomic.com/javadoc/datomic/Database.html#history&amp;ndash;'&gt;&lt;code&gt;db.history&amp;#40;&amp;#41;&lt;/code&gt;&lt;/a&gt; gives you a view off all the datoms (i.e facts) ever added to your database, even if they've been retracted since then&lt;/li&gt;&lt;li&gt;&lt;a href='http://docs.datomic.com/transactions.html'&gt;&lt;code&gt;:db/txInstant&lt;/code&gt;&lt;/a&gt; annotates every transaction (i.e 'write') with the time at which it was processed.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Essentially, these features give you access to the past versions of the database - not just the present one.  This makes it very tempting to use them for applications that need to provide time-related features of their own.  As we'll see, this approach comes with significant caveats.&lt;/p&gt;&lt;h2 id=&quot;the&amp;#95;problem&amp;#95;by&amp;#95;examples&quot;&gt;The problem by examples&lt;/h2&gt;&lt;h3 id=&quot;problem&amp;#95;1:&amp;#95;accessing&amp;#95;revisions&amp;#95;of&amp;#95;documents&quot;&gt;Problem 1: accessing revisions of documents&lt;/h3&gt;&lt;p&gt;Imagine for instance you're implementing some blogging platform on top of Datomic,  and you want to give users the ability to view every past version of a blog post.  Instinctively, since you're using Datomic, you'd want to reach out to &lt;code&gt;db.asOf&amp;#40;&amp;#41;&lt;/code&gt; for this task:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;defn get-blog-post-as-of
  &amp;quot;Given a database value `db`, blog post id `post-id`, and time `t`,
  returns the version of the blog post as of `t`&amp;quot;
  &amp;#91;db post-id t&amp;#93;
  &amp;#40;d/pull &amp;#40;d/as-of db t&amp;#41;
    '&amp;#91;:blog.post/title
      :blog.post/content&amp;#93;
    &amp;#91;:blog.post/id post-id&amp;#93;&amp;#41;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This works fine at first, but then a few weeks later you add a new feature to your blogging platform: blog posts can  be annotated with tags. So you add 2 new attributes &lt;code&gt;:blog.post/tags&lt;/code&gt; and &lt;code&gt;:blog.tag/name&lt;/code&gt; to your schema, and you ask  an intern to annotate each of the existing blog posts by hand with some tags. The viewing code now looks like this:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;defn get-blog-post-as-of
  &amp;quot;Given a database value `db`, blog post id `post-id`, and time `t`,
  returns the version of the blog post as of `t`&amp;quot;
  &amp;#91;db post-id t&amp;#93;
  &amp;#40;d/pull &amp;#40;d/as-of db t&amp;#41;
    '&amp;#91;:blog.post/title
      :blog.post/content
      {:blog.post/tags &amp;#91;:blog.tag/name&amp;#93;}&amp;#93; ;; we just added tags to the query
    &amp;#91;:blog.post/id post-id&amp;#93;&amp;#41;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The problem is, if you run this query for a &lt;code&gt;t&lt;/code&gt; that is &lt;em&gt;before&lt;/em&gt; when you transacted the new tag attributes, this won't work! These attributes won't even be in the asOf database, not to mention the data associated with them.&lt;/p&gt;&lt;p&gt;The better way to do this would be to reify the versions of blog posts explicitly in your schema as &lt;em&gt;revision entities&lt;/em&gt;, e.g:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;defn get-blog-post-as-of
  &amp;quot;Given a database value `db`, blog post id `post-id`, and time `t`,
  returns the version of the blog post as of `t`&amp;quot;
  &amp;#91;db post-id t&amp;#93;
  &amp;#40;let &amp;#91;version-t
        &amp;#40;d/q '&amp;#91;:find &amp;#40;max ?t1&amp;#41; . :in $ ?post ?t :where
               &amp;#91;?version :blog.post.version/post ?post&amp;#93;
               &amp;#91;?version :blog.post.version/t ?t1&amp;#93;
               &amp;#91;&amp;#40;&amp;lt;= ?t1 ?t&amp;#41;&amp;#93;&amp;#93;
          db &amp;#91;:blog.post/id post-id&amp;#93; t&amp;#41;
        version-eid
        &amp;#40;d/q '&amp;#91;:find ?version . :in $ ?post ?t1 :where
               &amp;#91;?version :blog.post.version/post ?post&amp;#93;
               &amp;#91;?version :blog.post.version/t ?t1&amp;#93;&amp;#93;
          db &amp;#91;:blog.post/id post-id&amp;#93; version-t&amp;#41;&amp;#93;
    &amp;#40;d/pull db
      '&amp;#91;:blog.post.version/title
        :blog.post.version/content
        {:blog.post.version/tags &amp;#91;:blog.tag/name&amp;#93;}&amp;#93;
      version-eid&amp;#41;&amp;#41;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;(Of course, this may not be the most storage-efficient way to represent blog posts - for a serious project, you may want to use a schema   which leverages more structural sharing.)&lt;/p&gt;&lt;h3 id=&quot;problem&amp;#95;2:&amp;#95;computing&amp;#95;time&amp;#95;series&quot;&gt;Problem 2: computing time series&lt;/h3&gt;&lt;p&gt;Now imagine you're tracking what users of your blogging platform 'like' what blog posts.  You may want to do this with using a &lt;code&gt;:user/likes-post&lt;/code&gt; attribute.&lt;/p&gt;&lt;p&gt;Now, in order to display some statistics to the author, you want to count how many users have liked a post in a given time interval.  It feels natural to do it using &lt;code&gt;:db/txInstant&lt;/code&gt;:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;defn count-post-likes-in-interval
  &amp;#91;db post-id t0 t1&amp;#93;
  &amp;#40;-&amp;gt; &amp;#40;d/q '&amp;#91;:find &amp;#40;count ?user&amp;#41; . :in $ ?post ?t0 ?t1 :where
             &amp;#91;?user :user/likes-post ?post ?t&amp;#93;
             &amp;#91;?t :db/txInstant ?time&amp;#93;
             &amp;#91;&amp;#40;&amp;lt;= ?t0 ?time&amp;#41;&amp;#93; &amp;#91;&amp;#40;&amp;lt; ?time ?t1&amp;#41;&amp;#93;&amp;#93;
        db &amp;#91;:blog.post/id post-id&amp;#93; t0 t1&amp;#41;
    &amp;#40;or 0&amp;#41;&amp;#41;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This works fine at first, but now imagine you have one of these requirements:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;you want to develop an &quot;offline mode&quot; for the mobile client of your platform, in which the likes will be persisted locally and merged back later.&lt;/li&gt;&lt;li&gt;your company acquires another company, and decides to merge their blogging platform in yours, since yours so much better (thanks to Datomic, no doubt).&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;In both cases, it will be impossible for you to import the timing information, since Datomic doesn't let you set &lt;code&gt;:db/txInstant&lt;/code&gt; to a past value.&lt;/p&gt;&lt;p&gt;The better way to do this would be to track the post likes with an explicit instant-typed attribute, for instance:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;defn count-post-likes-in-interval
  &amp;#91;db post-id t0 t1&amp;#93;
  &amp;#40;-&amp;gt; &amp;#40;d/q '&amp;#91;:find &amp;#40;count ?user&amp;#41; . :in $ ?post ?t0 ?t1 :where
             &amp;#91;?like :like/post ?post&amp;#93; ;; notice how the like now has its own entity
             &amp;#91;?like :like/user ?user&amp;#93;
             &amp;#91;?like :like/time ?time&amp;#93;
             &amp;#91;&amp;#40;&amp;lt;= ?t0 ?time&amp;#41;&amp;#93; &amp;#91;&amp;#40;&amp;lt; ?time ?t1&amp;#41;&amp;#93;&amp;#93;
        db &amp;#91;:blog.post/id post-id&amp;#93; t0 t1&amp;#41;
    &amp;#40;or 0&amp;#41;&amp;#41;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;taking&amp;#95;a&amp;#95;step&amp;#95;back:&amp;#95;event&amp;#95;time&amp;#95;vs&amp;#95;recording&amp;#95;time&quot;&gt;Taking a step back: event time vs recording time&lt;/h2&gt;&lt;p&gt;What just happened here? We've just seen two very tempting uses of &lt;code&gt;db.asOf&amp;#40;&amp;#41;&lt;/code&gt; and &lt;code&gt;:db/txInstant&lt;/code&gt;  which turn out to be prohibitively constraining as your system evolves (schema growth, data migrations, deferred imports, etc.),   because you have very little control over them.  &lt;strong&gt;Datomic does not let you change your mind about the information you encode in its time-travel features,&lt;/strong&gt; and that's usually too big a constraint.&lt;/p&gt;&lt;p&gt;This is not to mean Datomic time-travel features aren't useful - they're extremely valuable for debugging, auditing,  and integrating to other data systems. But you should probably not implement your business logic with them -  in particular, &lt;strong&gt;if your system needs to offer time-related functionality, it should probably not be implemented using Datomic's own time-travel features.&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Of course, I can already here some protests: &lt;em&gt;Wait, I was told Datomic was great for keeping track of time!?&lt;/em&gt;&lt;/p&gt;&lt;p&gt;I think the root of this issue is that we use the word 'time' to denote 2 essentially distinct concepts:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt;event time&lt;/strong&gt;: the time at which stuff happened.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;recording time&lt;/strong&gt;: the time at which you're system &lt;em&gt;learns&lt;/em&gt; that stuff happened.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;em&gt;(Disclaimer: this terminology is totally made up by me as I'm writing this.)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;For instance: imagine you're sailing on the Atlantic Ocean, in the middle of a storm. At 8:03 AM, a nasty wave wipes the deck clean  and you have to swim back to the boat. At 6:12 PM, you're sitting comfortably in the cabin, writing in the boat's log:  &quot;At 8:03 AM, a nasty wave made me fall from the boat.&quot; 8:03 AM is the event time; 6:12 PM is the recording time.  These are obviously 2 distinct times (which is a good thing, otherwise the boat's log would've ended up in the water).&lt;/p&gt;&lt;p&gt;Datomic, is great at reifying recording time, and giving you leverage over it.  On the other hand, mainstream mutable databases have not really educated us to the distinction between event time and recording time,  because they essentially give you no access to recording time, which makes the notion not very interesting.  Finally, these notions are not specific to Datomic - they probably generalize to any event-sourcing system.&lt;/p&gt;&lt;h2 id=&quot;what&amp;#95;are&amp;#95;datomic&amp;#95;historical&amp;#95;features&amp;#95;good&amp;#95;for&amp;#95;then?&quot;&gt;What are Datomic historical features good for then?&lt;/h2&gt;&lt;p&gt;In short, they're mostly useful for the generic 'technical housekeeping' of your system:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Preventing information loss:&lt;/strong&gt; you have an easy-to-query archive of every piece of information that was ever saved in your system - and you don't have to anticipate how you're going to leverage it.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Auditing:&lt;/strong&gt; you can know exactly when a piece of information entered your system and how it evolved in it (especially if you're &lt;a href='http://blog.datomic.com/2015/12/reified-transactions.html'&gt;annotating the transactions&lt;/a&gt; in which these changes occurred).&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Debugging:&lt;/strong&gt; you can reproduce the conditions of a bug at the time it happened.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Change detection:&lt;/strong&gt; answering 'what changed' questions, which is very valuable when integrating Datomic to 'derived data' systems.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Having said that, it's not entirely the case that Datomic's time-travel features don't help you manage event time - they do, precisely by preventing information loss.&lt;/p&gt;&lt;p&gt;For instance, let's go back to our 'users like posts' example. Imagine that you've kept track of what users like which posts using the first approach, that is using a single &lt;code&gt;:user/likes-post&lt;/code&gt; attribute. Then you realize you'd like to keep track of when that happens, and therefore migrate to the second approach - that is, using an explicit 'like' entity. Using &lt;code&gt;:db/txInstant&lt;/code&gt;, you will at least be able to keep track of time for the likes you've collected so far - it's a bit hacky and might be inaccurate in some cases, but it's much better than no information at all.&lt;/p&gt;&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;&lt;p&gt;If you're new to Datomic, you probably have the same misconceptions as I did regarding the use of Datomic's historical features.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;bad news:&lt;/strong&gt; you've probably over-estimated the usefulness of these features for implementing your own specific time travel. Unless you really know what you're doing, I recommend you don't use &lt;code&gt;db.asOf&amp;#40;&amp;#41;&lt;/code&gt;, &lt;code&gt;db.history&amp;#40;&amp;#41;&lt;/code&gt;, and &lt;code&gt;:db/txInstant&lt;/code&gt; in your business logic code.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;good news:&lt;/strong&gt; you've probably under-estimated the usefulness of these features for managing your entire system as a programmer.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;I believe the key to getting past this confusion is the distinction between &lt;strong&gt;event time&lt;/strong&gt; (when things happened)  and &lt;strong&gt;recording time&lt;/strong&gt; (when your system learns they happened).&lt;/p&gt;&lt;p&gt;Finally, I advise you don't give too much importance to the time-travel features of Datomic - they're just the icing on the cake.  &lt;em&gt;The main benefits of immutability don't arise from time travel; they arise from unlimited consistent reads, locally-scoped changes, easy change detection, and all that can be built on top of them.&lt;/em&gt;&lt;/p&gt;
</description>
<pubDate>
Sat, 08 Jul 2017 00:00:00 +0200
</pubDate>
</item>
<item>
<guid>
http://vvvvalvalval.github.io/posts/2016-07-24-datomic-web-app-a-practical-guide.html
</guid>
<link>
http://vvvvalvalval.github.io/posts/2016-07-24-datomic-web-app-a-practical-guide.html
</link>
<title>
Using Datomic in your app: a practical guide
</title>
<description>
&lt;p&gt;&lt;em&gt;Schema rigidity, N+1 problem, impedance mismatch, remote querying, consistency...&lt;/em&gt;  Datomic eliminates many of the biggest problems of traditional databases.  That's how I like to pick technologies: to solve the hard problems for me and leave me the easy ones.  I have been using Datomic professionally for over 8 months now, and I can testify that it's given me a tremendous boost in productivity and quality,  even for ordinary web development tasks.&lt;/p&gt;&lt;p&gt;However, because Datomic is so different from other databases, and because its young ecosystem still lacks convention,  it's taken me some time and thought (at least a week) to come up with an architecture that is practical and lets me leverage its special powers.  My hope is that by reading this post, you'll be able to get started more quickly.&lt;/p&gt;&lt;h2 id=&quot;required&amp;#95;background&quot;&gt;Required background&lt;/h2&gt;&lt;p&gt;The code samples will be in Clojure, but most of the ideas behind them translate easily to other JVM languages.&lt;/p&gt;&lt;p&gt;I will not dive into the generalities of web development with Clojure; for that, I recommend the &lt;a href='http://www.luminusweb.net/'&gt;Luminus Framework&lt;/a&gt;.  I will only focus on the aspects that are specific to Datomic.&lt;/p&gt;&lt;p&gt;I am assuming that you have basic notions of how Datomic works.  If you don't, I heartedly recommend the &lt;a href='http://www.datomic.com/training.html'&gt;Day of Datomic&lt;/a&gt; training series, as well as the &lt;a href='http://docs.datomic.com/'&gt;official documentation&lt;/a&gt;.&lt;/p&gt;&lt;h3 id=&quot;a&amp;#95;quick&amp;#95;datomic&amp;#95;refresher&quot;&gt;A quick Datomic refresher&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;In Datomic, the basic unit of information is the &lt;em&gt;datom&lt;/em&gt;,which is a 5-tuple of the form &lt;code&gt;&amp;#91;&amp;lt;entity id&amp;gt; &amp;lt;attribute&amp;gt; &amp;lt;value&amp;gt; &amp;lt;transaction id&amp;gt; &amp;lt;operation&amp;gt;&amp;#93;&lt;/code&gt;, representing a fact. Examples of datoms are &lt;code&gt;&amp;#91;42 :user/email &amp;quot;hello@gmail.com&amp;quot; 201 true&amp;#93;&lt;/code&gt; and &lt;code&gt;&amp;#91;42 :user/friend 42 206 false&amp;#93;&lt;/code&gt;. The &lt;em&gt;transaction id&lt;/em&gt; essentially tells us the time at which the fact was added to the system; the &lt;em&gt;operation&lt;/em&gt; tells us   if we learned the fact or unlearned it.&lt;/li&gt;&lt;li&gt;A Datomic &lt;em&gt;database value&lt;/em&gt; is an immutable, shared data structure that is logically a set of datoms.A database value represents all the knowledge we have at a certain point in time. It's analogous to a &lt;em&gt;commit&lt;/em&gt; in Git.&lt;/li&gt;&lt;li&gt;Database values only grow by accumulating new datoms (there's no 'remove' operation: they do not 'forget' facts).&lt;/li&gt;&lt;li&gt;A Datomic system is a succession of database values. The succession of values is controlled by a process called the Transactor. A Datomic &lt;em&gt;Connection&lt;/em&gt; is a remote &lt;em&gt;reference&lt;/em&gt; to the current database value (similar to a &lt;a href='http://clojure.org/reference/agents'&gt;Clojure Agent&lt;/a&gt;). You can immediately get the current database value from a connection, and you can send writes (called &lt;a href='http://docs.datomic.com/transactions.html'&gt;transaction requests&lt;/a&gt;) asynchronously to the connection.&lt;/li&gt;&lt;li&gt;With Datomic, reading is local, and happens on the application process (which is called a 'Peer'). This is possible because database values are immutable, therefore easy to cache and location-transparent. As a peer queries a database value, it gets lazily loaded and cached into its memory, by chunks (called &lt;em&gt;segments&lt;/em&gt;) so as to avoid many I/O roundtrips to storage.&lt;/li&gt;&lt;li&gt;Datomic provides a low-level reading interface via its &lt;a href='http://docs.datomic.com/indexes.html'&gt;indexes&lt;/a&gt;,  as well 2 high-level reading interfaces on top of it: the &lt;a href='http://docs.datomic.com/query.html'&gt;Datalog&lt;/a&gt; query language and &lt;a href='http://docs.datomic.com/entities.html'&gt;Entities&lt;/a&gt;.&lt;/li&gt;&lt;/ul&gt;&lt;h2 id=&quot;business&amp;#95;logic&quot;&gt;Business Logic&lt;/h2&gt;&lt;h3 id=&quot;represent&amp;#95;business&amp;#95;entities&amp;#95;with...&amp;#95;entities&quot;&gt;Represent business entities with... Entities&lt;/h3&gt;&lt;p&gt;When I was programming with client-server databases, I often asked myself questions like:  &lt;em&gt;Should my function accept an id for this entity? Or should it accept a map representing the entity? If so, what attributes of the entity do I need? What if I need more?&lt;/em&gt; etc.  Obviously there's a balance to be struck between flexibility and performance when  addressing this kind of dilemma, because we're talking about a potentially costly roundtrip to the database server.&lt;/p&gt;&lt;p&gt;With Datomic we don't have this dilemma, because we have Entities. Entities are about as cheap to make as identifiers,  contain as much information as the whole database, and provide a convenient map-like interface.  So the guideline is simple: I always use Entities as the unit of information to communicate between my business logic functions.&lt;/p&gt;&lt;p&gt;For instance, here's a function which finds the comments of a user about a post:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;require '&amp;#91;datomic.api :as d&amp;#93;&amp;#41;

&amp;#40;defn comments-of-user-about-post
  &amp;quot;Given a user Entity and a post Entity, returns the user's comments about that post as a seq of Entities.&amp;quot;
  &amp;#91;user post&amp;#93;
  &amp;#40;let &amp;#91;db &amp;#40;d/entity-db user&amp;#41;&amp;#93;
    &amp;#40;-&amp;gt;&amp;gt; &amp;#40;d/q '&amp;#91;:find &amp;#91;?comment ...&amp;#93; :in $ ?user ?post :where
                &amp;#91;?comment :comment/post ?post&amp;#93;
                &amp;#91;?comment :comment/user ?user&amp;#93;&amp;#93;
           db &amp;#40;:db/id user&amp;#41; &amp;#40;:db/id post&amp;#41;&amp;#41;
     &amp;#40;map #&amp;#40;d/entity db %&amp;#41;&amp;#41;
     &amp;#41;&amp;#41;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;On the whole, I implement business logic using a few categories of functions:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;functions that accept entities, and return other entities (like in the example above)&lt;/li&gt;&lt;li&gt;functions that accept entities, and compute a result (e.g a boolean for making a decision, or a number synthesized from an aggregation)&lt;/li&gt;&lt;li&gt;functions that accept entities, and return transaction data (for writing)&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;In addition, at the boundaries of my domain logic, I have functions which convert entities to and from entities, mostly:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;em&gt;finder&lt;/em&gt; functions, accepting a db value and an identifier and returning an entity, e.g &lt;code&gt;&amp;#40;find-user-by-id db #uuid&amp;quot;57062d44-8829-4776-af3a-2fdf4d7ce93a&amp;quot;&amp;#41;&lt;/code&gt;&lt;/li&gt;&lt;li&gt;&lt;em&gt;clientizer&lt;/em&gt; functions, accepting an entity and returning a data structure (typically a plain old map) which can be sent over the network (typically to the  client), serialized as JSON or Transit for example. Here's an example of clientizer function: &lt;span class=&quot;sn&quot;&gt;advanced Datomic users may find this implementation uselessly verbose. Depending on the contract between your server and your client, you may be able to write a much more concise implementation using Datomic's Pull API; you may even not need clientizer functions at all!&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;defn cl-comment
  &amp;quot;clientizes a comment.&amp;quot;
  &amp;#91;cmt&amp;#93;
  {:id &amp;#40;:comment/id cmt&amp;#41;
   :content &amp;#40;:comment/content cmt&amp;#41;
   :author {:id &amp;#40;-&amp;gt; cmt :comment/author :user/id&amp;#41;}
   :post {:id &amp;#40;-&amp;gt; cmt :comment/post :post/id&amp;#41;}}&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Don't forget that in Datomic the database is effectively local, so you don't have the N+1 problem.  This means you can feel free to handle a request by doing many simple queries instead of one big query. &lt;strong&gt;&lt;i&gt;A query is not an expedition.&lt;/i&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;For example, imagine you want to make a Compojure REST endpoint that fetches the comments of a user about a specific post. Because you want to save network roundtrips to database storage, you may write it as:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;;; BAD
&amp;#40;GET &amp;quot;/posts/:postId/comments-of-user/:userId&amp;quot;
  &amp;#91;postId userId :as req&amp;#93;
  &amp;#40;let &amp;#91;db &amp;#40;:db req&amp;#41;&amp;#93;
    {:body &amp;#40;-&amp;gt;&amp;gt;
             ;; big hairy query, which complects resources identification, domain logic, and result layout
             &amp;#40;d/q '&amp;#91;:find ?id ?content ?userId ?postId
                    :in $ ?userId ?postId :where
                    ;; resources identification
                    &amp;#91;?user :user/id ?userId&amp;#93;
                    &amp;#91;?post :post/id ?postId&amp;#93;
                    ;; domain logic
                    &amp;#91;?comment :comment/post ?post&amp;#93;
                    &amp;#91;?comment :comment/author ?user&amp;#93;
                    ;; result layout
                    &amp;#91;?comment :comment/id ?id&amp;#93;
                    &amp;#91;?comment :comment/content ?content&amp;#93;
                    &amp;#93;
               db userId postId&amp;#41;
             &amp;#40;map &amp;#40;fn &amp;#91;&amp;#91;id content userId postId&amp;#93;&amp;#93;
                    {:id id
                     :content content
                     :author {:id userId}
                     :post {:id postId}}&amp;#41;&amp;#41;&amp;#41;}&amp;#41;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Obviously this is not great for code reuse. Well, you don't have to do that. Instead, you can compose the simple functions we have defined above and just write:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;;; GOOD
&amp;#40;GET &amp;quot;/posts/:postId/comments-of-user/:userId&amp;quot;
  &amp;#91;postId userId :as req&amp;#93;
  &amp;#40;let &amp;#91;db &amp;#40;:db req&amp;#41;
        ;; resources identification
        user &amp;#40;find-user-by-id db userId&amp;#41;
        post &amp;#40;find-post-by-id db postId&amp;#41;&amp;#93;
    {:body &amp;#40;-&amp;gt;&amp;gt; &amp;#40;comments-of-user-about-post user post&amp;#41; ;; domain logic
             &amp;#40;map cl-comment&amp;#41; ;; result layout
             &amp;#41;}&amp;#41;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;There are many queries involved here, but there will be very few roundtrips to storage, typically one or two, and maybe zero if the relevant segments are already cached on the Peer.&lt;/p&gt;&lt;h3 id=&quot;querying:&amp;#95;datalog&amp;#95;vs&amp;#95;entities.&quot;&gt;Querying: Datalog vs Entities.&lt;/h3&gt;&lt;p&gt;&lt;div style=&quot;text-align:center;&quot;&gt;&lt;img src=&quot;/img/DATALOG-VS-ENTITIES.jpg&quot; width=&quot;400px&quot;&gt;&lt;/div&gt;&lt;/p&gt;&lt;p&gt;Datomic gives you 2 main mechanisms for querying: Entities and Datalog queries. They're very complementary; feel free to mix and match them!&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Datalog works though pattern recognition in the database graph. It has its own constructs for control flow and abstraction, and is useful for expressing domain logic via declarative rules.&lt;/li&gt;&lt;li&gt;Entities are useful for 'navigating' around in your database, using your programming language for control flow and abstraction.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Additionally, both Datalog and Entities can be combined with the &lt;a href='http://docs.datomic.com/pull.html'&gt;Pull API&lt;/a&gt;,  giving you a powerful, declarative, data-oriented way of formatting the results of a query.&lt;/p&gt;&lt;h2 id=&quot;schema&amp;#95;/&amp;#95;model&amp;#95;declaration&quot;&gt;Schema / model declaration&lt;/h2&gt;&lt;p&gt;Before you can add useful data to Datomic, you need to &lt;em&gt;install your schema&lt;/em&gt;, which specifies the set of attributes that represent your domain model in Datomic.&lt;/p&gt;&lt;p&gt;In Datomic, installing your schema consists of submitting a regular transaction. Attribute installation transactions are idempotent,  so you can just write your schema installation transaction in your application code and &lt;code&gt;transact&lt;/code&gt; in your server startup code.&lt;/p&gt;&lt;p&gt;Here's an example of a schema installation transaction, representing a Person entity with id, email and name fields:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;ns myapp.model
  &amp;#40;:require &amp;#91;datomic.api :as d&amp;#93;&amp;#41;&amp;#41;

&amp;#40;def schema
  &amp;#91;{:db/id &amp;#40;d/tempid :db.part/db&amp;#41;
    :db/ident :person/name
    :db/valueType :db.type/uuid
    :db/unique :db.unique/identity
    :db/doc &amp;quot;A person's unique id&amp;quot;
    :db/cardinality :db.cardinality/one
    :db.install/&amp;#95;attribute :db.part/db}
   {:db/id &amp;#40;d/tempid :db.part/db&amp;#41;
    :db/ident :person/email
    :db/valueType :db.type/string
    :db/doc &amp;quot;A person's email address&amp;quot;
    :db/fulltext true
    :db/cardinality :db.cardinality/one
    :db.install/&amp;#95;attribute :db.part/db}
   {:db/id &amp;#40;d/tempid :db.part/db&amp;#41;
    :db/ident :person/name
    :db/valueType :db.type/string
    :db/doc &amp;quot;A person's name&amp;quot;
    :db/fulltext true
    :db/cardinality :db.cardinality/one
    :db.install/&amp;#95;attribute :db.part/db}&amp;#93;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;There is a &lt;a href='http://stackoverflow.com/questions/31416378/recommended-way-to-declare-datomic-schema-in-clojure-application'&gt;variety of opinions&lt;/a&gt; on how you should declare and install your schema, but in my view we have 2 issues here:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Issue 1: there's a lot of noise; ideally we'd like to spend 1 LoC on each attribute, not 7.&lt;/li&gt;&lt;li&gt;Issue 2: it's &lt;em&gt;only&lt;/em&gt; useful for Datomic schema installation, whereas you may want to declare a schema for your data model for other purposes   (input validation, documentation, REST endpoints generation, plumatic Schemas, test.check generators, etc.).  In other words, when implementing these other aspects of your data model, you'll be to duplicating code to some extent.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;There are several libraries which tackle these issues; some are just concise DSLs on top of Datomic schema transactions,  while others take care of more things (but are also more opinionated):&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href='https://github.com/Yuppiechef/datomic-schema'&gt;datomic-schema&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href='https://github.com/cloojure/tupelo-datomic'&gt;tupelo-datomic&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href='https://github.com/SparkFund/spec-tacular'&gt;spec-tacular&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href='https://github.com/zcaudate/adi'&gt;adi&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;The general idea is always the same: have a DSL generate a high-level data structure representing your data model,  then &lt;em&gt;derive&lt;/em&gt; your Datomic schema installation transactions (and other things) from this data structure.&lt;/p&gt;&lt;p&gt;Personally, none of these libraries satisfied me completely for my use case, so I wrote up my own little DSL for dealing with Issue 1  (it's not hard, really, you can totally get away with it).  I've been coping with Issue 2 so far without too much trouble - it's a pain, but really not what I spend most time on.  So really, see what works for you.  &lt;span class=&quot;sn&quot;&gt;Some Datomic users prefer keeping the schema in raw EDN-form,  arguing that the operational advantage of having the schema in a static file in transactable-form with no dependencies outweighs the inconvenience of it being verbose.  Datomic creators made the great call of designing Datomic schemas to be data-oriented and query-able, giving the users maximum flexibility in how they declare and deploy them.  You should choose the approach that suits you best for you use case and personal taste.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;In this regard, you may be wondering:&lt;/p&gt;&lt;h3 id=&quot;where's&amp;#95;my&amp;#95;orm?&quot;&gt;Where's my ORM?&lt;/h3&gt;&lt;p&gt;&lt;em&gt;(If you're definitely not interested in ORMs, you may skip this section).&lt;/em&gt;&lt;/p&gt;&lt;p&gt;Well, first off, you have to consider that Clojure is not Object-oriented, and that Datomic is not Relational (in the sense that data  is not structured as relations, which is a fancy name for tables). So much for O and R.&lt;/p&gt;&lt;p&gt;However, this doesn't mean that you wouldn't want to perform a Mapping of some sort. One of goals of ORMs is to let you use constructs of  your programming language. What with Entities and the Pull API, Datomic already goes a long way to facilitate that.&lt;/p&gt;&lt;p&gt;Another feature of ORMs is to address other issues with your data, such as validation (see 'Issue 2' above).  Datomic doesn't provide anything to help you do that.&lt;/p&gt;&lt;p&gt;If that's an issue, you may even want to roll out your own mapping library.  Implementing ORMs is knowingly difficult, but Clojure/Datomic Mapping should be significantly easier that Object/Relational Mapping,  because many of the fundamental issues of SQL databases and Object-Oriented languages simply don't exist in these technologies:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;The database is immutable and not remote, which eliminates most of the thorny distributed systems / concurrency issues you would face when implementing an ORM for a client-server database.&lt;/li&gt;&lt;li&gt;The impedance mismatch between Datomic databases and Clojure data structures is &lt;em&gt;much&lt;/em&gt; smaller than the impedance mismatch between relations and objects.&lt;/li&gt;&lt;li&gt;The DDL of Datomic is first-class data, which you can run query against and annotate as much as you want.&lt;/li&gt;&lt;li&gt;You're not constrained by a class system for declaring schemas, so you can use the syntax and information model you want.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;(Don't be too eager to go down that road though. Chances are you'll be &lt;em&gt;fine&lt;/em&gt; with just Datomic)&lt;/p&gt;&lt;p&gt;ORMs tend to be frowned upon in the Clojure community, because existing ORM implementations are so incompatible with the idea of simplicity,  because they encourage terrible distributed system semantics,  and probably also because many the Java Enterprise veterans of the community had a traumatic experience with them.&lt;/p&gt;&lt;p&gt;However, I do believe that some of the appeal of ORMs is valid.  Maybe what's missing in this space is a generic, extensible way to declare your schemas and derive behaviour from them,  and I might eventually come up with a library that lets you do it à la carte. Stay tuned.&lt;/p&gt;&lt;h2 id=&quot;data&amp;#95;migrations&quot;&gt;Data Migrations&lt;/h2&gt;&lt;p&gt;Part of database management is ensuring your database schema evolves in sync with your application code.&lt;/p&gt;&lt;p&gt;As we've seen, adding an attribute (the equivalent of adding a column or table is SQL) is straightforward.  You can just reinstall your whole schema at deployment time. Same thing for &lt;a href='http://docs.datomic.com/database-functions.html'&gt;database functions&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Modifying an attribute (e.g changing the type of &lt;code&gt;:person/id&lt;/code&gt; from &lt;code&gt;:db.type/uuid&lt;/code&gt; to &lt;code&gt;:db.type/string&lt;/code&gt;) is more problematic,  and I suggest you do your best to avoid it. Try to get your schema right in the first place; experiment with it in the  in-memory connection before committing it to durable storage. If you have committed it already, consider versioning the attribute  (e.g &lt;code&gt;:person.v2/id&lt;/code&gt;).&lt;/p&gt;&lt;p&gt;You probably won't ever need to delete an attribute. Just stop using it in your application code.  Optionally, you can mark an attribute as deprecated:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;by updating its documentation, e.g &lt;code&gt;:db/doc &amp;quot;DEPRECATED - use :person/firstName and :person/lastName instead. A person's name&amp;quot;&lt;/code&gt;&lt;/li&gt;&lt;li&gt;by adding a home-made deprecation attribute (e.g &lt;code&gt;:attr/deprecated&lt;/code&gt;) &lt;em&gt;to the attribute itself&lt;/em&gt;, since Datomic attributes are themselves entities.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Finally, you will sometimes need to run a migration that does not consist of modifying the schema, but the data itself  (fixing badly formatted data, adding a default value of a new attribute, etc.).  You want to run these migrations exactly once at deployment time.  The strategy for that is:  &lt;/p&gt;&lt;ol&gt;&lt;li&gt;write a transaction function for your migration&lt;/li&gt;&lt;li&gt;keep track of what transaction have already been run in the database&lt;/li&gt;&lt;li&gt;have a generic transaction function that conditionally runs another transaction only if it has not already been run&lt;/li&gt;&lt;li&gt;at deployment time, send your migration transactions wrapped by the generic transaction function to the transactor.  This way the transactional features of Datomic take care of the coordination for you.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;Note that there's a library called &lt;a href='https://github.com/rkneufeld/conformity'&gt;Conformity&lt;/a&gt; which takes care of 2, 3 and 4 for you.&lt;/p&gt;&lt;p&gt;As an example, imagine that you realize you stored all of your user's email addresses without controlling the case,  and you want to convert them to lower case.&lt;/p&gt;&lt;p&gt;You will add this transaction function to your schema:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;{:db/id &amp;#40;d/tempid :db.part/user&amp;#41;
 :db/ident :myapp.fns.migrations/lowercase-user-emails
 :db/fn &amp;#40;d/function
          {:lang &amp;quot;clojure&amp;quot;
           :params '&amp;#91;db&amp;#93;
           :requires '&amp;#40;&amp;#91;datomic.api :as d&amp;#93;
                       &amp;#91;clojure.string :as str&amp;#93;&amp;#41;
           :code '&amp;#40;for &amp;#91;&amp;#91;user email&amp;#93; &amp;#40;d/q '&amp;#91;:find ?user ?email :where
                                            &amp;#91;?user :user/email ?email&amp;#93;&amp;#93;
                                       db&amp;#41;&amp;#93;
                    &amp;#91;:db/add user :user/email &amp;#40;str/lower-case email&amp;#41;&amp;#93;&amp;#41;}&amp;#41;}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Then the transaction that runs your migration is simply:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#91;&amp;#91;myapp.fns.migrations/lowercase-user-emails&amp;#93;&amp;#93;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The generic transaction function for conditionnaly running migrations may look like the following:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#91;{:db/id &amp;#40;d/tempid :db.part/user&amp;#41;
  :db/ident :run-tx-if-necessary
  :db/doc &amp;quot;runs the given named transaction if it has not already been run.&amp;quot;
  :db/fn &amp;#40;d/function
           {:lang &amp;quot;clojure&amp;quot;
            :params '&amp;#91;db migr-name tx-data&amp;#93;
            :requires '&amp;#40;&amp;#91;datomic.api :as d&amp;#93;&amp;#41;
            :code '&amp;#40;when-not &amp;#40;d/q '&amp;#91;:find ?migr . :in $ ?name :where
                                    &amp;#91;?migr :migration/name ?name&amp;#93;&amp;#93;
                               db migr-name&amp;#41;
                     &amp;#40;concat
                       &amp;#91;&amp;#91;:db/add &amp;#40;d/tempid :db.part/user&amp;#41; :migration/name ?name&amp;#93;&amp;#93;
                       tx-data&amp;#41;&amp;#41;}&amp;#41;}
 {:db/id &amp;#40;d/tempid :db.part/db&amp;#41;
  :db/ident :migration/name
  :db/valueType :db.type/string
  :db/unique :db.unique/identity
  :db/doc &amp;quot;Support attribute for :run-tx-if-necessary&amp;quot;
  :db/cardinality :db.cardinality/one
  :db.install/&amp;#95;attribute :db.part/db}&amp;#93;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Then conditionally running the migration simply consists of transacting the following:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#91;&amp;#91;:run-tx-if-necessary &amp;quot;lowercase-user-emails&amp;quot; &amp;#91;&amp;#91;myapp.fns.migrations/lowercase-user-emails&amp;#93;&amp;#93;&amp;#93;&amp;#93;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Again, if you're using Comformity, you needn't concern yourself with that. This is just to give you an idea of how it works.&lt;/p&gt;&lt;h2 id=&quot;testing&amp;#95;and&amp;#95;development&amp;#95;workflow&quot;&gt;Testing and development workflow&lt;/h2&gt;&lt;p&gt;A significant part of the leverage you get from using Clojure and Datomic is the testing and interactive development stories. These are not trivial to get right, so you need to plan your architecture and workflow for them. Hopefully I've done most of the work for you.&lt;/p&gt;&lt;h3 id=&quot;fixture&amp;#95;data&quot;&gt;Fixture data&lt;/h3&gt;&lt;p&gt;If you're doing example-based testing, you're going to need some example data for your tests to work on, aka &lt;em&gt;fixture data&lt;/em&gt;.&lt;/p&gt;&lt;p&gt;Simply have a namespace where you write your fixtures as Datomic transactions, which will be run when your create your Datomic connection for testing or development.&lt;/p&gt;&lt;p&gt;You'll also want to expose some stable identifiers so that your test code can find the particular entities that interest them in the fixtures.&lt;/p&gt;&lt;p&gt;Example:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;ns myapp.fixtures
  &amp;#40;:require &amp;#91;datomic.api :as d&amp;#93;&amp;#41;&amp;#41;

&amp;#40;def person1-id #uuid&amp;quot;579ef389-525e-4017-bdd7-3eebb4a1f484&amp;quot;&amp;#41;
&amp;#40;def person2-id #uuid&amp;quot;579ef39b-13af-4acd-b3c9-3fb63a42d2ef&amp;quot;&amp;#41;

&amp;#40;def persons
  &amp;#91;{:person/id person1-id
    :person/email &amp;quot;person1@gmail.com&amp;quot;
    :person/name &amp;quot;Odysseus&amp;quot;
    :db/id &amp;#40;d/tempid :db.part/user&amp;#41;}
   {:person/id person2-id
    :person/email &amp;quot;person2@gmail.com&amp;quot;
    :person/name &amp;quot;Calliope&amp;quot;
    :db/id &amp;#40;d/tempid :db.part/user&amp;#41;}&amp;#93;&amp;#41;

;; &amp;#91;...&amp;#93;

&amp;#40;defn tx-fixtures
  &amp;quot;Returns a transaction which installs all the fixture data.&amp;quot;
  &amp;#91;&amp;#93;
  &amp;#40;concat
    persons
    ;; &amp;#91;...&amp;#93;
    &amp;#41;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;creating&amp;#95;in-memory&amp;#95;connections&quot;&gt;Creating in-memory connections&lt;/h3&gt;&lt;p&gt;The next thing we need is a way to obtain an in-memory Datomic connection with all the schema and fixture data installed.&lt;/p&gt;&lt;p&gt;Here's an implementation, which we'll modify slightly when we learn about forking connections.&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;require '&amp;#91;datomic.api :as d&amp;#93;&amp;#41;
&amp;#40;require '&amp;#91;myapp.schema :as mysc&amp;#93;&amp;#41;
&amp;#40;require '&amp;#91;myapp.fixtures :as fix&amp;#93;&amp;#41;

&amp;#40;defn scratch-conn
  &amp;quot;Creates an in-memory Datomic connection.
  NOTE: we actually won't be using this implementation, see next section on forking connections.&amp;quot;
  &amp;#91;&amp;#93;
  &amp;#40;let &amp;#91;uri &amp;#40;str &amp;quot;datomic:mem://&amp;quot; &amp;quot;mem-conn-&amp;quot; &amp;#40;d/squuid&amp;#41;&amp;#41;&amp;#93;
    &amp;#40;d/create-database uri&amp;#41;
    &amp;#40;d/connect uri&amp;#41;&amp;#41;&amp;#41;

&amp;#40;defn fixture-conn
  &amp;quot;Creates a Datomic connection with the schema and fixture data installed.&amp;quot;
  &amp;#91;&amp;#93;
  &amp;#40;let &amp;#91;conn &amp;#40;scratch-conn&amp;#41;&amp;#93;
    @&amp;#40;d/transact conn &amp;#40;mysc/tx-schema&amp;#41;&amp;#41;
    @&amp;#40;d/transact conn &amp;#40;fix/tx-fixtures&amp;#41;&amp;#41;
    conn&amp;#41;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;forking&amp;#95;database&amp;#95;connections&quot;&gt;Forking database connections&lt;/h3&gt;&lt;p&gt;So now we have connections that we can use for development and testing. That's a good start, but in their current form they can be impractical:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;if you run a test case which does writes, and want to go back to a fresh state, you'll need to explicitly release the current connection and make a new one;&lt;/li&gt;&lt;li&gt;on my dev laptop, running &lt;code&gt;&amp;#40;fixture-conn&amp;#41;&lt;/code&gt; takes about 300 ms to create the database and install the schema and fixture.  If you plan on running dozens or hundreds of tests, this can feel really slow.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Fortunately, a few months ago I discovered that you can use one of Datomic's superpowers, &lt;em&gt;speculative writes&lt;/em&gt; (aka &lt;a href='http://docs.datomic.com/clojure/#datomic.api/with'&gt;db.with()&lt;/a&gt;),  to implement an &lt;em&gt;fork&lt;/em&gt; operation on Datomic connections.  I could talk at length about forking connections (and I do it &lt;a href='http://vvvvalvalval.github.io/posts/2016-01-03-architecture-datomic-branching-reality.html'&gt;here&lt;/a&gt;); in a nutshell, forking a connection is the ability to  create a new, local connection which holds the same current database value as the old connection, but will evolve independently  of the old connection afterwards.&lt;/p&gt;&lt;p&gt;Forking connections solves both our problems because:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;you don't need to do any manual resource reclamation; forked connections will just be garbage-collected when you're done with them.&lt;/li&gt;&lt;li&gt;forking is completely inexpensive in time and space (the overhead is that of creating a Clojure Atom).&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;This changes the way we obtain a mock connection: instead of creating a connection from scratch on each test case,  we'll create a &lt;em&gt;starting-point&lt;/em&gt; connection once, and then &lt;em&gt;fork&lt;/em&gt; it to obtain a fresh connection for each test case.&lt;/p&gt;&lt;p&gt;I've implemented a tiny library called &lt;a href='https://github.com/vvvvalvalval/datomock'&gt;datomock&lt;/a&gt; which implements this fork operation.  It also implements the equivalent of &lt;code&gt;scratch-conn&lt;/code&gt;, so our previous code becomes:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;require '&amp;#91;datomic.api :as d&amp;#93;&amp;#41;
&amp;#40;require '&amp;#91;datomock.core :as dm&amp;#93;&amp;#41;
&amp;#40;require '&amp;#91;myapp.schema :as mysc&amp;#93;&amp;#41;
&amp;#40;require '&amp;#91;myapp.fixtures :as fix&amp;#93;&amp;#41;

&amp;#40;defn make-fixture-conn
  &amp;#91;&amp;#93;
  &amp;#40;let &amp;#91;conn &amp;#40;dm/mock-conn&amp;#41;&amp;#93;
    @&amp;#40;d/transact conn &amp;#40;mysc/tx-schema&amp;#41;&amp;#41;
    @&amp;#40;d/transact conn &amp;#40;fix/tx-fixtures&amp;#41;&amp;#41;
    conn&amp;#41;&amp;#41;

&amp;#40;def starting-point-conn &amp;#40;make-fixture-conn&amp;#41;&amp;#41;

&amp;#40;defn fixture-conn
  &amp;quot;Creates a Datomic connection with the schema and fixture data installed.&amp;quot;
  &amp;#91;&amp;#93;
  &amp;#40;dm/fork-conn starting-point-conn&amp;#41;&amp;#41;

&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;(we'll make one more tiny change to this code in the next section. It'll be the last one, I promise!)&lt;/p&gt;&lt;p&gt;Forking Datomic connections has other benefits.  For instance, forking your production connection enables you to instantly reproduce the state of your production system on your local machine.  That's very handy for debugging, or if you need to make a manual modification to your data and want to &quot;rehearse&quot; it locally before  committing it to the production database.&lt;/p&gt;&lt;h3 id=&quot;auto-reloading&amp;#95;tests&amp;#95;and&amp;#95;fixture&amp;#95;freshness&quot;&gt;Auto-reloading tests and fixture freshness&lt;/h3&gt;&lt;p&gt;We still have a problem with the above code: it works fine for running your test suite once or starting a local server, but it's not compatible with interactive development.&lt;/p&gt;&lt;p&gt;Whether you're running your tests in the REPL or using a auto-reloading test runner like Midje, whenever you make changes to your schema or fixture code, &lt;code&gt;starting-point-conn&lt;/code&gt; won't get updated automatically, and your tests won't reflect your last code changes.&lt;/p&gt;&lt;p&gt;We solve this using the oldest magic trick of Computer Science: time-based caching! Instead of storing our &lt;code&gt;starting-point-conn&lt;/code&gt; in a Var, we'll cache it with a Time To Live of a few seconds.&lt;/p&gt;&lt;p&gt;If you're using the Google Guava library you can use their in-memory cache directly, otherwise it's easy enough to make your own with an Atom and the core.cache library.&lt;/p&gt;&lt;p&gt;So finally, here's the &lt;strong&gt;whole&lt;/strong&gt; code for creating in-memory connections:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;require '&amp;#91;clojure.core.cache :as cache&amp;#93;&amp;#41;
&amp;#40;require '&amp;#91;datomic.api :as d&amp;#93;&amp;#41;
&amp;#40;require '&amp;#91;datomock.core :as dm&amp;#93;&amp;#41;
&amp;#40;require '&amp;#91;myapp.schema :as mysc&amp;#93;&amp;#41;
&amp;#40;require '&amp;#91;myapp.fixtures :as fix&amp;#93;&amp;#41;

&amp;#40;defn make-fixture-conn
  &amp;#91;&amp;#93;
  &amp;#40;let &amp;#91;conn &amp;#40;dm/mock-conn&amp;#41;&amp;#93;
    @&amp;#40;d/transact conn &amp;#40;mysc/tx-schema&amp;#41;&amp;#41;
    @&amp;#40;d/transact conn &amp;#40;fix/tx-fixtures&amp;#41;&amp;#41;
    conn&amp;#41;&amp;#41;

&amp;#40;defonce conn-cache
  &amp;#40;atom &amp;#40;cache/ttl-cache-factory {} :ttl 5000&amp;#41;&amp;#41;&amp;#41;

&amp;#40;defn starting-point-conn &amp;#91;&amp;#93;
  &amp;#40;:conn &amp;#40;swap! conn-cache #&amp;#40;if &amp;#40;cache/has? % :conn&amp;#41;
                             &amp;#40;cache/hit % :conn&amp;#41;
                             &amp;#40;cache/miss % :conn &amp;#40;make-fixture-conn&amp;#41;&amp;#41;&amp;#41;
           &amp;#41;&amp;#41;&amp;#41;

&amp;#40;defn fixture-conn
  &amp;quot;Creates a Datomic connection with the schema and fixture data installed.&amp;quot;
  &amp;#91;&amp;#93;
  &amp;#40;dm/fork-conn &amp;#40;starting-point-conn&amp;#41;&amp;#41;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;environments&quot;&gt;Environments&lt;/h3&gt;&lt;p&gt;In my day-to-day work, the environments I use are:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;'local': in-memory Datomic instance with fixture data.&lt;/li&gt;&lt;li&gt;'dev': Datomic instance on my local machine with real-world data (typically a dump of my production instance).&lt;/li&gt;&lt;li&gt;'prod': Datomic connection of my production system&lt;/li&gt;&lt;li&gt;'dev-fork': fork of the 'dev' Datomic instance, so that I can work on real-world data without persisting anything.&lt;/li&gt;&lt;li&gt;'prod-fork': fork of my production Datomic instance, when I need to work on up-to-date data locally&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;In practice, the environments I use most are 'local', 'dev-fork' and 'prod-fork'.&lt;/p&gt;&lt;h2 id=&quot;misc&quot;&gt;Misc&lt;/h2&gt;&lt;p&gt;Here are some last tips:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;If you have ClojureScript on the client, don't forget to have a look at the &lt;a href='https://github.com/omcljs/om/wiki#om-next'&gt;Om Next architecture&lt;/a&gt;. It's very straightforward to implement with Datomic and the Pull API, and it can save you a lot of work and trouble compared to  setting up a REST architecture.&lt;/li&gt;&lt;li&gt;Check out &lt;a href='https://github.com/tonsky/datascript'&gt;Datascript&lt;/a&gt;, which can make it easy to sync data between Datomic and the client.&lt;/li&gt;&lt;li&gt;One technique that's often useful is &lt;em&gt;attribute sharing&lt;/em&gt;: share an attribute across several entity types. For instance, if there are several entity types for which you want to track the creation time, you may want to have a generic &lt;code&gt;:time/created&lt;/code&gt; attribute, instead of 2 attributes &lt;code&gt;:post/created&lt;/code&gt; and &lt;code&gt;:comment/created&lt;/code&gt;. (There are ways in which you can abuse this approach, just know that it's a possibility).&lt;/li&gt;&lt;li&gt;Write your own lib! The Datomic ecosystem is still young, and Datomic is pretty uniquely extensible via libraries. It's completely okay to write a few helper functions to make your interactions with Datomic more convenient. Think of Datomic as a great &lt;em&gt;foundation&lt;/em&gt; for your database needs.&lt;/li&gt;&lt;/ul&gt;&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;&lt;p&gt;I hope you've found this useful, if there's anything that's unclear or missing in this post feel free to comment.  Have fun with Datomic!&lt;/p&gt;
</description>
<pubDate>
Sun, 24 Jul 2016 00:00:00 +0200
</pubDate>
</item>
<item>
<guid>
http://vvvvalvalval.github.io/posts/2016-01-03-architecture-datomic-branching-reality.html
</guid>
<link>
http://vvvvalvalval.github.io/posts/2016-01-03-architecture-datomic-branching-reality.html
</link>
<title>
Application architecture with Datomic: branching reality
</title>
<description>
&lt;p&gt;&lt;div style=&quot;text-align:center;&quot;&gt;&lt;img src=&quot;/img/multiverse.jpg&quot; width=&quot;300px&quot;&gt;&lt;/div&gt;&lt;/p&gt;&lt;p&gt;In this post, I'll present an architectural pattern for structuring Clojure and Datomic apps, playing a similar role  to Dependency Injection in the Object-Oriented world.&lt;/p&gt;&lt;p&gt;The big picture is that your application logic manipulates &lt;em&gt;universes&lt;/em&gt;, which are mutable programmatic values with a &lt;code&gt;fork&lt;/code&gt; operation, which essentially makes 2 diverging universes out of one. This 'fork' abstraction is analogous to forking branches in Git, and is made possible using one of Datomic's special powers: speculative writes.&lt;/p&gt;&lt;p&gt;I've found this approach to make system-level tests very straightforward to write, and to play nicely with interactive development. Read on for more details.&lt;/p&gt;&lt;h2 id=&quot;universes&quot;&gt;Universes&lt;/h2&gt;&lt;p&gt;Any but the most trivial application needs some way to separate configuration from use. Some examples:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;if your application is backed by a database, you'll want your application code to use a connection to your test database in a test environment,and a connection to your production database in a production environment.&lt;/li&gt;&lt;li&gt;if your application needs to send emails, for instance using a web service like Mandrill, you'll want to use a test Mandrill token  during development and tests, and a real Mandrill token in production.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;These requirements are well-known, and have been traditionally addressed in class-based languages like Java using 'Inversion of Control Patterns' like &lt;em&gt;Dependency Injection&lt;/em&gt; and &lt;em&gt;Service Locator&lt;/em&gt;.&lt;/p&gt;&lt;p&gt;In Clojure, there are no classes, so it's tempting to simply use global Vars to store configuration:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;require '&amp;#91;datomic.api :as d&amp;#93;&amp;#41;

;; configuration
&amp;#40;def conn &amp;quot;the Datomic connection&amp;quot;
  &amp;#40;d/connect &amp;#40;System/getProperty &amp;quot;DATOMIC&amp;#95;URI&amp;quot;&amp;#41;&amp;#41;&amp;#41;

&amp;#40;def mandrill-token &amp;quot;the token for authenticating to the Mandrill API&amp;quot;
  &amp;#40;System/getProperty &amp;quot;MANDRILL&amp;#95;TOKEN&amp;quot;&amp;#41;&amp;#41;


;; business logic
&amp;#40;defn some-business-logic &amp;#91;x y&amp;#93;
  &amp;#40;d/transact conn &amp;#40;make-some-transaction-using x :and y ...&amp;#41;&amp;#41;
  &amp;#40;send-mandrill-email! mandrill-token &amp;#40;make-some-email-with x :and y ...&amp;#41;&amp;#41;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Please, never do this. This is global state and environment coupling at the same time. It will make your tests harder to write, ruin your REPL experience, and complect the lifecycle of your application with the loading of its code. Bad, bad, bad.&lt;/p&gt;&lt;p&gt;Another tempting idea is to use dynamic Vars, one of Clojure's special features, to mitigate the above-mentioned issues:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;require '&amp;#91;datomic.api :as d&amp;#93;&amp;#41;

;; configuration
&amp;#40;def &amp;#94;:dynamic conn &amp;quot;the Datomic connection&amp;quot; nil&amp;#41;

&amp;#40;def &amp;#94;:dynamic mandrill-token &amp;quot;the token for authenticating to the Mandrill API&amp;quot; nil&amp;#41;


;; business logic
&amp;#40;defn some-business-logic &amp;#91;x y&amp;#93;
  &amp;#40;d/transact conn &amp;#40;make-some-transaction-using x :and y ...&amp;#41;&amp;#41;
  &amp;#40;send-mandrill-email! mandrill-token &amp;#40;make-some-email-with x :and y ...&amp;#41;&amp;#41;&amp;#41;

;; starting the application
&amp;#40;defn start-app! &amp;#91;&amp;#93;
  &amp;#40;binding &amp;#91;conn &amp;#40;d/connect &amp;#40;System/getProperty &amp;quot;DATOMIC&amp;#95;URI&amp;quot;&amp;#41;&amp;#41;
            mandrill-token &amp;#40;System/getProperty &amp;quot;MANDRILL&amp;#95;TOKEN&amp;quot;&amp;#41;&amp;#93;
    ...&amp;#41;&amp;#41;

&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;I don't recommend this either. This is still environment coupling, even if you have an easier way to control the environment. You may also find yourself typing thse annoying &lt;code&gt;&amp;#40;binding ...&amp;#41;&lt;/code&gt; clauses all the time in the REPL, which kind of defeats the purpose of using Vars.&lt;/p&gt;&lt;p&gt;It is now an &lt;a href='https://github.com/stuartsierra/component'&gt;established best practice&lt;/a&gt; in the Clojure community to pass the configuration as additional arguments to your business logic functions,  making them self-contained. For example, you can pass the configuration values as a map&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;defn some-business-logic &amp;#91;{:keys &amp;#91;conn mandrill-token&amp;#93;} x y&amp;#93;
  &amp;#40;d/transact conn &amp;#40;make-some-transaction-using x :and y ...&amp;#41;&amp;#41;
  &amp;#40;send-mandrill-email! mandrill-token &amp;#40;make-some-email-with x :and y ...&amp;#41;&amp;#41;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Where does the configuration map come from? It depends on your application. For instance, if your application is an HTTP server with a Ring adapter, the &lt;code&gt;-main&lt;/code&gt; function could create the configuration map from  environment properties at startup, then listen to the HTTP port and 'attach' the configuration map to each incoming request.&lt;/p&gt;&lt;p&gt;This 'configuration map' could also be called a 'context' or 'environment', but I want to call it a &lt;em&gt;universe&lt;/em&gt;, for reasons which will become more obvious later.&lt;/p&gt;&lt;p&gt;What makes a universe? Here are some examples of what you might put in this configuration map:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;database connections&lt;/li&gt;&lt;li&gt;API tokens and other configuration constants&lt;/li&gt;&lt;li&gt;application services as protocol implementations (so that you may mock them), e.g Ring session-stores&lt;/li&gt;&lt;li&gt;if you're using Datomic, the current database value&lt;/li&gt;&lt;li&gt;the present time (never use &lt;code&gt;&amp;#40;new java.util.Date&amp;#41;&lt;/code&gt;, that's environment coupling too!)&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;The mental model is that your application logic is made of stateless, configuration-free, timeless components which manipulate the universe (&lt;em&gt;any universe&lt;/em&gt;) in response to events. In contrast, with Dependency Injection, I would say that your application components are created inside and configured by a universe.&lt;/p&gt;&lt;p&gt;In testing, universes will tend to be made out of test database connections and mocked services. After all, that's the idea behind making mocks for testing: fabricating a small, isolated universe in which we can mess around without affecting the &lt;em&gt;real&lt;/em&gt; universe, the one our business cares about.&lt;/p&gt;&lt;p&gt;Hold that thought. We'll make a small detour in Datomic Land to get some reality-branching superpowers, then come back to universes,  at which point things will get more interesting.&lt;/p&gt;&lt;h2 id=&quot;lemma:&amp;#95;mocking&amp;#95;datomic&amp;#95;connections&quot;&gt;Lemma: mocking Datomic connections&lt;/h2&gt;&lt;p&gt;Datomic supports &lt;em&gt;speculative writes&lt;/em&gt;, in the form of its &lt;code&gt;datomic.api/with&lt;/code&gt; function. Roughly speaking, &lt;code&gt;with&lt;/code&gt; accepts a database value and a write specification, and returns an updated database value &lt;em&gt;as if&lt;/em&gt; you had sent a transaction to the connection.&lt;/p&gt;&lt;p&gt;Therefore, it's useful to answer &quot;what if&quot; questions. But we can go further and abuse &lt;code&gt;with&lt;/code&gt; to mock Datomic connections in-memory. Here is a complete implementation, which is essentially an Atom holding database values, which uses &lt;code&gt;with&lt;/code&gt; for writes (&lt;strong&gt;edit:&lt;/strong&gt; you can now use the &lt;a href='https://github.com/vvvvalvalval/datomock'&gt;datomock library&lt;/a&gt;):&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;import 'datomic.Connection&amp;#41;
&amp;#40;import '&amp;#40;java.util.concurrent BlockingQueue LinkedBlockingDeque&amp;#41;&amp;#41;
&amp;#40;require 'datomic.promise&amp;#41;
&amp;#40;require '&amp;#91;datomic.api :as d&amp;#93;&amp;#41;

&amp;#40;defrecord MockConnection
  &amp;#91;dbAtom, &amp;#94;BlockingQueue txQueue&amp;#93;

  Connection
  &amp;#40;db &amp;#91;this&amp;#93; @dbAtom&amp;#41;
  &amp;#40;transact &amp;#91;this tx-data&amp;#93; &amp;#40;doto &amp;#40;datomic.promise/settable-future&amp;#41;
                             &amp;#40;deliver &amp;#40;let &amp;#91;tx-res
                                            &amp;#40;loop &amp;#91;&amp;#93;
                                              &amp;#40;let &amp;#91;old-val @dbAtom
                                                    tx-res &amp;#40;d/with old-val tx-data&amp;#41;
                                                    new-val &amp;#40;:db-after tx-res&amp;#41;&amp;#93;
                                                &amp;#40;if &amp;#40;compare-and-set! dbAtom old-val new-val&amp;#41;
                                                  tx-res
                                                  &amp;#40;recur&amp;#41;&amp;#41;
                                                &amp;#41;&amp;#41;&amp;#93;
                                        &amp;#40;.add &amp;#94;BlockingQueue txQueue tx-res&amp;#41;
                                        tx-res&amp;#41;&amp;#41;
                             &amp;#41;&amp;#41;
  &amp;#40;transactAsync &amp;#91;this tx-data&amp;#93; &amp;#40;.transact this tx-data&amp;#41;&amp;#41;

  &amp;#40;gcStorage &amp;#91;this olderThan&amp;#93;&amp;#41;
  &amp;#40;requestIndex &amp;#91;this&amp;#93;&amp;#41;
  &amp;#40;release &amp;#91;this&amp;#93;&amp;#41;
  &amp;#40;sync &amp;#91;this&amp;#93; &amp;#40;doto &amp;#40;datomic.promise/settable-future&amp;#41;
                 &amp;#40;deliver &amp;#40;.db this&amp;#41;&amp;#41;&amp;#41;&amp;#41;
  &amp;#40;syncExcise &amp;#91;this t&amp;#93; &amp;#40;.sync this&amp;#41;&amp;#41;
  &amp;#40;syncIndex &amp;#91;this t&amp;#93; &amp;#40;.sync this&amp;#41;&amp;#41;
  &amp;#40;syncSchema &amp;#91;this t&amp;#93; &amp;#40;.sync this&amp;#41;&amp;#41;
  &amp;#40;sync &amp;#91;this t&amp;#93; &amp;#40;.sync this&amp;#41;&amp;#41;
  &amp;#40;txReportQueue &amp;#91;this&amp;#93; &amp;#40;.txQueue this&amp;#41;&amp;#41;

  &amp;#41;

&amp;#40;defn &amp;#94;Connection mock-conn
  &amp;quot;Creates a mocked version of datomic.Connection which uses db/with internally.
  Only supports datomic.api/db, datomic.api/transact and datomic.api/transact-async operations.
  Sync and housekeeping methods are implemented as noops. #log&amp;#40;&amp;#41; is not supported.&amp;quot;
  &amp;#91;db&amp;#93;
  &amp;#40;MockConnection. &amp;#40;atom db&amp;#41; &amp;#40;LinkedBlockingDeque.&amp;#41;&amp;#41;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;You may be wondering, how is this different than using Datomic's built-in in-memory connections ? (as in &lt;code&gt;&amp;#40;d/connect &amp;quot;datomic:mem://my-db-name&amp;quot;&amp;#41;&amp;#41;&lt;/code&gt;) Well, Datomic's in-memory connections start with a blank database, whereas in the above implementation the user provides a &lt;em&gt;starting-point database&lt;/em&gt;. This starting point might be a database loaded with fixture data; it might also be your current production database!&lt;/p&gt;&lt;p&gt;In particular, you can use these mock connections to make a local 'fork' of any Datomic connection:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;defn &amp;#94;Connection fork-conn
  &amp;quot;Creates a local fork of the given Datomic connection.
  Writes to the forked connection will not affect the original;
  conversely, writes to the original connection will not affect the forked one.&amp;quot;
  &amp;#91;conn&amp;#93;
  &amp;#40;mock-conn &amp;#40;d/db conn&amp;#41;&amp;#41;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;Analogy to Git:&lt;/strong&gt; This is the same notion of forking as in Git, where database values are like commits, and connections are like branches.  (However, unlike Git, there is no 'merge' operation).&lt;/p&gt;&lt;h2 id=&quot;forking&amp;#95;universes&quot;&gt;Forking universes&lt;/h2&gt;&lt;p&gt;This notion of forking is interesting, and applicable to other objects than Datomic connections. For example, immutable data structures and simple mutable interfaces (e.g HTTP session stores) can be forked too.&lt;/p&gt;&lt;p&gt;Which brings us to the main point: &lt;strong&gt;if the universes of your application have Datomic as their main data store, then you can &lt;em&gt;fork&lt;/em&gt; these universes&lt;/strong&gt;.&lt;/p&gt;&lt;p&gt;&lt;em&gt;Forking&lt;/em&gt; a universe is making a local 'copy' of a universal which behaves exactly as the original one, in which you can mess around without affecting the original one.&lt;/p&gt;&lt;p&gt;This is of tremendous value for system-level testing. Because of functional programming, Clojure already has a great story for testing &lt;em&gt;in the small&lt;/em&gt;, but in the large, your system is essentially a process which performs in-place updates in response to events. Forkable connections are a nice fit for this model. Forget about your setup and teardown phases: instead, you have a &lt;em&gt;starting point&lt;/em&gt; universe,  and for each of your tests which involves writes, you simply fork off another universe, perform your tests, and forget about it when you're done.  Garbage collection will do the cleaning up for you.&lt;/p&gt;&lt;p&gt;For instance, imagine you have an e-commerce website, and you want to test the purchase flow. The purchase flow consists of the user signing up, verifying her account, adding items to the cart, and checking out. Typically, the test will consist of one ideal scenario, and several scenarios where things go wrong, like the cart expiring or the user logging out before checking out. You can easily test this by branching off several universes matching different scenarios as you progress along the user path:&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;/img/funnel-purchase.png&quot; width=&quot;100%&quot;&gt;&lt;/p&gt;&lt;p&gt;The code for testing this may look like the following:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;let &amp;#91;u &amp;#40;fork starting-point-universe&amp;#41;&amp;#93;
  &amp;#40;create-account! u&amp;#41;

  &amp;#40;let &amp;#91;u &amp;#40;fork u&amp;#41;&amp;#93;
    &amp;#40;expect-to-fail
      &amp;#40;add-items-to-cart! u some-items-data&amp;#41;&amp;#41;&amp;#41;

  &amp;#40;verify-account! u&amp;#41;

  &amp;#40;let &amp;#91;u &amp;#40;fork u&amp;#41;&amp;#93;
    &amp;#40;expect-to-fail
      &amp;#40;add-items-to-cart! u sold-out-items-data&amp;#41;&amp;#41;&amp;#41;

  &amp;#40;add-items-to-cart! u some-items-data&amp;#41;

  &amp;#40;let &amp;#91;u &amp;#40;fork u&amp;#41;&amp;#93;
    &amp;#40;expect-to-fail
      &amp;#40;log-out! u&amp;#41;
      &amp;#40;pay-and-check-out! u&amp;#41;&amp;#41;&amp;#41;

  &amp;#40;let &amp;#91;u &amp;#40;assoc &amp;#40;fork u&amp;#41;
            :now &amp;#40;after-the-cart-has-expired&amp;#41;&amp;#41;&amp;#93;
    &amp;#40;expect-to-fail
      &amp;#40;pay-and-check-out! u&amp;#41;&amp;#41;&amp;#41;

  &amp;#40;expect-to-succeed
    &amp;#40;pay-and-check-out! u&amp;#41;&amp;#41;
  &amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Forkable universes also offer a lot of leverage of interactive development. Sometimes I want to work in my development environment with my production data, but without committing any change to my production database;  this is useful for experimenting with new features, or for demonstration purposes.  All I have to is fork my production context and run my local server on it.&lt;/p&gt;&lt;p&gt;I can also imagine automating the above idea to make &quot;inspection tests&quot;, in which you would periodically simulate some scenarios on your production data.&lt;/p&gt;&lt;p&gt;Finally, I think forkability makes room for some REPL-friendly debugging techniques.  For example, you can insert 'checkpoints' in a code path you're debugging, which when reached will make forks of the current universe and store them.  You can then retrieve these checkpoints to inspect the past of the universe, or to replay some steps manually.&lt;/p&gt;&lt;h2 id=&quot;about&amp;#95;mutability&quot;&gt;About mutability&lt;/h2&gt;&lt;p&gt;Universes are essentially about mutability and side-effects, which may seem at odds with the functional spirit of Clojure and Datomic. That's not the case in my opinion, since Clojure positioned itself &lt;a href='http://www.infoq.com/presentations/Value-Identity-State-Rich-Hickey'&gt;since the beginning&lt;/a&gt; as supporting mutability in the few places where it is a better fit than a purely functional style.&lt;/p&gt;&lt;p&gt;Having said that, universes and the ability to fork them are no excuse to make a mutable imperative mess. You still want to make the building blocks of your application purely functional, on as large a scale as is reasonable.&lt;/p&gt;&lt;h2 id=&quot;forkability,&amp;#95;and&amp;#95;clojure's&amp;#95;time&amp;#95;model&quot;&gt;Forkability, and Clojure's time model&lt;/h2&gt;&lt;p&gt;The &lt;em&gt;Epochal Time Model&lt;/em&gt; embodied in Clojure and Datomic consists of an &lt;em&gt;identity&lt;/em&gt; (represented e.g by a Datomic connection, an Atom, ...) which &lt;em&gt;state&lt;/em&gt; changes over time as a succession of values (e.g Datomic database values, persistent data structures, ...): &quot;the state is the value of an identity at a point in time&quot;. In this model, changing the state means setting the state of an identity to a new value.&lt;/p&gt;&lt;p&gt;Interestingly, &lt;em&gt;forking&lt;/em&gt; also has a natural interpretation in this time model: duplicating an identity without changing its state.  (at least that's the way I see it).&lt;/p&gt;&lt;h2 id=&quot;practical&amp;#95;usage&quot;&gt;Practical usage&lt;/h2&gt;&lt;p&gt;I have a test namespace with a function to create 'starting-point universe' loaded with fixture data. This function is called by tests, and by me from the REPL. Because loading the database schema and fixture data can take some time (~100ms), I back this function with a TTL cache of a few seconds. This allows me to never have a stale context as my code evolves, while not wasting time on a heavy setup phase for each test.&lt;/p&gt;&lt;p&gt;On top of that, I have a dev namespace with 2 functions &lt;code&gt;fu&lt;/code&gt; (&lt;em&gt;Fresh Universe&lt;/em&gt;) and &lt;code&gt;lu&lt;/code&gt; (&lt;em&gt;Local Universe&lt;/em&gt;). Both return universes with fixture data, but &lt;code&gt;fu&lt;/code&gt; returns a different universe each time it is called (stateless), whereas &lt;code&gt;lu&lt;/code&gt; creates a universe the first time and then returns it (session); there is an optional param to reset the universe returned by &lt;code&gt;lu&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;To achieve full universe forkability, I also had to make mock implementations of a few key-value stores in addition to Datomic, such as Ring session stores.&lt;/p&gt;&lt;h2 id=&quot;parting&amp;#95;thoughts&quot;&gt;Parting thoughts&lt;/h2&gt;&lt;p&gt;I am constantly amazed to see how immutability, although it encourages functional programming, also makes dealing with side-effects and mutable places better. This is a lesson we have learned in the small with Clojure's references, and now we're learning it in the large with Datomic.&lt;/p&gt;&lt;p&gt;At &lt;a href='https://www.bandsquare.com'&gt;BandSquare&lt;/a&gt; we have applied the above ideas to our whole backend system, to great benefits so far. We will continue to explore the possibilities and limitations of forkable universes, and we welcome your feedback.&lt;/p&gt;&lt;p&gt;Happy New Year!&lt;/p&gt;
</description>
<pubDate>
Sun, 03 Jan 2016 00:00:00 +0100
</pubDate>
</item>
<item>
<guid>
http://vvvvalvalval.github.io/posts/2015-09-16-bottup-approach-to-reagent-state.html
</guid>
<link>
http://vvvvalvalval.github.io/posts/2015-09-16-bottup-approach-to-reagent-state.html
</link>
<title>
A bottom-up approach to state in Reagent
</title>
<description>
&lt;p&gt;In this post, I'll present an alternative way of managing state in Reagent applications to what is currently made popular by libraries like &lt;a href='https://github.com/Day8/re-frame'&gt;Re-frame&lt;/a&gt;.&lt;/p&gt;&lt;h2 id=&quot;tl;dr&quot;&gt;TL;DR&lt;/h2&gt;&lt;p&gt;We'll be able to declare 'local state' inside our Reagent components, which feels like ephemeral local atoms but is accessible globally and is Figwheel-reloadable.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;End result&lt;/strong&gt; : &lt;iframe src=&quot;https://player.vimeo.com/video/139510973&quot; width=&quot;100%&quot; height=&quot;330&quot; frameborder=&quot;0&quot; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;&lt;/p&gt;&lt;p&gt;(watch it in HD &lt;a href=&quot;https://vimeo.com/139510973&quot; target=&quot;_blank&quot;&gt;here&lt;/a&gt;)&lt;/p&gt;&lt;h2 id=&quot;rationale&quot;&gt;Rationale&lt;/h2&gt;&lt;p&gt;From what I have seen, the currently most popular approach to state management in Reagent applications is to have one global Reactive Atom and to centralize the behaviour for updating this Ratom.&lt;/p&gt;&lt;p&gt;I completely agree that this approach is very sound for a large space of applications; it also has the advantage of making your code &lt;a href='https://github.com/bhauman/lein-figwheel#writing-reloadable-code'&gt;Figwheel-reloadable&lt;/a&gt; out of the box.&lt;/p&gt;&lt;p&gt;However, I do believe this approach has its limitations. Basing everything on a global ratom encourages your components to leverage a lot of context, making them less 'portable'. More importantly, I find this forces you to have a top-down approach to state management: you need to design the whole schema for your app state, and account for everything that could happen to it from the very start.&lt;/p&gt;&lt;p&gt;Sometimes, I feel I do not want this. Instead, I want my components to behave not as partial views of some global state, but as 'micro-applications', managing their own state instead of deferring this to some global decision maker. I like the idea that my components are autonomous, and can just be plugged into their parents without much knowledge of their context. This is what I call a &lt;em&gt;bottom-up&lt;/em&gt; approach to state management. &lt;span class=&quot;sn&quot;&gt;This is about the only way of doing things in libraries like AngularJS, in which directives just have local state and are meant to be autonomous. What I find great in Reagent is that I can combine both approaches.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;In this post, I'll present a way of achieving this, while retaining some of the great benefits of the top-down approach.&lt;/p&gt;&lt;h2 id=&quot;requirements&quot;&gt;Requirements&lt;/h2&gt;&lt;p&gt;Our goal is to abide by the following requirements :&lt;/p&gt;&lt;ol&gt;&lt;li&gt;We want to make Reagent components with local state. In particular, the lifecycle of this local state is bound to the lifecycle of the component: it gets initialized when the component mounts, it gets cleaned up when the component unmounts.&lt;/li&gt;&lt;li&gt;We want this local state managed by the component, not externally&lt;/li&gt;&lt;li&gt;This 'local state' is actually perceptible from the global Reactive Atom of our app. This way, our system has the 'all state in one place' property, a.k.a 'email me your state and I'll see exactly what you see'.&lt;/li&gt;&lt;li&gt;This local state is &lt;em&gt;reloadable&lt;/em&gt;, i.e when we are developing with Figwheel, we don't have to re-create this state each time we make a code change.&lt;/li&gt;&lt;/ol&gt;&lt;h2 id=&quot;the&amp;#95;traditional&amp;#95;approach&amp;#95;to&amp;#95;local-state&amp;#95;in&amp;#95;reagent&quot;&gt;The traditional approach to local-state in Reagent&lt;/h2&gt;&lt;p&gt;As we can learn from the &lt;a href='https://reagent-project.github.io/'&gt;project page&lt;/a&gt;, the traditional way of making components with local state is as follows:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;instead of writing a rendering function, you write a 'wrapper' function which &lt;em&gt;returns&lt;/em&gt; a rendering function.&lt;/li&gt;&lt;li&gt;the 'wrapper' function initializes some local state in the form of ratoms stored in locals of the wrapper function&lt;/li&gt;&lt;li&gt;the rendering function just closes over these locals and uses them.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;This is all very neat and intuitive, but it does not quite comply to our requirements : it's not reachable from our global state ratom, and it's not figwheel-reloadable.&lt;/p&gt;&lt;h2 id=&quot;strategy&quot;&gt;Strategy&lt;/h2&gt;&lt;p&gt;Here is how we'll implement this :&lt;/p&gt;&lt;ul&gt;&lt;li&gt;we still have a unique global ratom, which will hold &lt;em&gt;all the state&lt;/em&gt; of the application (including component-local state)&lt;/li&gt;&lt;li&gt;instead of creating local ratoms, stateful components will be handed a 'location' (a Cursor) in the global state where to put their local state.&lt;/li&gt;&lt;li&gt;they will initialize this local state when they mount, and clean it when they unmount&lt;/li&gt;&lt;li&gt;we'll also need some tricks to make this robust to figwheel code reloads.&lt;/li&gt;&lt;/ul&gt;&lt;h2 id=&quot;example&quot;&gt;Example&lt;/h2&gt;&lt;p&gt;I'll demonstrate this with a very poor, ugly version of TODO MVC.&lt;/p&gt;&lt;p&gt;Let's first lay out the 'model' of our app:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;require '&amp;#91;reagent.core :as r&amp;#93;&amp;#41;

;; this atom holds the global state, we use `defonce` to make it reloadable
&amp;#40;defonce todo-state-atom &amp;#40;r/atom {:todos &amp;#91;&amp;#93;}&amp;#41;&amp;#41;

;; here's a little helper to generate unique ids
&amp;#40;defonce next-id &amp;#40;atom 0&amp;#41;&amp;#41;
&amp;#40;defn gen-id &amp;#91;&amp;#93; &amp;#40;swap! next-id inc&amp;#41;&amp;#41;

;; these 3 functions are for manipulating the state
&amp;#40;defn add-todo &amp;#91;todo-state&amp;#93; &amp;#40;update todo-state :todos conj {:id &amp;#40;gen-id&amp;#41; :text &amp;quot;&amp;quot;}&amp;#41;&amp;#41;

&amp;#40;defn delete-todo &amp;#91;todo-state {:keys &amp;#91;id&amp;#93;}&amp;#93;
  &amp;#40;update todo-state :todos &amp;#40;fn &amp;#91;todos&amp;#93; &amp;#40;-&amp;gt;&amp;gt; todos &amp;#40;remove #&amp;#40;= &amp;#40;:id %&amp;#41; id&amp;#41;&amp;#41; vec&amp;#41;&amp;#41;&amp;#41;&amp;#41;

&amp;#40;defn update-todo &amp;#91;todo-state {:keys &amp;#91;id&amp;#93; :as todo}&amp;#93;
  &amp;#40;update todo-state :todos &amp;#40;fn &amp;#91;todos&amp;#93; &amp;#40;-&amp;gt;&amp;gt; todos &amp;#40;map #&amp;#40;if &amp;#40;= &amp;#40;:id %&amp;#41; id&amp;#41; todo %&amp;#41;&amp;#41; vec&amp;#41;&amp;#41;&amp;#41;&amp;#41;

&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Now, let's see how to implement the view.&lt;/p&gt;&lt;h3 id=&quot;the&amp;#95;traditional&amp;#95;way:&amp;#95;with&amp;#95;old&amp;#95;fashioned&amp;#95;locals&quot;&gt;The traditional way: with old fashioned locals&lt;/h3&gt;&lt;p&gt;As a reference for comparison, we'll start by implementing it the 'traditional' Reagent way : with local ratoms to hold the local state.&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;;; ... and here's our UI :
&amp;#40;declare &amp;lt;todos-list&amp;gt; &amp;lt;todo-item&amp;gt;&amp;#41;

&amp;#40;defn &amp;lt;todos-list&amp;gt; &amp;#91;&amp;#93;
  &amp;#40;let &amp;#91;update-me! #&amp;#40;swap! todo-state-atom update-todo %&amp;#41;
        delete-me! #&amp;#40;swap! todo-state-atom delete-todo %&amp;#41;&amp;#93;
    &amp;#91;:div.container
     &amp;#91;:h2 &amp;quot;TODO&amp;quot;&amp;#93;
     &amp;#91;:ul
      &amp;#40;for &amp;#91;todo &amp;#40;:todos @todo-state-atom&amp;#41;&amp;#93;
        &amp;#94;{:key &amp;#40;:id todo&amp;#41;} &amp;#91;&amp;lt;todo-item&amp;gt; todo update-me! delete-me!&amp;#93;
        &amp;#41;&amp;#93;
     &amp;#91;:button.btn.btn-success {:on-click #&amp;#40;swap! todo-state-atom add-todo&amp;#41;} &amp;quot;Add&amp;quot;&amp;#93;

     &amp;#91;:div
      &amp;#91;:h2 &amp;quot;State&amp;quot;&amp;#93;
      &amp;#91;:pre &amp;#40;with-out-str &amp;#40;pprint/pprint @todo-state-atom&amp;#41;&amp;#41;&amp;#93;&amp;#93;&amp;#93;&amp;#41;&amp;#41;

&amp;#40;defn &amp;lt;todo-item&amp;gt; &amp;#91;{:keys &amp;#91;id&amp;#93;} update-me! delete-me!&amp;#93;
  &amp;#40;let &amp;#91;local-state &amp;#40;r/atom {:editing false}&amp;#41;&amp;#93;
    &amp;#40;fn &amp;#91;{:keys &amp;#91;id text&amp;#93; :as todo} update-me! delete-me!&amp;#93;
      &amp;#40;if &amp;#40;:editing @local-state&amp;#41;
        &amp;#91;:li
         &amp;#91;:span &amp;quot;type in some awesome text :&amp;quot;&amp;#93;
         &amp;#91;:input {:type &amp;quot;text&amp;quot; :value text :on-change #&amp;#40;update-me! &amp;#40;assoc todo :text &amp;#40;-&amp;gt; % .-target .-value&amp;#41;&amp;#41;&amp;#41;}&amp;#93;
         &amp;#91;:button {:on-click #&amp;#40;swap! local-state assoc :editing false&amp;#41;} &amp;quot;Done&amp;quot;&amp;#93;&amp;#93;
        &amp;#91;:li
         &amp;#91;:span &amp;quot;text: &amp;quot; text&amp;#93;
         &amp;#91;:button {:on-click #&amp;#40;swap! local-state assoc :editing true&amp;#41;} &amp;quot;Edit&amp;quot;&amp;#93;
         &amp;#91;:button {:on-click #&amp;#40;delete-me! todo&amp;#41;} &amp;quot;Remove&amp;quot;&amp;#93;&amp;#93;&amp;#41;
      &amp;#41;&amp;#41;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This is the most straightforward way of doing things, but as we said earlier, it does not yield an optimal result: the local state is not reachable from the global atom, not does it survive code reloads. Let's make this better.&lt;/p&gt;&lt;h3 id=&quot;the&amp;#95;new&amp;#95;way:&amp;#95;with&amp;#95;managed&amp;#95;cursors&quot;&gt;The new way: with managed cursors&lt;/h3&gt;&lt;p&gt;We'll store the local state in cursors of the global ratom, instead of ratoms stored in locals.&lt;/p&gt;&lt;p&gt;Of course, now that we're not using locals, we can no longer rely on garbage collection to clean up after us, so we have to do it explicitly using lifecycle methods.&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;;; in this cursor, we'll put the local state of each list item
&amp;#40;defonce todos-state-cursor &amp;#40;r/cursor todo-state-atom &amp;#91;:todo-state&amp;#93;&amp;#41;&amp;#41;

&amp;#40;declare &amp;lt;todos-list&amp;gt; &amp;lt;todo-item&amp;gt; &amp;lt;todo-item-plugged&amp;gt;&amp;#41;

&amp;#40;defn &amp;lt;todos-list&amp;gt; &amp;#91;&amp;#93;
  &amp;#40;let &amp;#91;update-me! #&amp;#40;swap! todo-state-atom update-todo %&amp;#41;
        delete-me! #&amp;#40;swap! todo-state-atom delete-todo %&amp;#41;&amp;#93;
    &amp;#91;:div.container
     &amp;#91;:h2 &amp;quot;TODO&amp;quot;&amp;#93;
     &amp;#91;:ul
      &amp;#40;for &amp;#91;todo &amp;#40;:todos @todo-state-atom&amp;#41;&amp;#93;
        &amp;#94;{:key &amp;#40;:id todo&amp;#41;} &amp;#91;&amp;lt;todo-item&amp;gt; todos-state-cursor todo update-me! delete-me!&amp;#93;
        &amp;#41;&amp;#93;
     &amp;#91;:button.btn.btn-success {:on-click #&amp;#40;swap! todo-state-atom add-todo&amp;#41;} &amp;quot;Add&amp;quot;&amp;#93;

     &amp;#91;:div
      &amp;#91;:h2 &amp;quot;State&amp;quot;&amp;#93;
      &amp;#91;:pre &amp;#40;with-out-str &amp;#40;pprint/pprint @todo-state-atom&amp;#41;&amp;#41;&amp;#93;&amp;#93;&amp;#93;&amp;#41;&amp;#41;

&amp;#40;defn &amp;lt;todo-item&amp;gt; &amp;#91;parent-atom {:keys &amp;#91;id&amp;#93;} update-me! delete-me!&amp;#93;
  &amp;#40;let &amp;#91;local-state-cursor &amp;#40;r/cursor parent-atom &amp;#91;id&amp;#93;&amp;#41;&amp;#93;
    &amp;#40;r/create-class
      {:component-will-mount &amp;#40;fn &amp;#91;&amp;#95;&amp;#93; &amp;#40;when-not @local-state-cursor ;; setting up
                                       &amp;#40;reset! local-state-cursor {:editing false}&amp;#41;&amp;#41;&amp;#41;
       :component-will-unmount &amp;#40;fn &amp;#91;&amp;#95;&amp;#93; &amp;#40;swap! parent-atom dissoc id&amp;#41;&amp;#41; ;; cleaning up
       :reagent-render
       &amp;#40;fn &amp;#91;parent-atom {:keys &amp;#91;id text&amp;#93; :as todo} update-me! delete-me!&amp;#93;
         &amp;#40;if &amp;#40;:editing @local-state-cursor&amp;#41;
           &amp;#91;:li
            &amp;#91;:span &amp;quot;type in some awesome text :&amp;quot;&amp;#93;
            &amp;#91;:input {:type &amp;quot;text&amp;quot; :value text :on-change #&amp;#40;update-me! &amp;#40;assoc todo :text &amp;#40;-&amp;gt; % .-target .-value&amp;#41;&amp;#41;&amp;#41;}&amp;#93;
            &amp;#91;:button {:on-click #&amp;#40;swap! local-state-cursor assoc :editing false&amp;#41;} &amp;quot;Done&amp;quot;&amp;#93;&amp;#93;
           &amp;#91;:li
            &amp;#91;:span &amp;quot;text: &amp;quot; text&amp;#93;
            &amp;#91;:button {:on-click #&amp;#40;swap! local-state-cursor assoc :editing true&amp;#41;} &amp;quot;Edit&amp;quot;&amp;#93;
            &amp;#91;:button {:on-click #&amp;#40;delete-me! todo&amp;#41;} &amp;quot;Remove&amp;quot;&amp;#93;&amp;#93;&amp;#41;
         &amp;#41;}&amp;#41;&amp;#41;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We have now full visibility of the whole state of our app, and can manipulate all of it using the REPL. This is a big improvement.&lt;/p&gt;&lt;p&gt;However, we haven't achieved reloadability yet. Let's see how it goes.&lt;/p&gt;&lt;h3 id=&quot;making&amp;#95;it&amp;#95;reloadable&quot;&gt;Making it reloadable&lt;/h3&gt;&lt;p&gt;This is kind of tricky.&lt;/p&gt;&lt;p&gt;In order to reload the code, our app has to be re-mounted into the DOM on each code reload. I'm using the &lt;a href='https://github.com/bhauman/figwheel-template'&gt;figwheel Leiningen template&lt;/a&gt;, which does it by calling a &lt;code&gt;mount-root&lt;/code&gt; function on each reload :&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;defn mount-root &amp;#91;&amp;#93;
  &amp;#40;r/render &amp;#91;&amp;lt;todos-list&amp;gt;&amp;#93; &amp;#40;.getElementById js/document &amp;quot;app&amp;quot;&amp;#41;&amp;#41;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The problem is, each time a new version gets mounted, the old version gets unmounted. As a consequence, the &lt;code&gt;:component-will-unmount&lt;/code&gt; function we defined above is called, and diligently erases our local state.&lt;/p&gt;&lt;p&gt;We need to find a way of informing our component that the unmounting is caused by a Figwheel reload, so that it does not erase its state. This is made harder by the fact that mounting happens asynchronously.&lt;/p&gt;&lt;p&gt;The best way I've found is to set up a flag when the reloading happens, and leave it up long enough that the DOM can mount :&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;defonce reloading-state &amp;#40;atom false&amp;#41;&amp;#41; ;; note that we're using a regular atom: the whole point is not to interfere with Reagent here.

&amp;#40;defn reload! &amp;#91;timeout&amp;#93;
  &amp;#40;when timeout
    &amp;#40;reset! reloading-state true&amp;#41;
    &amp;#40;js/setTimeout #&amp;#40;reset! reloading-state false&amp;#41; timeout&amp;#41;&amp;#41;&amp;#41;

&amp;#40;defn reloading? &amp;#91;&amp;#93; @reloading-state&amp;#41;

;; ...

&amp;#40;defn mount-root &amp;#91;&amp;#93;
  &amp;#40;reload! 200&amp;#41;
  &amp;#40;r/render &amp;#91;&amp;lt;todos-list&amp;gt;&amp;#93; &amp;#40;.getElementById js/document &amp;quot;app&amp;quot;&amp;#41;&amp;#41;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Now we can use this by making a tiny change to our component definition :&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;defn &amp;lt;todo-item&amp;gt; &amp;#91;parent-atom {:keys &amp;#91;id&amp;#93;} update-me! delete-me!&amp;#93;
       ;; ...
       :component-will-unmount &amp;#40;fn &amp;#91;&amp;#95;&amp;#93; &amp;#40;when-not &amp;#40;reloading?&amp;#41;
                                         &amp;#40;swap! parent-atom dissoc id&amp;#41;&amp;#41;&amp;#41;
        ;; ...
       &amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;To be honest, I'm not very proud of it, but it works; and given that it only affects our development environment, I don't feel too worried using this little hack.&lt;/p&gt;&lt;h3 id=&quot;making&amp;#95;it&amp;#95;less&amp;#95;tedious:&amp;#95;pluggable&amp;#95;components&quot;&gt;Making it less tedious: pluggable components&lt;/h3&gt;&lt;p&gt;This is great, but it's a pity that we have to resort to lifecycle methods and explicit calls to our &lt;code&gt;&amp;#40;reloading?&amp;#41;&lt;/code&gt; hack every time we want a component with local state, especially since we're using Reagent, which usually excels as hiding away this sort of things.&lt;/p&gt;&lt;p&gt;Fortunately, we can make it more practical. A few weeks ago, I experimented with the concept of so-called (by me) &lt;a href='https://github.com/vvvvalvalval/reagent-pluggable-components-poc'&gt;&lt;em&gt;pluggable components&lt;/em&gt;&lt;/a&gt;,  which are a way of writing stateful components which have a cleanup phase without writing the same 'lifecyle methods recipes' over and over again.&lt;/p&gt;&lt;p&gt;I won't detail how it works here (although there's &lt;a href='https://github.com/vvvvalvalval/reagent-pluggable-components-poc/blob/master/src/cljs/reagent_plug/core.cljs#L13'&gt;not much&lt;/a&gt; to it), but basically here's the amount of work it takes :&lt;/p&gt;&lt;p&gt;We first define a 'managed cursor' recipe, which encapsulates the 'local cursor lifecycle' logic we coded above :&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;defmethod make-plug ::r/managed-cursor &amp;#91;&amp;#91;&amp;#95;&amp;#93; &amp;#91;parent-ratom key&amp;#93;&amp;#93;
  &amp;#40;let &amp;#91;curs &amp;#40;r/cursor parent-ratom &amp;#91;key&amp;#93;&amp;#41;&amp;#93;
    &amp;#40;-&amp;gt;Plug curs #&amp;#40;do nil&amp;#41; #&amp;#40;when-not &amp;#40;reloading?&amp;#41; &amp;#40;swap! parent-ratom dissoc key&amp;#41;&amp;#41;&amp;#41;&amp;#41;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;From now on, we'll be able to reuse this recipe for any stateful component. Let's see how that goes for &lt;code&gt;&amp;lt;todo-item&amp;gt;&lt;/code&gt; :&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;defn &amp;lt;todos-list&amp;gt; &amp;#91;&amp;#93;
      ;; ...
      &amp;#40;for &amp;#91;todo &amp;#40;:todos @todo-state-atom&amp;#41;&amp;#93;
        ;; the external API for the component is a tiny bit different
        &amp;#94;{:key &amp;#40;:id todo&amp;#41;} &amp;#91;&amp;lt;todo-item&amp;gt; &amp;#91;todos-state-cursor &amp;#40;:id todo&amp;#41;&amp;#93; todo update-me! delete-me!&amp;#93;
        &amp;#41;&amp;#93;
      ;; ...
     &amp;#41;


&amp;#40;defplugged &amp;lt;todo-item&amp;gt;
  &amp;#91;&amp;#40;local-state-cursor &amp;#91;::r/managed-cursor&amp;#93;&amp;#41; ;; `local-state-cursor` gets injected into our component, and will be cleaned up once unmounted
   {:keys &amp;#91;id&amp;#93;} update-me! delete-me!&amp;#93;
  &amp;#40;when-not @local-state-cursor
    &amp;#40;reset! local-state-cursor {:editing false}&amp;#41;&amp;#41;
  &amp;#40;fn &amp;#91;&amp;#95; {:keys &amp;#91;id text&amp;#93; :as todo} update-me! delete-me!&amp;#93;
    &amp;#40;if &amp;#40;:editing @local-state-cursor&amp;#41;
      &amp;#91;:li
       &amp;#91;:span &amp;quot;type in some text : &amp;quot;&amp;#93;
       &amp;#91;:input.form-control {:type &amp;quot;text&amp;quot; :value text :style {:width &amp;quot;100px&amp;quot; :display &amp;quot;inline-block&amp;quot;}
                             :on-change #&amp;#40;update-me! &amp;#40;assoc todo :text &amp;#40;-&amp;gt; % .-target .-value&amp;#41;&amp;#41;&amp;#41;}&amp;#93;
       &amp;quot; &amp;quot;
       &amp;#91;:button.btn.btn-success {:on-click #&amp;#40;swap! local-state-cursor assoc :editing false&amp;#41;} &amp;quot;Done&amp;quot;&amp;#93;&amp;#93;
      &amp;#91;:li
       &amp;#91;:span &amp;quot;text: &amp;quot; text &amp;quot; &amp;quot;&amp;#93;
       &amp;#91;:button.btn.btn-primary {:on-click #&amp;#40;swap! local-state-cursor assoc :editing true&amp;#41;} &amp;quot;Edit&amp;quot;&amp;#93; &amp;quot; &amp;quot;
       &amp;#91;:button.btn.btn-danger {:on-click #&amp;#40;delete-me! todo&amp;#41;} &amp;quot;Remove&amp;quot;&amp;#93;&amp;#93;&amp;#41;
    &amp;#41;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;It's now as lightweight as we'd expect of Reagent!&lt;/p&gt;&lt;h2 id=&quot;wrapping&amp;#95;up&quot;&gt;Wrapping up&lt;/h2&gt;&lt;p&gt;I'm very excited about the possibilities of this. We can now have state that feels local, while being reachable and reloadable, with the huge benefits that come with it. Of course, this concept still has to be proven, and this implementation may be suboptimal.&lt;/p&gt;&lt;p&gt;We're getting &lt;a href='https://www.youtube.com/watch?v=PUv66718DII'&gt;there&lt;/a&gt;!&lt;/p&gt;
</description>
<pubDate>
Wed, 16 Sep 2015 00:00:00 +0200
</pubDate>
</item>
<item>
<guid>
http://vvvvalvalval.github.io/posts/2015-09-06-productive-git-setup.html
</guid>
<link>
http://vvvvalvalval.github.io/posts/2015-09-06-productive-git-setup.html
</link>
<title>
Productive Git setup
</title>
<description>
&lt;p&gt;When getting started with Git, you don't always know there exist some trick to make you more productive with it. Here are a few, most of which are already in the &lt;a href='http://git-scm.com/book/en/v1/Git-Basics-Tips-and-Tricks'&gt;official documentation&lt;/a&gt;.&lt;/p&gt;&lt;h2 id=&quot;installing&amp;#95;autocompletion&quot;&gt;Installing autocompletion&lt;/h2&gt; &lt;p&gt;When working with git from the command-line, it's very useful to have autocompletion for your branch/remote names, git commands, etc. Fortunately, there is a bash script for that.  &lt;/p&gt;&lt;p&gt;&lt;!&amp;ndash;more&amp;ndash;&gt;  &lt;/p&gt;&lt;p&gt;To achieve this, download &lt;a href='https://raw.githubusercontent.com/git/git/master/contrib/completion/git-completion.bash'&gt;this file&lt;/a&gt;, put it under your home directory under the name .git-completion.bash, then reference it from your bash initialization file (either ~/.bash_profile or ~/.bashrc) :  &lt;/p&gt;&lt;pre&gt;&lt;code&gt;source &amp;#126;/.git-completion.bash
&lt;/code&gt;&lt;/pre&gt; &lt;h2 id=&quot;defining&amp;#95;aliases&quot;&gt;Defining aliases&lt;/h2&gt; &lt;h3 id=&quot;for&amp;#95;common&amp;#95;commands&quot;&gt;For common commands&lt;/h3&gt; &lt;p&gt;Commands like &lt;code&gt;commit&lt;/code&gt;, &lt;code&gt;branch&lt;/code&gt;, `checkout are so common that it's useful to type them with fewer characters.  To do so, you create git &lt;i&gt;aliases&lt;/i&gt; by typing the following commands in a terminal :  &lt;/p&gt;&lt;pre&gt;&lt;code&gt;git config --global alias.co checkout   
git config --global alias.br branch   
git config --global alias.ci commit   
git config --global alias.st status
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Once you have done this, you can type co, br, ci, st every time you would normaly type checkout, branch, commit, status.  &lt;/p&gt;&lt;h3 id=&quot;to&amp;#95;print&amp;#95;the&amp;#95;commits&amp;#95;graph&quot;&gt;To print the commits graph&lt;/h3&gt; &lt;p&gt;The following alias will enable you print a pretty representation of the commits graph in your terminal window :&lt;/p&gt;&lt;pre&gt;&lt;code&gt;git config --global alias.lg &amp;quot;log --graph --all --pretty=format:'%C&amp;#40;bold&amp;#41;%h%Creset -%C&amp;#40;auto&amp;#41;%d%Creset %s %C&amp;#40;green dim&amp;#41;&amp;#40;%cr&amp;#41;%Creset %C&amp;#40;ul&amp;#41;&amp;lt;%an&amp;gt;&amp;quot;  
`&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Now, typing &lt;code&gt;git lg&lt;/code&gt; in your repository will print something like this :   &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;/img/git-lg-screenshot.png&quot; width=&quot;100%&quot;&gt;  &lt;/p&gt;&lt;p&gt;The effect of setting aliases is to modify your ~/.gitconfig file, which should now look like this :&lt;/p&gt;&lt;pre&gt;&lt;code&gt;   &amp;#91;user&amp;#93;  
       name = Valentin Waeselynck  
       email = val@bandsquare.fr  
  &amp;#91;alias&amp;#93;  
       lg = log --graph --all --pretty=format:'%C&amp;#40;bold&amp;#41;%h%Creset -%C&amp;#40;auto&amp;#41;%d%Creset %s %C&amp;#40;green dim&amp;#41;&amp;#40;%cr&amp;#41;%Creset %C&amp;#40;ul&amp;#41;&amp;lt;%an&amp;gt;'  
       co = checkout  
       br = branch  
       ci = commit  
       st = status  
  &amp;#91;core&amp;#93;  
       editor = vim   
  &amp;#91;filter &amp;quot;media&amp;quot;&amp;#93;  
       clean = git media clean %f  
       smudge = git media smudge %f  
       required = true  
&lt;/code&gt;&lt;/pre&gt; &lt;h2 id=&quot;using&amp;#95;a&amp;#95;git&amp;#95;gui&amp;#95;client&quot;&gt;Using a git GUI client&lt;/h2&gt; &lt;p&gt;Working from the command line with the above config is enough for 95% of my everyday work.  But sometimes, I need a better visualisation tool (e.g for diffs) in my local environment, so I also use &lt;a href='https://www.sourcetreeapp.com/'&gt;SourceTree&lt;/a&gt;.&lt;/p&gt;
</description>
<pubDate>
Sun, 06 Sep 2015 00:00:00 +0200
</pubDate>
</item>
<item>
<guid>
http://vvvvalvalval.github.io/posts/2015-09-06-Having-a-good-terminal-console-on-OS-X-in-2015.html
</guid>
<link>
http://vvvvalvalval.github.io/posts/2015-09-06-Having-a-good-terminal-console-on-OS-X-in-2015.html
</link>
<title>
Having a good terminal console on OS X in 2015
</title>
<description>
 &lt;p&gt;As a programmer, your terminal console is part of your everyday life.  That's where you launch your local server, start your database, see your heroku logs, try out that mysterious command you found on some forum, etc.  Don't try to escape it; instead, learn to master it and make it comfortable enough that you feel at home using it.  &lt;/p&gt;&lt;p&gt;My current choice for a terminal on OSX is &lt;a href='http://iterm2.com/'&gt;ITerm2 (official website)&lt;/a&gt;.  &lt;/p&gt;&lt;p&gt;&lt;!&amp;ndash;more&amp;ndash;&gt;  &lt;/p&gt;&lt;h2 id=&quot;installing&amp;#95;iterm2&quot;&gt;Installing ITerm2&lt;/h2&gt; &lt;p&gt;Nothing tricky here, just download it from the official website.  What you get is a zip archive that unpacks to a .app file. All you have to do is move that file to your Applications folder.  &lt;/p&gt;&lt;h2 id=&quot;adding&amp;#95;some&amp;#95;colors&amp;#95;to&amp;#95;the&amp;#95;console&quot;&gt;Adding some colors to the console&lt;/h2&gt; &lt;p&gt;I like my console to have a dark background because it's easier on the eyes and environment-friendly.  Also I want to see some relevant information like current *nix user and current directory.  &lt;/p&gt;&lt;p&gt;For this I use a little shell script :&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;bash&quot;&gt;  # COLORFUL PROMPT  
  # uncomment for a colored prompt, if the terminal has the capability; turned  
  # off by default to not distract the user: the focus in a terminal window  
  # should be on the output of commands, not on the prompt  
  force&amp;#95;color&amp;#95;prompt=yes  
  if &amp;#91; -n &amp;quot;$force&amp;#95;color&amp;#95;prompt&amp;quot; &amp;#93;; then  
    if &amp;#91; -x /usr/bin/tput &amp;#93; &amp;amp;&amp;amp; tput setaf 1 &amp;gt;&amp;amp;/dev/null; then  
      # We have color support; assume it's compliant with Ecma-48  
      # &amp;#40;ISO/IEC-6429&amp;#41;. &amp;#40;Lack of such support is extremely rare, and such  
      # a case would tend to support setf rather than setaf.&amp;#41;  
      color&amp;#95;prompt=yes  
    else  
      color&amp;#95;prompt=  
    fi  
  fi  
  # ANSI color codes  
  RS=&amp;quot;\&amp;#91;\033&amp;#91;0m\&amp;#93;&amp;quot;  # reset  
  HC=&amp;quot;\&amp;#91;\033&amp;#91;1m\&amp;#93;&amp;quot;  # hicolor  
  UL=&amp;quot;\&amp;#91;\033&amp;#91;4m\&amp;#93;&amp;quot;  # underline  
  INV=&amp;quot;\&amp;#91;\033&amp;#91;7m\&amp;#93;&amp;quot;  # inverse background and foreground  
  FBLK=&amp;quot;\&amp;#91;\033&amp;#91;30m\&amp;#93;&amp;quot; # foreground black  
  FRED=&amp;quot;\&amp;#91;\033&amp;#91;31m\&amp;#93;&amp;quot; # foreground red  
  FGRN=&amp;quot;\&amp;#91;\033&amp;#91;32m\&amp;#93;&amp;quot; # foreground green  
  FYEL=&amp;quot;\&amp;#91;\033&amp;#91;33m\&amp;#93;&amp;quot; # foreground yellow  
  FBLE=&amp;quot;\&amp;#91;\033&amp;#91;34m\&amp;#93;&amp;quot; # foreground blue  
  FMAG=&amp;quot;\&amp;#91;\033&amp;#91;35m\&amp;#93;&amp;quot; # foreground magenta  
  FCYN=&amp;quot;\&amp;#91;\033&amp;#91;36m\&amp;#93;&amp;quot; # foreground cyan  
  FWHT=&amp;quot;\&amp;#91;\033&amp;#91;37m\&amp;#93;&amp;quot; # foreground white  
  BBLK=&amp;quot;\&amp;#91;\033&amp;#91;40m\&amp;#93;&amp;quot; # background black  
  BRED=&amp;quot;\&amp;#91;\033&amp;#91;41m\&amp;#93;&amp;quot; # background red  
  BGRN=&amp;quot;\&amp;#91;\033&amp;#91;42m\&amp;#93;&amp;quot; # background green  
  BYEL=&amp;quot;\&amp;#91;\033&amp;#91;43m\&amp;#93;&amp;quot; # background yellow  
  BBLE=&amp;quot;\&amp;#91;\033&amp;#91;44m\&amp;#93;&amp;quot; # background blue  
  BMAG=&amp;quot;\&amp;#91;\033&amp;#91;45m\&amp;#93;&amp;quot; # background magenta  
  BCYN=&amp;quot;\&amp;#91;\033&amp;#91;46m\&amp;#93;&amp;quot; # background cyan  
  BWHT=&amp;quot;\&amp;#91;\033&amp;#91;47m\&amp;#93;&amp;quot; # background white  
  #variables pointing to ANSI color codes  
  USER&amp;#95;CLR=&amp;quot;$RS$HC$FGRN&amp;quot; # the color of the user name, e.g 'val'  
  HOST&amp;#95;CLR=&amp;quot;$RS$FYEL&amp;quot; # the color of the host, e.g 'VVV-SATELLITE-P850'  
  LOC&amp;#95;CLR=&amp;quot;$RS$FGRN&amp;quot; # the color of the location, e.g '&amp;#126;/Documents'  
  MISC&amp;#95;CLR=&amp;quot;$RS$HC$FYEL&amp;quot; # the color of other symbols  
  if &amp;#91; &amp;quot;$color&amp;#95;prompt&amp;quot; = yes &amp;#93;; then  
    #PS1='${debian&amp;#95;chroot:+&amp;#40;$debian&amp;#95;chroot&amp;#41;}\&amp;#91;\033&amp;#91;01;32m\&amp;#93;\u@\h\&amp;#91;\033&amp;#91;00m\&amp;#93;:\&amp;#91;\033&amp;#91;01;34m\&amp;#93;\w\&amp;#91;\033&amp;#91;00m\&amp;#93;\$ '  
    # primary prompt : contains special characters an sequences for additional info about a session.  
    #PS1=&amp;quot;$HC$FYEL&amp;#91; $FBLE${debian&amp;#95;chroot:+&amp;#40;$debian&amp;#95;chroot&amp;#41;}\u$FYEL: $FBLE\w $FYEL&amp;#93;\\$ $RS&amp;quot;  
    PS1=&amp;quot;$HC$MISC&amp;#95;CLR&amp;#91; $USER&amp;#95;CLR\u$HOST&amp;#95;CLR@\h: $LOC&amp;#95;CLR\w $MISC&amp;#95;CLR&amp;#93;\n$USER&amp;#95;CLR\\$ $RS&amp;quot;  
    # secondary prompt shows just '&amp;gt;'  
    PS2=&amp;quot;$HC$FYEL&amp;gt; $RS&amp;quot;  
  else  
    #PS1='${debian&amp;#95;chroot:+&amp;#40;$debian&amp;#95;chroot&amp;#41;}\u@\h:\w\$ '  
    # primary prompt : contains special characters an sequences for additional info about a session.  
    PS1=&amp;quot;&amp;#91; \u: \w &amp;#93;\\$ &amp;quot;  
    # secondary prompt shows just '&amp;gt;'  
    PS2=&amp;quot;&amp;gt; &amp;quot;  
  fi  
  unset color&amp;#95;prompt force&amp;#95;color&amp;#95;prompt  
&lt;/code&gt;&lt;/pre&gt;&lt;br /&gt;&lt;p&gt;To use it, I created a colorful&lt;i&gt;prompt.sh file with the above content which I put in a  ~/.my&lt;/i&gt;bash&lt;i&gt;config directory, then called it from my ~/.bash&lt;/i&gt;profile file (which is in charge of initializing my terminal) by adding these lines to it:  &lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;code&gt;&amp;#126;/.bash&amp;#95;profile&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;bash&quot;&gt;  # enable colorful prompt  
  source &amp;#126;/.my&amp;#95;bash&amp;#95;config/colorful&amp;#95;prompt.sh
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;You can do it all with a simple text editor like TextMate. Don't hesitate to change the colors to your liking, it should be easy from the above code.  Note that this also works on other *nix operating systems, not just OSX.  &lt;/p&gt;&lt;p&gt;Now you have a pretty terminal, which is the first step towards loving to work in the command line.  Next step is to make it more ergonomic.  &lt;/p&gt;&lt;h2 id=&quot;using&amp;#95;iterm2&amp;#95;:&amp;#95;panes,&amp;#95;tabs,&amp;#95;profiles&amp;#95;and&amp;#95;window&amp;#95;arrangements&quot;&gt;Using ITerm2 : panes, tabs, profiles and window arrangements&lt;/h2&gt;  &lt;h3 id=&quot;organizing&quot;&gt;Organizing&lt;/h3&gt;  &lt;p&gt;The first thing I find practical in ITerm2 is the possibility to have several shell sessions open next to each other in the same window.  When using ITerm2, you can have several windows, each window has several tabs, each tab is split into panes.  &lt;/p&gt;&lt;p&gt;I recommend using only one window, making it full-screen, and having many tabs each split into a few panes.  It all looks like this :&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;/img/iterm2-screenshot.png&quot; width=&quot;100%&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;small&gt;In this window, there are 6 tabs, and the current tab has 3 panes&lt;/small&gt;  &lt;/p&gt;&lt;p&gt;I'll typically have one or two tabs per project; for example, for a web development project,  I'll have a tab for the frontend and one for the backend. On the backend tab,  I'll have a small pane for my local database server, one for my backend server,  and a large one for git commands and and other command-line stuff.  &lt;/p&gt;&lt;p&gt;To achieve such a layout, use the Shell menu of ITerm2, where you can see options to create new tabs (CMD-T) and split them into panes (CMD-D, CMD-MAJ-D). You can navigate across tabs with CMD-LEFT and CMD-RIGHT.  &lt;/p&gt;&lt;h3 id=&quot;having&amp;#95;a&amp;#95;ready-to-use&amp;#95;terminal&amp;#95;with&amp;#95;profiles&amp;#95;and&amp;#95;window&amp;#95;arrangements&quot;&gt;Having a ready-to-use terminal with profiles and window arrangements&lt;/h3&gt; &lt;p&gt;You don't want to have to re-create this arrangement every time you start ITerm2.  This is why there are profiles and window arrangements.   &lt;/p&gt;&lt;p&gt;A profile is essentially a pre-defined file system location for a shell session to start in.&lt;br /&gt; If you want to always be in the same location in a certain pane, you'll have to create a profile for it.  &lt;/p&gt;&lt;p&gt;To create a profile, do Profiles &gt; Open Profiles &gt; Edit Profile, then +, then you enter the name and file system location for this profile and you're good to go.  &lt;/p&gt;&lt;p&gt;To have a pane with a specific profile, it's a bit tricky.  Place yourself in a pane, click Shell &gt; Split Vertically, then you will prompted for a profile for the newly created pane.  After that, you can close the older pane. I haven't found a more direct way.  &lt;/p&gt;&lt;p&gt;The last thing to do to save your beautiful tabs/panes layout is to save it in a window arrangement.  To do so, go to Window &gt; Save Window Arrangement.  If you want to start ITerm2 with always the same window arrangement (which you probably do),  you can set a default window arrangement in the Preferences.  &lt;/p&gt;&lt;h2 id=&quot;wrapping&amp;#95;up&quot;&gt;Wrapping up&lt;/h2&gt; &lt;p&gt;I hope this will make your relationship to terminal consoles happier.  As Obi-Wan Kenobi said to Luke in the Millennium Falcon, this is your first step into a larger world.  I was actually pleasantly surprised to discover ITerm2 for Mac, I haven't found something as ergonomic for Ubuntu.&lt;/p&gt;
</description>
<pubDate>
Sun, 06 Sep 2015 00:00:00 +0200
</pubDate>
</item>
</channel>
</rss>
